{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anumsajid13/Fabricae-FYP/blob/main/ImageToImage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz_KSSUsrPWt",
        "outputId": "15dd85ac-3403-4618-dcc5-784aa1a3228a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ai-toolkit'...\n",
            "remote: Enumerating objects: 3980, done.\u001b[K\n",
            "remote: Counting objects: 100% (2064/2064), done.\u001b[K\n",
            "remote: Compressing objects: 100% (245/245), done.\u001b[K\n",
            "remote: Total 3980 (delta 1947), reused 1839 (delta 1815), pack-reused 1916 (from 1)\u001b[K\n",
            "Receiving objects: 100% (3980/3980), 29.68 MiB | 15.56 MiB/s, done.\n",
            "Resolving deltas: 100% (3031/3031), done.\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (8.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.26.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (11.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "# Clone the required repository and install dependencies\n",
        "!git clone https://github.com/ostris/ai-toolkit\n",
        "!pip install diffusers transformers torch psutil\n",
        "!mkdir -p /content/dataset\n",
        "\n",
        "# Reasoning:\n",
        "# - Cloning the repository and installing required libraries (Diffusers, Transformers, Torch, etc.)\n",
        "# - Creating a directory for the dataset if it doesn't already exist\n",
        "#   (this will be useful when mounting or downloading data to this environment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QX2MUiwr5-L",
        "outputId": "c98c075a-2e48-4108-b582-96561b2ade81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submodule 'repositories/batch_annotator' (https://github.com/ostris/batch-annotator) registered for path 'repositories/batch_annotator'\n",
            "Submodule 'repositories/ipadapter' (https://github.com/tencent-ailab/IP-Adapter.git) registered for path 'repositories/ipadapter'\n",
            "Submodule 'repositories/leco' (https://github.com/p1atdev/LECO) registered for path 'repositories/leco'\n",
            "Submodule 'repositories/sd-scripts' (https://github.com/kohya-ss/sd-scripts.git) registered for path 'repositories/sd-scripts'\n",
            "Cloning into '/content/ai-toolkit/repositories/batch_annotator'...\n",
            "Cloning into '/content/ai-toolkit/repositories/ipadapter'...\n",
            "Cloning into '/content/ai-toolkit/repositories/leco'...\n",
            "Cloning into '/content/ai-toolkit/repositories/sd-scripts'...\n",
            "Submodule path 'repositories/batch_annotator': checked out '420e142f6ad3cc14b3ea0500affc2c6c7e7544bf'\n",
            "Submodule 'repositories/controlnet' (https://github.com/lllyasviel/ControlNet-v1-1-nightly.git) registered for path 'repositories/batch_annotator/repositories/controlnet'\n",
            "Cloning into '/content/ai-toolkit/repositories/batch_annotator/repositories/controlnet'...\n",
            "Submodule path 'repositories/batch_annotator/repositories/controlnet': checked out 'e2b44154b72965c5e11b1ccee941d550682e4701'\n",
            "Submodule path 'repositories/ipadapter': checked out '5a18b1f3660acaf8bee8250692d6fb3548a19b14'\n",
            "Submodule path 'repositories/leco': checked out '9294adf40218e917df4516737afb13f069a6789d'\n",
            "Submodule path 'repositories/sd-scripts': checked out 'b78c0e2a69e52ce6c79abc6c8c82d1a9cabcf05c'\n",
            "Collecting git+https://github.com/huggingface/diffusers.git (from -r requirements.txt (line 4))\n",
            "  Cloning https://github.com/huggingface/diffusers.git to /tmp/pip-req-build-wo4hq90e\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers.git /tmp/pip-req-build-wo4hq90e\n",
            "  Resolved https://github.com/huggingface/diffusers.git to commit ea40933f36038d61ecf6278b8019030291a67842\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu121)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.4.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.46.2)\n",
            "Collecting lycoris-lora==1.8.3 (from -r requirements.txt (line 6))\n",
            "  Downloading lycoris_lora-1.8.3.tar.gz (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flatten_json (from -r requirements.txt (line 7))\n",
            "  Downloading flatten_json-0.1.14-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
            "Collecting oyaml (from -r requirements.txt (line 9))\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.17.1)\n",
            "Collecting kornia (from -r requirements.txt (line 11))\n",
            "  Downloading kornia-0.7.4-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting invisible-watermark (from -r requirements.txt (line 12))\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.8.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (1.1.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.10.2)\n",
            "Collecting albumentations==1.4.15 (from -r requirements.txt (line 16))\n",
            "  Downloading albumentations-1.4.15-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting albucore==0.0.16 (from -r requirements.txt (line 17))\n",
            "  Downloading albucore-0.0.16-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (2.9.2)\n",
            "Collecting omegaconf (from -r requirements.txt (line 19))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting k-diffusion (from -r requirements.txt (line 20))\n",
            "  Downloading k_diffusion-0.1.1.post1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting open_clip_torch (from -r requirements.txt (line 21))\n",
            "  Downloading open_clip_torch-2.29.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (1.0.11)\n",
            "Collecting prodigyopt (from -r requirements.txt (line 23))\n",
            "  Downloading prodigyopt-1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting controlnet_aux==0.0.7 (from -r requirements.txt (line 24))\n",
            "  Downloading controlnet_aux-0.0.7.tar.gz (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.4/202.4 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-dotenv (from -r requirements.txt (line 25))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting bitsandbytes (from -r requirements.txt (line 26))\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting hf_transfer (from -r requirements.txt (line 27))\n",
            "  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting lpips (from -r requirements.txt (line 28))\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pytorch_fid (from -r requirements.txt (line 29))\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting optimum-quanto==0.2.4 (from -r requirements.txt (line 30))\n",
            "  Downloading optimum_quanto-0.2.4-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (0.2.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (0.26.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (0.13.2)\n",
            "Collecting gradio (from -r requirements.txt (line 34))\n",
            "  Downloading gradio-5.6.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (8.0.4)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (1.13.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (0.24.0)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (4.10.0.84)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (8.5.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (4.10.0.84)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (3.16.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (11.0.0)\n",
            "Collecting ninja (from optimum-quanto==0.2.4->-r requirements.txt (line 30))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.0.dev0->-r requirements.txt (line 4)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.0.dev0->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (4.66.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from flatten_json->-r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.67.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (75.1.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.1.3)\n",
            "Collecting kornia-rs>=0.1.0 (from kornia->-r requirements.txt (line 11))\n",
            "  Downloading kornia_rs-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting PyWavelets>=1.1.1 (from invisible-watermark->-r requirements.txt (line 12))\n",
            "  Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 14)) (5.9.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 18)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 18)) (2.23.4)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 19))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clean-fid (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting clip-anytorch (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading clip_anytorch-2.6.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting dctorch (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading dctorch-0.1.2-py3-none-any.whl.metadata (607 bytes)\n",
            "Collecting jsonmerge (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading jsonmerge-1.9.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchdiffeq (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading torchdiffeq-0.2.4-py3-none-any.whl.metadata (440 bytes)\n",
            "Collecting torchsde (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from k-diffusion->-r requirements.txt (line 20)) (0.18.7)\n",
            "Collecting ftfy (from open_clip_torch->-r requirements.txt (line 21))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.3 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading gradio_client-1.4.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (0.27.2)\n",
            "Collecting markupsafe~=2.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (3.10.11)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (2.2.2)\n",
            "Collecting pydub (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading ruff-0.7.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (0.13.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.3->gradio->-r requirements.txt (line 34))\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->-r requirements.txt (line 35)) (1.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2024.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (0.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (13.9.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch->-r requirements.txt (line 21)) (0.2.13)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata->controlnet_aux==0.0.7->-r requirements.txt (line 24)) (3.21.0)\n",
            "Requirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonmerge->k-diffusion->-r requirements.txt (line 20)) (4.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.32.0.dev0->-r requirements.txt (line 4)) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.32.0.dev0->-r requirements.txt (line 4)) (2.2.3)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (4.3.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (1.3.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 20)) (4.0.11)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (0.21.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 20)) (5.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (0.1.2)\n",
            "Downloading albumentations-1.4.15-py3-none-any.whl (200 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albucore-0.0.16-py3-none-any.whl (9.5 kB)\n",
            "Downloading optimum_quanto-0.2.4-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.7/109.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatten_json-0.1.14-py3-none-any.whl (8.0 kB)\n",
            "Downloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Downloading kornia-0.7.4-py2.py3-none-any.whl (899 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.4/899.4 kB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading k_diffusion-0.1.1.post1-py3-none-any.whl (33 kB)\n",
            "Downloading open_clip_torch-2.29.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prodigyopt-1.0-py3-none-any.whl (5.5 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading gradio-5.6.0-py3-none-any.whl (57.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruff-0.7.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n",
            "Downloading clip_anytorch-2.6.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dctorch-0.1.2-py3-none-any.whl (2.3 kB)\n",
            "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonmerge-1.9.2-py3-none-any.whl (19 kB)\n",
            "Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading torchdiffeq-0.2.4-py3-none-any.whl (32 kB)\n",
            "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: lycoris-lora, controlnet_aux, diffusers, antlr4-python3-runtime\n",
            "  Building wheel for lycoris-lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lycoris-lora: filename=lycoris_lora-1.8.3-py3-none-any.whl size=77134 sha256=57ff12af7c4b70e1ab36f7be7cfbf61a12950f65da8205e84343369b2305d673\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/d8/ac/e1feba5dec18685dac32ff2465ea1908cbe6a919a0c008a215\n",
            "  Building wheel for controlnet_aux (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for controlnet_aux: filename=controlnet_aux-0.0.7-py3-none-any.whl size=274344 sha256=982839945e9d72a751e9642f001c01e7a91933bbc0ca7a48f066eb6c109beb94\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/3e/93/6678b4c0bc2ec31d53409b25d4189cbb08bae843e8b2b78e52\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.32.0.dev0-py3-none-any.whl size=2935438 sha256=2bd305d4cb038ebb67083217d35a32421043840d1c2a1a9966ee4a2ec544eaef\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vab0i4e6/wheels/4d/b7/a8/6f9549ceec5daad78675b857ac57d697c387062506520a7b50\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=af83e6329971ea56d7653d21c7d1ed09cc73b07cafedbe6c71e0c6b5e18aa796\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built lycoris-lora controlnet_aux diffusers antlr4-python3-runtime\n",
            "Installing collected packages: trampoline, pydub, ninja, antlr4-python3-runtime, websockets, uvicorn, tomlkit, semantic-version, ruff, PyWavelets, python-multipart, python-dotenv, prodigyopt, oyaml, omegaconf, markupsafe, kornia-rs, hf_transfer, ftfy, flatten_json, ffmpy, aiofiles, starlette, albucore, safehttpx, gradio-client, fastapi, diffusers, albumentations, torchsde, torchdiffeq, optimum-quanto, kornia, jsonmerge, invisible-watermark, gradio, dctorch, bitsandbytes, pytorch_fid, lycoris-lora, lpips, clip-anytorch, clean-fid, open_clip_torch, k-diffusion, controlnet_aux\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: albucore\n",
            "    Found existing installation: albucore 0.0.19\n",
            "    Uninstalling albucore-0.0.19:\n",
            "      Successfully uninstalled albucore-0.0.19\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.31.0\n",
            "    Uninstalling diffusers-0.31.0:\n",
            "      Successfully uninstalled diffusers-0.31.0\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.4.20\n",
            "    Uninstalling albumentations-1.4.20:\n",
            "      Successfully uninstalled albumentations-1.4.20\n",
            "Successfully installed PyWavelets-1.7.0 aiofiles-23.2.1 albucore-0.0.16 albumentations-1.4.15 antlr4-python3-runtime-4.9.3 bitsandbytes-0.44.1 clean-fid-0.1.35 clip-anytorch-2.6.0 controlnet_aux-0.0.7 dctorch-0.1.2 diffusers-0.32.0.dev0 fastapi-0.115.5 ffmpy-0.4.0 flatten_json-0.1.14 ftfy-6.3.1 gradio-5.6.0 gradio-client-1.4.3 hf_transfer-0.1.8 invisible-watermark-0.2.0 jsonmerge-1.9.2 k-diffusion-0.1.1.post1 kornia-0.7.4 kornia-rs-0.1.7 lpips-0.1.4 lycoris-lora-1.8.3 markupsafe-2.1.5 ninja-1.11.1.1 omegaconf-2.3.0 open_clip_torch-2.29.0 optimum-quanto-0.2.4 oyaml-1.0 prodigyopt-1.0 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.12 pytorch_fid-0.3.0 ruff-0.7.4 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.12.0 torchdiffeq-0.2.4 torchsde-0.2.6 trampoline-0.1.2 uvicorn-0.32.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!cd ai-toolkit && git submodule update --init --recursive && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWlLPA5ksDEA"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SPxsSxtRoYa",
        "outputId": "fb319331-bfa8-4bd7-b916-9039d0275445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Hugging Face access token and press enter: ··········\n",
            "HF_TOKEN environment variable has been set.\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# Set up Hugging Face Token for accessing pre-trained models\n",
        "hf_token = getpass.getpass('Enter your Hugging Face access token and press enter: ')\n",
        "os.environ['HF_TOKEN'] = hf_token\n",
        "print(\"HF_TOKEN environment variable has been set.\")\n",
        "\n",
        "# Reasoning:\n",
        "# - Using Hugging Face's token allows you to load and save models from your Hugging Face account.\n",
        "# - Setting it as an environment variable enables secure access to protected resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyMBPqYesXbI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3byU-yoeSXLI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import torch library\n",
        "import torch\n",
        "\n",
        "# Define paths for dataset folders\n",
        "sketch_folder = '/content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches'\n",
        "image_folder = '/content/drive/MyDrive/Create_Dataset/Create_Dataset/images'\n",
        "prompt_folder = '/content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts'\n",
        "\n",
        "# Define hyperparameters\n",
        "batch_size = 4\n",
        "num_epochs = 5\n",
        "learning_rate = 5e-5\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Reasoning:\n",
        "# - Specifying paths makes the code modular and easy to modify if paths change.\n",
        "# - Setting hyperparameters (batch size, epochs, learning rate) and selecting the device (GPU or CPU)\n",
        "#   is essential for training configurations, especially for fine-tuning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZfWTFHMscOp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hnh4v9ZVUPLX",
        "outputId": "db666cf2-d82a-4c19-d865-10324fac3186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class SketchToImageDataset(Dataset):\n",
        "    def __init__(self, sketch_folder, image_folder, prompt_folder, transform=None):\n",
        "        self.sketch_folder = sketch_folder\n",
        "        self.image_folder = image_folder\n",
        "        self.prompt_folder = prompt_folder\n",
        "        self.transform = transform or transforms.ToTensor()\n",
        "\n",
        "        # Get file lists and base names (i.e., filenames without extensions)\n",
        "        sketch_files = sorted(os.listdir(sketch_folder))\n",
        "        image_files = sorted(os.listdir(image_folder))\n",
        "        prompt_files = sorted(os.listdir(prompt_folder))\n",
        "\n",
        "        # Get base names (i.e., file names without extensions)\n",
        "        sketch_base_names = {os.path.splitext(file)[0] for file in sketch_files}\n",
        "        image_base_names = {os.path.splitext(file)[0] for file in image_files}\n",
        "        prompt_base_names = {os.path.splitext(file)[0] for file in prompt_files}\n",
        "\n",
        "        # Find common base names across all three folders\n",
        "        common_base_names = sketch_base_names.intersection(image_base_names, prompt_base_names)\n",
        "\n",
        "        # Filter files in each folder that match the common base names\n",
        "        self.sketch_files = [file for file in sketch_files if os.path.splitext(file)[0] in common_base_names]\n",
        "        self.image_files = [file for file in image_files if os.path.splitext(file)[0] in common_base_names]\n",
        "        self.prompt_files = [file for file in prompt_files if os.path.splitext(file)[0] in common_base_names]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sketch_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      # Get file paths\n",
        "      sketch_path = os.path.join(self.sketch_folder, self.sketch_files[idx])\n",
        "      image_path = os.path.join(self.image_folder, self.image_files[idx])\n",
        "      prompt_path = os.path.join(self.prompt_folder, self.prompt_files[idx])\n",
        "\n",
        "      # Debugging step to print file paths\n",
        "      print(f\"Loading files: {sketch_path}, {image_path}, {prompt_path}\")\n",
        "\n",
        "      # Ensure the image files exist\n",
        "      if not os.path.exists(sketch_path):\n",
        "          raise FileNotFoundError(f\"Sketch file not found: {sketch_path}\")\n",
        "      if not os.path.exists(image_path):\n",
        "          raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
        "      if not os.path.exists(prompt_path):\n",
        "          raise FileNotFoundError(f\"Prompt file not found: {prompt_path}\")\n",
        "\n",
        "      # Load images using PIL\n",
        "      try:\n",
        "          sketch_image = Image.open(sketch_path).convert(\"RGB\")\n",
        "          target_image = Image.open(image_path).convert(\"RGB\")\n",
        "      except Exception as e:\n",
        "          print(f\"Error loading images: {e}\")\n",
        "          return None  # Handle image loading failure gracefully\n",
        "\n",
        "      # Debugging step to print image sizes\n",
        "      print(f\"Loaded sketch image: {sketch_image.size}, Loaded target image: {target_image.size}\")\n",
        "\n",
        "      # Load the text prompt\n",
        "      with open(prompt_path, 'r') as f:\n",
        "          prompt = f.read().strip()\n",
        "\n",
        "      # Apply transformation to convert PIL images to tensors\n",
        "      if self.transform:\n",
        "          sketch_image = self.transform(sketch_image)\n",
        "          target_image = self.transform(target_image)\n",
        "\n",
        "      return {'sketch': sketch_image, 'image': target_image, 'prompt': prompt}\n",
        "\n",
        "\n",
        "\n",
        "# Define the transformations (convert images to tensors)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),  # Resize to a consistent size\n",
        "    transforms.ToTensor(),  # Convert images to tensors\n",
        "])\n",
        "\n",
        "# Initialize the dataset with the transformations\n",
        "dataset = SketchToImageDataset(sketch_folder, image_folder, prompt_folder, transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RTum0xpsmUJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj5jvc0J4d4w",
        "outputId": "93152189-002d-44c8-c5db-c23373f96a46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Filtered Sketch Files: ['image1.png', 'image100.png', 'image103.png', 'image105.png', 'image107.png', 'image108.png', 'image114.png', 'image12.png', 'image123.png', 'image125.png', 'image13.png', 'image130.png', 'image131.png', 'image134.png', 'image139.png', 'image14.png', 'image140.png', 'image141.png', 'image146.png', 'image147.png', 'image148.png', 'image152.png', 'image158.png', 'image159.png', 'image160.png', 'image163.png', 'image167.png', 'image176.png', 'image18.png', 'image183.png', 'image198.png', 'image2.png', 'image21.png', 'image212.png', 'image213.png', 'image219.png', 'image220.png', 'image226.png', 'image229.png', 'image23.png', 'image231.png', 'image233.png', 'image234.png', 'image235.png', 'image236.png', 'image24.png', 'image240.png', 'image242.png', 'image246.png', 'image25.png', 'image254.png', 'image258.png', 'image259.png', 'image262.png', 'image264.png', 'image266.png', 'image269.png', 'image270.png', 'image271.png', 'image272.png', 'image274.png', 'image275.png', 'image276.png', 'image277.png', 'image278.png', 'image279.png', 'image28.png', 'image282.png', 'image283.png', 'image284.png', 'image285.png', 'image286.png', 'image287.png', 'image288.png', 'image29.png', 'image290.png', 'image292.png', 'image293.png', 'image295.png', 'image299.png', 'image301.png', 'image302.png', 'image303.png', 'image307.png', 'image310.png', 'image314.png', 'image318.png', 'image324.png', 'image33.png', 'image331.png', 'image334.png', 'image337.png', 'image338.png', 'image339.png', 'image34.png', 'image340.png', 'image343.png', 'image344.png', 'image349.png', 'image354.png', 'image355.png', 'image356.png', 'image361.png', 'image366.png', 'image368.png', 'image37.png', 'image370.png', 'image371.png', 'image374.png', 'image375.png', 'image380.png', 'image382.png', 'image386.png', 'image392.png', 'image394.png', 'image398.png', 'image399.png', 'image402.png', 'image403.png', 'image406.png', 'image412.png', 'image413.png', 'image420.png', 'image421.png', 'image422.png', 'image436.png', 'image44.png', 'image442.png', 'image443.png', 'image445.png', 'image446.png', 'image45.png', 'image452.png', 'image453.png', 'image46.png', 'image461.png', 'image462.png', 'image465.png', 'image466.png', 'image467.png', 'image473.png', 'image474.png', 'image475.png', 'image477.png', 'image48.png', 'image481.png', 'image483.png', 'image484.png', 'image485.png', 'image487.png', 'image489.png', 'image492.png', 'image497.png', 'image498.png', 'image501.png', 'image503.png', 'image508.png', 'image509.png', 'image51.png', 'image510.png', 'image511.png', 'image513.png', 'image514.png', 'image515.png', 'image517.png', 'image518.png', 'image521.png', 'image525.png', 'image526.png', 'image527.png', 'image532.png', 'image534.png', 'image535.png', 'image536.png', 'image537.png', 'image538.png', 'image539.png', 'image540.png', 'image541.png', 'image542.png', 'image543.png', 'image546.png', 'image552.png', 'image553.png', 'image555.png', 'image556.png', 'image558.png', 'image561.png', 'image562.png', 'image563.png', 'image566.png', 'image567.png', 'image568.png', 'image569.png', 'image570.png', 'image571.png', 'image572.png', 'image576.png', 'image578.png', 'image581.png', 'image583.png', 'image586.png', 'image589.png', 'image596.png', 'image601.png', 'image603.png', 'image606.png', 'image608.png', 'image61.png', 'image611.png', 'image612.png', 'image614.png', 'image618.png', 'image621.png', 'image623.png', 'image637.png', 'image641.png', 'image642.png', 'image646.png', 'image647.png', 'image649.png', 'image65.png', 'image655.png', 'image656.png', 'image660.png', 'image661.png', 'image663.png', 'image667.png', 'image668.png', 'image10.png', 'image101.png', 'image102.png', 'image104.png', 'image106.png', 'image109.png', 'image11.png', 'image110.png', 'image111.png', 'image112.png', 'image113.png', 'image115.png', 'image116.png', 'image117.png', 'image118.png', 'image119.png', 'image120.png', 'image121.png', 'image122.png', 'image124.png', 'image126.png', 'image127.png', 'image128.png', 'image129.png', 'image132.png', 'image133.png', 'image135.png', 'image136.png', 'image137.png', 'image138.png', 'image142.png', 'image143.png', 'image144.png', 'image145.png', 'image149.png', 'image15.png', 'image150.png', 'image151.png', 'image153.png', 'image154.png', 'image155.png', 'image156.png', 'image157.png', 'image16.png', 'image161.png', 'image162.png', 'image164.png', 'image165.png', 'image166.png', 'image168.png', 'image169.png', 'image17.png', 'image170.png', 'image171.png', 'image172.png', 'image173.png', 'image174.png', 'image175.png', 'image177.png', 'image178.png', 'image179.png', 'image180.png', 'image181.png', 'image182.png', 'image184.png', 'image185.png', 'image186.png', 'image187.png', 'image188.png', 'image189.png', 'image19.png', 'image190.png', 'image191.png', 'image192.png', 'image193.png', 'image194.png', 'image195.png', 'image196.png', 'image197.png', 'image199.png', 'image20.png', 'image200.png', 'image201.png', 'image202.png', 'image203.png', 'image204.png', 'image205.png', 'image206.png', 'image207.png', 'image208.png', 'image209.png', 'image210.png', 'image211.png', 'image214.png', 'image215.png', 'image216.png', 'image217.png', 'image218.png', 'image22.png', 'image221.png', 'image222.png', 'image223.png', 'image224.png', 'image225.png', 'image227.png', 'image228.png', 'image230.png', 'image232.png', 'image237.png', 'image238.png', 'image239.png', 'image241.png', 'image243.png', 'image244.png', 'image245.png', 'image247.png', 'image248.png', 'image249.png', 'image250.png', 'image251.png', 'image252.png', 'image253.png', 'image255.png', 'image256.png', 'image257.png', 'image26.png', 'image260.png', 'image261.png', 'image263.png', 'image265.png', 'image267.png', 'image268.png', 'image27.png', 'image273.png', 'image280.png', 'image281.png', 'image289.png', 'image291.png', 'image294.png', 'image296.png', 'image297.png', 'image298.png', 'image3.png', 'image30.png', 'image300.png', 'image304.png', 'image305.png', 'image306.png', 'image308.png', 'image309.png', 'image31.png', 'image311.png', 'image312.png', 'image313.png', 'image315.png', 'image316.png', 'image317.png', 'image319.png', 'image320.png', 'image321.png', 'image322.png', 'image323.png', 'image325.png', 'image326.png', 'image327.png', 'image328.png', 'image329.png', 'image330.png', 'image332.png', 'image333.png', 'image335.png', 'image336.png', 'image341.png', 'image342.png', 'image345.png', 'image346.png', 'image347.png', 'image348.png', 'image35.png', 'image350.png', 'image351.png', 'image352.png', 'image353.png', 'image357.png', 'image358.png', 'image359.png', 'image36.png', 'image360.png', 'image362.png', 'image363.png', 'image364.png', 'image365.png', 'image367.png', 'image369.png', 'image372.png', 'image373.png', 'image376.png', 'image377.png', 'image378.png', 'image379.png', 'image38.png', 'image381.png', 'image383.png', 'image384.png', 'image385.png', 'image387.png', 'image388.png', 'image389.png', 'image39.png', 'image390.png', 'image391.png', 'image393.png', 'image395.png', 'image396.png', 'image397.png', 'image4.png', 'image40.png', 'image400.png', 'image401.png', 'image404.png', 'image405.png', 'image407.png', 'image408.png', 'image409.png', 'image41.png', 'image410.png', 'image411.png', 'image414.png', 'image415.png', 'image416.png', 'image417.png', 'image418.png', 'image419.png', 'image42.png', 'image423.png', 'image424.png', 'image425.png', 'image426.png', 'image427.png', 'image428.png', 'image429.png', 'image43.png', 'image430.png', 'image431.png', 'image432.png', 'image433.png', 'image434.png', 'image435.png', 'image437.png', 'image438.png', 'image439.png', 'image440.png', 'image441.png', 'image444.png', 'image447.png', 'image448.png', 'image449.png', 'image450.png', 'image451.png', 'image454.png', 'image455.png', 'image456.png', 'image457.png', 'image458.png', 'image459.png', 'image460.png', 'image463.png', 'image464.png', 'image468.png', 'image469.png', 'image47.png', 'image470.png', 'image471.png', 'image472.png', 'image476.png', 'image478.png', 'image479.png', 'image480.png', 'image482.png', 'image486.png', 'image488.png', 'image49.png', 'image490.png', 'image491.png', 'image493.png', 'image494.png', 'image495.png', 'image496.png', 'image499.png', 'image5.png', 'image50.png', 'image500.png', 'image502.png', 'image504.png', 'image505.png', 'image506.png', 'image507.png', 'image512.png', 'image516.png', 'image519.png', 'image52.png', 'image520.png', 'image522.png', 'image523.png', 'image524.png', 'image528.png', 'image529.png', 'image53.png', 'image530.png', 'image531.png', 'image533.png', 'image54.png', 'image544.png', 'image545.png', 'image547.png', 'image548.png', 'image549.png', 'image55.png', 'image550.png', 'image551.png', 'image554.png', 'image557.png', 'image559.png', 'image56.png', 'image560.png', 'image564.png', 'image565.png', 'image57.png', 'image573.png', 'image574.png', 'image575.png', 'image577.png', 'image579.png', 'image58.png', 'image580.png', 'image582.png', 'image584.png', 'image585.png', 'image587.png', 'image588.png', 'image59.png', 'image590.png', 'image591.png', 'image592.png', 'image593.png', 'image594.png', 'image595.png', 'image597.png', 'image598.png', 'image599.png', 'image6.png', 'image60.png', 'image600.png', 'image602.png', 'image604.png', 'image605.png', 'image607.png', 'image609.png', 'image610.png', 'image613.png', 'image615.png', 'image616.png', 'image617.png', 'image619.png', 'image62.png', 'image620.png', 'image622.png', 'image624.png', 'image625.png', 'image626.png', 'image627.png', 'image628.png', 'image629.png', 'image63.png', 'image630.png', 'image631.png', 'image632.png', 'image633.png', 'image634.png', 'image635.png', 'image636.png', 'image638.png', 'image639.png', 'image64.png', 'image640.png', 'image643.png', 'image644.png', 'image645.png', 'image648.png', 'image650.png', 'image651.png', 'image652.png', 'image653.png', 'image654.png', 'image657.png', 'image658.png', 'image659.png', 'image66.png', 'image662.png', 'image664.png', 'image665.png', 'image666.png']\n",
            "Filtered Image Files: ['image657.png', 'image665.png', 'image663.png', 'image658.png', 'image666.png', 'image664.png', 'image655.png', 'image661.png', 'image659.png', 'image656.png', 'image631.png', 'image660.png', 'image662.png', 'image646.png', 'image630.png', 'image639.png', 'image648.png', 'image637.png', 'image635.png', 'image643.png', 'image640.png', 'image612.png', 'image654.png', 'image636.png', 'image624.png', 'image647.png', 'image644.png', 'image626.png', 'image667.png', 'image651.png', 'image65.png', 'image64.png', 'image627.png', 'image628.png', 'image641.png', 'image632.png', 'image649.png', 'image638.png', 'image653.png', 'image6.png', 'image652.png', 'image602.png', 'image633.png', 'image597.png', 'image642.png', 'image625.png', 'image615.png', 'image645.png', 'image608.png', 'image600.png', 'image623.png', 'image63.png', 'image66.png', 'image650.png', 'image629.png', 'image598.png', 'image596.png', 'image603.png', 'image668.png', 'image62.png', 'image606.png', 'image611.png', 'image568.png', 'image634.png', 'image622.png', 'image620.png', 'image614.png', 'image572.png', 'image583.png', 'image605.png', 'image621.png', 'image589.png', 'image61.png', 'image618.png', 'image580.png', 'image577.png', 'image590.png', 'image567.png', 'image59.png', 'image604.png', 'image573.png', 'image587.png', 'image569.png', 'image594.png', 'image58.png', 'image578.png', 'image609.png', 'image619.png', 'image579.png', 'image581.png', 'image617.png', 'image595.png', 'image566.png', 'image584.png', 'image610.png', 'image582.png', 'image560.png', 'image593.png', 'image57.png', 'image613.png', 'image599.png', 'image616.png', 'image588.png', 'image571.png', 'image607.png', 'image558.png', 'image56.png', 'image542.png', 'image60.png', 'image562.png', 'image585.png', 'image546.png', 'image564.png', 'image55.png', 'image575.png', 'image586.png', 'image601.png', 'image570.png', 'image592.png', 'image550.png', 'image545.png', 'image538.png', 'image561.png', 'image565.png', 'image557.png', 'image555.png', 'image547.png', 'image576.png', 'image554.png', 'image534.png', 'image535.png', 'image563.png', 'image543.png', 'image553.png', 'image559.png', 'image521.png', 'image540.png', 'image591.png', 'image539.png', 'image523.png', 'image544.png', 'image512.png', 'image506.png', 'image532.png', 'image514.png', 'image516.png', 'image527.png', 'image518.png', 'image531.png', 'image54.png', 'image525.png', 'image551.png', 'image552.png', 'image574.png', 'image51.png', 'image520.png', 'image489.png', 'image536.png', 'image541.png', 'image52.png', 'image549.png', 'image548.png', 'image510.png', 'image513.png', 'image537.png', 'image530.png', 'image53.png', 'image507.png', 'image464.png', 'image494.png', 'image5.png', 'image500.png', 'image519.png', 'image529.png', 'image498.png', 'image522.png', 'image493.png', 'image487.png', 'image50.png', 'image485.png', 'image524.png', 'image495.png', 'image509.png', 'image481.png', 'image526.png', 'image511.png', 'image501.png', 'image484.png', 'image490.png', 'image488.png', 'image505.png', 'image556.png', 'image508.png', 'image515.png', 'image492.png', 'image502.png', 'image528.png', 'image517.png', 'image460.png', 'image48.png', 'image478.png', 'image454.png', 'image459.png', 'image451.png', 'image483.png', 'image496.png', 'image480.png', 'image477.png', 'image482.png', 'image491.png', 'image467.png', 'image486.png', 'image456.png', 'image465.png', 'image472.png', 'image438.png', 'image439.png', 'image49.png', 'image433.png', 'image504.png', 'image440.png', 'image503.png', 'image463.png', 'image457.png', 'image476.png', 'image458.png', 'image468.png', 'image466.png', 'image479.png', 'image533.png', 'image497.png', 'image46.png', 'image447.png', 'image461.png', 'image442.png', 'image475.png', 'image469.png', 'image446.png', 'image450.png', 'image436.png', 'image455.png', 'image437.png', 'image474.png', 'image47.png', 'image471.png', 'image426.png', 'image473.png', 'image413.png', 'image470.png', 'image462.png', 'image41.png', 'image448.png', 'image434.png', 'image407.png', 'image452.png', 'image499.png', 'image44.png', 'image445.png', 'image415.png', 'image449.png', 'image432.png', 'image389.png', 'image453.png', 'image419.png', 'image395.png', 'image416.png', 'image422.png', 'image418.png', 'image411.png', 'image410.png', 'image424.png', 'image428.png', 'image444.png', 'image441.png', 'image4.png', 'image435.png', 'image431.png', 'image43.png', 'image412.png', 'image387.png', 'image409.png', 'image393.png', 'image443.png', 'image421.png', 'image430.png', 'image425.png', 'image396.png', 'image392.png', 'image45.png', 'image42.png', 'image420.png', 'image40.png', 'image386.png', 'image427.png', 'image423.png', 'image35.png', 'image363.png', 'image358.png', 'image401.png', 'image391.png', 'image383.png', 'image376.png', 'image360.png', 'image414.png', 'image377.png', 'image408.png', 'image417.png', 'image390.png', 'image373.png', 'image380.png', 'image379.png', 'image37.png', 'image362.png', 'image39.png', 'image429.png', 'image397.png', 'image394.png', 'image404.png', 'image38.png', 'image398.png', 'image400.png', 'image355.png', 'image333.png', 'image375.png', 'image405.png', 'image36.png', 'image352.png', 'image382.png', 'image403.png', 'image388.png', 'image372.png', 'image381.png', 'image378.png', 'image370.png', 'image385.png', 'image330.png', 'image364.png', 'image406.png', 'image374.png', 'image349.png', 'image369.png', 'image368.png', 'image371.png', 'image321.png', 'image366.png', 'image365.png', 'image305.png', 'image402.png', 'image345.png', 'image384.png', 'image367.png', 'image324.png', 'image350.png', 'image335.png', 'image336.png', 'image359.png', 'image307.png', 'image312.png', 'image325.png', 'image30.png', 'image310.png', 'image341.png', 'image361.png', 'image301.png', 'image304.png', 'image34.png', 'image346.png', 'image320.png', 'image314.png', 'image308.png', 'image311.png', 'image399.png', 'image357.png', 'image339.png', 'image351.png', 'image313.png', 'image326.png', 'image353.png', 'image343.png', 'image354.png', 'image348.png', 'image334.png', 'image332.png', 'image356.png', 'image292.png', 'image342.png', 'image296.png', 'image329.png', 'image297.png', 'image306.png', 'image344.png', 'image318.png', 'image331.png', 'image287.png', 'image317.png', 'image340.png', 'image319.png', 'image337.png', 'image338.png', 'image309.png', 'image286.png', 'image293.png', 'image328.png', 'image316.png', 'image347.png', 'image298.png', 'image264.png', 'image31.png', 'image33.png', 'image290.png', 'image315.png', 'image282.png', 'image323.png', 'image327.png', 'image29.png', 'image291.png', 'image278.png', 'image3.png', 'image271.png', 'image27.png', 'image267.png', 'image299.png', 'image288.png', 'image268.png', 'image275.png', 'image273.png', 'image300.png', 'image322.png', 'image274.png', 'image279.png', 'image295.png', 'image246.png', 'image270.png', 'image277.png', 'image289.png', 'image303.png', 'image261.png', 'image262.png', 'image285.png', 'image284.png', 'image283.png', 'image302.png', 'image263.png', 'image281.png', 'image28.png', 'image25.png', 'image233.png', 'image266.png', 'image234.png', 'image244.png', 'image243.png', 'image250.png', 'image213.png', 'image294.png', 'image276.png', 'image241.png', 'image251.png', 'image260.png', 'image235.png', 'image257.png', 'image255.png', 'image269.png', 'image249.png', 'image237.png', 'image229.png', 'image242.png', 'image254.png', 'image209.png', 'image258.png', 'image245.png', 'image253.png', 'image247.png', 'image248.png', 'image259.png', 'image280.png', 'image231.png', 'image210.png', 'image272.png', 'image227.png', 'image197.png', 'image211.png', 'image216.png', 'image219.png', 'image206.png', 'image217.png', 'image196.png', 'image200.png', 'image23.png', 'image191.png', 'image21.png', 'image226.png', 'image190.png', 'image230.png', 'image212.png', 'image256.png', 'image198.png', 'image220.png', 'image221.png', 'image193.png', 'image195.png', 'image232.png', 'image24.png', 'image239.png', 'image22.png', 'image214.png', 'image203.png', 'image170.png', 'image228.png', 'image2.png', 'image202.png', 'image265.png', 'image179.png', 'image225.png', 'image224.png', 'image223.png', 'image222.png', 'image252.png', 'image176.png', 'image153.png', 'image208.png', 'image192.png', 'image236.png', 'image184.png', 'image205.png', 'image177.png', 'image240.png', 'image158.png', 'image20.png', 'image238.png', 'image194.png', 'image26.png', 'image187.png', 'image199.png', 'image215.png', 'image201.png', 'image218.png', 'image19.png', 'image145.png', 'image207.png', 'image161.png', 'image183.png', 'image130.png', 'image172.png', 'image14.png', 'image150.png', 'image18.png', 'image17.png', 'image146.png', 'image160.png', 'image173.png', 'image155.png', 'image182.png', 'image15.png', 'image140.png', 'image175.png', 'image171.png', 'image180.png', 'image185.png', 'image157.png', 'image156.png', 'image174.png', 'image204.png', 'image16.png', 'image168.png', 'image186.png', 'image166.png', 'image178.png', 'image119.png', 'image134.png', 'image188.png', 'image181.png', 'image132.png', 'image149.png', 'image135.png', 'image147.png', 'image165.png', 'image144.png', 'image154.png', 'image162.png', 'image148.png', 'image169.png', 'image159.png', 'image139.png', 'image151.png', 'image12.png', 'image13.png', 'image143.png', 'image138.png', 'image129.png', 'image152.png', 'image131.png', 'image11.png', 'image164.png', 'image142.png', 'image136.png', 'image141.png', 'image163.png', 'image100.png', 'image189.png', 'image127.png', 'image111.png', 'image104.png', 'image103.png', 'image137.png', 'image102.png', 'image108.png', 'image123.png', 'image110.png', 'image1.png', 'image124.png', 'image112.png', 'image113.png', 'image122.png', 'image117.png', 'image120.png', 'image107.png', 'image114.png', 'image116.png', 'image118.png', 'image109.png', 'image10.png', 'image121.png', 'image106.png', 'image133.png', 'image126.png', 'image167.png', 'image128.png', 'image115.png', 'image105.png', 'image101.png', 'image125.png']\n",
            "Filtered Prompt Files: ['image110.txt', 'image115.txt', 'image104.txt', 'image101.txt', 'image106.txt', 'image113.txt', 'image116.txt', 'image103.txt', 'image100.txt', 'image111.txt', 'image105.txt', 'image114.txt', 'image102.txt', 'image1.txt', 'image11.txt', 'image109.txt', 'image107.txt', 'image108.txt', 'image10.txt', 'image112.txt', 'image139.txt', 'image137.txt', 'image136.txt', 'image126.txt', 'image125.txt', 'image119.txt', 'image124.txt', 'image142.txt', 'image123.txt', 'image132.txt', 'image13.txt', 'image129.txt', 'image133.txt', 'image130.txt', 'image122.txt', 'image141.txt', 'image131.txt', 'image134.txt', 'image12.txt', 'image140.txt', 'image143.txt', 'image135.txt', 'image138.txt', 'image128.txt', 'image118.txt', 'image144.txt', 'image121.txt', 'image120.txt', 'image127.txt', 'image117.txt', 'image14.txt', 'image164.txt', 'image15.txt', 'image150.txt', 'image151.txt', 'image16.txt', 'image169.txt', 'image170.txt', 'image168.txt', 'image146.txt', 'image17.txt', 'image152.txt', 'image161.txt', 'image145.txt', 'image156.txt', 'image157.txt', 'image158.txt', 'image162.txt', 'image154.txt', 'image165.txt', 'image159.txt', 'image153.txt', 'image148.txt', 'image149.txt', 'image155.txt', 'image172.txt', 'image171.txt', 'image166.txt', 'image160.txt', 'image163.txt', 'image147.txt', 'image167.txt', 'image182.txt', 'image198.txt', 'image186.txt', 'image173.txt', 'image181.txt', 'image191.txt', 'image189.txt', 'image199.txt', 'image175.txt', 'image19.txt', 'image190.txt', 'image195.txt', 'image180.txt', 'image184.txt', 'image193.txt', 'image183.txt', 'image185.txt', 'image192.txt', 'image188.txt', 'image197.txt', 'image187.txt', 'image179.txt', 'image20.txt', 'image2.txt', 'image177.txt', 'image178.txt', 'image194.txt', 'image176.txt', 'image196.txt', 'image18.txt', 'image174.txt', 'image219.txt', 'image228.txt', 'image204.txt', 'image208.txt', 'image218.txt', 'image227.txt', 'image214.txt', 'image226.txt', 'image223.txt', 'image221.txt', 'image209.txt', 'image225.txt', 'image220.txt', 'image206.txt', 'image200.txt', 'image202.txt', 'image201.txt', 'image215.txt', 'image229.txt', 'image207.txt', 'image222.txt', 'image217.txt', 'image216.txt', 'image21.txt', 'image22.txt', 'image211.txt', 'image224.txt', 'image205.txt', 'image212.txt', 'image213.txt', 'image210.txt', 'image203.txt', 'image242.txt', 'image254.txt', 'image238.txt', 'image257.txt', 'image248.txt', 'image231.txt', 'image25.txt', 'image252.txt', 'image249.txt', 'image234.txt', 'image232.txt', 'image23.txt', 'image256.txt', 'image241.txt', 'image235.txt', 'image251.txt', 'image245.txt', 'image240.txt', 'image233.txt', 'image244.txt', 'image230.txt', 'image250.txt', 'image24.txt', 'image247.txt', 'image236.txt', 'image255.txt', 'image243.txt', 'image237.txt', 'image253.txt', 'image239.txt', 'image246.txt', 'image26.txt', 'image261.txt', 'image278.txt', 'image285.txt', 'image276.txt', 'image287.txt', 'image269.txt', 'image259.txt', 'image260.txt', 'image279.txt', 'image263.txt', 'image271.txt', 'image286.txt', 'image281.txt', 'image265.txt', 'image275.txt', 'image268.txt', 'image273.txt', 'image258.txt', 'image270.txt', 'image282.txt', 'image28.txt', 'image264.txt', 'image284.txt', 'image262.txt', 'image27.txt', 'image266.txt', 'image272.txt', 'image267.txt', 'image277.txt', 'image274.txt', 'image283.txt', 'image280.txt', 'image314.txt', 'image298.txt', 'image309.txt', 'image311.txt', 'image316.txt', 'image307.txt', 'image304.txt', 'image30.txt', 'image313.txt', 'image300.txt', 'image305.txt', 'image29.txt', 'image3.txt', 'image297.txt', 'image310.txt', 'image288.txt', 'image308.txt', 'image293.txt', 'image303.txt', 'image31.txt', 'image315.txt', 'image296.txt', 'image292.txt', 'image294.txt', 'image289.txt', 'image299.txt', 'image306.txt', 'image290.txt', 'image301.txt', 'image291.txt', 'image302.txt', 'image312.txt', 'image295.txt', 'image334.txt', 'image323.txt', 'image344.txt', 'image339.txt', 'image330.txt', 'image341.txt', 'image347.txt', 'image332.txt', 'image34.txt', 'image331.txt', 'image322.txt', 'image328.txt', 'image319.txt', 'image337.txt', 'image326.txt', 'image333.txt', 'image324.txt', 'image317.txt', 'image33.txt', 'image325.txt', 'image335.txt', 'image342.txt', 'image329.txt', 'image343.txt', 'image346.txt', 'image336.txt', 'image321.txt', 'image345.txt', 'image340.txt', 'image318.txt', 'image327.txt', 'image320.txt', 'image338.txt', 'image361.txt', 'image366.txt', 'image367.txt', 'image348.txt', 'image36.txt', 'image35.txt', 'image351.txt', 'image357.txt', 'image353.txt', 'image364.txt', 'image375.txt', 'image362.txt', 'image350.txt', 'image368.txt', 'image354.txt', 'image356.txt', 'image358.txt', 'image352.txt', 'image373.txt', 'image369.txt', 'image363.txt', 'image37.txt', 'image370.txt', 'image372.txt', 'image359.txt', 'image349.txt', 'image374.txt', 'image371.txt', 'image355.txt', 'image360.txt', 'image365.txt', 'image400.txt', 'image376.txt', 'image398.txt', 'image379.txt', 'image388.txt', 'image395.txt', 'image38.txt', 'image386.txt', 'image390.txt', 'image383.txt', 'image396.txt', 'image39.txt', 'image394.txt', 'image392.txt', 'image387.txt', 'image40.txt', 'image382.txt', 'image397.txt', 'image393.txt', 'image399.txt', 'image389.txt', 'image380.txt', 'image4.txt', 'image378.txt', 'image391.txt', 'image381.txt', 'image385.txt', 'image384.txt', 'image377.txt', 'image41.txt', 'image421.txt', 'image411.txt', 'image404.txt', 'image415.txt', 'image408.txt', 'image403.txt', 'image416.txt', 'image417.txt', 'image420.txt', 'image42.txt', 'image402.txt', 'image406.txt', 'image418.txt', 'image407.txt', 'image405.txt', 'image422.txt', 'image419.txt', 'image409.txt', 'image410.txt', 'image414.txt', 'image413.txt', 'image412.txt', 'image401.txt', 'image430.txt', 'image439.txt', 'image438.txt', 'image424.txt', 'image431.txt', 'image434.txt', 'image442.txt', 'image43.txt', 'image427.txt', 'image426.txt', 'image435.txt', 'image425.txt', 'image436.txt', 'image432.txt', 'image437.txt', 'image440.txt', 'image44.txt', 'image428.txt', 'image433.txt', 'image441.txt', 'image429.txt', 'image443.txt', 'image423.txt', 'image446.txt', 'image452.txt', 'image463.txt', 'image461.txt', 'image459.txt', 'image457.txt', 'image454.txt', 'image458.txt', 'image455.txt', 'image46.txt', 'image464.txt', 'image453.txt', 'image447.txt', 'image445.txt', 'image448.txt', 'image451.txt', 'image450.txt', 'image462.txt', 'image449.txt', 'image460.txt', 'image456.txt', 'image45.txt', 'image444.txt', 'image474.txt', 'image483.txt', 'image466.txt', 'image484.txt', 'image472.txt', 'image473.txt', 'image468.txt', 'image467.txt', 'image479.txt', 'image470.txt', 'image476.txt', 'image471.txt', 'image482.txt', 'image477.txt', 'image475.txt', 'image486.txt', 'image478.txt', 'image481.txt', 'image469.txt', 'image480.txt', 'image465.txt', 'image485.txt', 'image48.txt', 'image47.txt', 'image490.txt', 'image505.txt', 'image494.txt', 'image496.txt', 'image491.txt', 'image501.txt', 'image492.txt', 'image497.txt', 'image488.txt', 'image503.txt', 'image502.txt', 'image493.txt', 'image495.txt', 'image489.txt', 'image49.txt', 'image498.txt', 'image499.txt', 'image500.txt', 'image506.txt', 'image487.txt', 'image5.txt', 'image504.txt', 'image50.txt', 'image523.txt', 'image507.txt', 'image513.txt', 'image511.txt', 'image515.txt', 'image522.txt', 'image524.txt', 'image516.txt', 'image521.txt', 'image510.txt', 'image51.txt', 'image528.txt', 'image509.txt', 'image518.txt', 'image517.txt', 'image52.txt', 'image527.txt', 'image514.txt', 'image525.txt', 'image508.txt', 'image519.txt', 'image520.txt', 'image526.txt', 'image512.txt', 'image54.txt', 'image548.txt', 'image537.txt', 'image534.txt', 'image546.txt', 'image543.txt', 'image530.txt', 'image542.txt', 'image549.txt', 'image536.txt', 'image533.txt', 'image544.txt', 'image535.txt', 'image541.txt', 'image529.txt', 'image532.txt', 'image531.txt', 'image545.txt', 'image540.txt', 'image539.txt', 'image53.txt', 'image538.txt', 'image547.txt', 'image550.txt', 'image56.txt', 'image558.txt', 'image559.txt', 'image551.txt', 'image568.txt', 'image552.txt', 'image554.txt', 'image570.txt', 'image555.txt', 'image55.txt', 'image569.txt', 'image557.txt', 'image563.txt', 'image560.txt', 'image564.txt', 'image562.txt', 'image567.txt', 'image565.txt', 'image566.txt', 'image561.txt', 'image556.txt', 'image553.txt', 'image57.txt', 'image577.txt', 'image587.txt', 'image572.txt', 'image584.txt', 'image586.txt', 'image576.txt', 'image580.txt', 'image582.txt', 'image585.txt', 'image581.txt', 'image59.txt', 'image571.txt', 'image583.txt', 'image589.txt', 'image58.txt', 'image591.txt', 'image574.txt', 'image573.txt', 'image590.txt', 'image575.txt', 'image579.txt', 'image588.txt', 'image578.txt', 'image596.txt', 'image611.txt', 'image604.txt', 'image608.txt', 'image598.txt', 'image592.txt', 'image607.txt', 'image610.txt', 'image603.txt', 'image609.txt', 'image60.txt', 'image6.txt', 'image600.txt', 'image602.txt', 'image593.txt', 'image595.txt', 'image597.txt', 'image605.txt', 'image601.txt', 'image61.txt', 'image606.txt', 'image594.txt', 'image599.txt', 'image625.txt', 'image628.txt', 'image618.txt', 'image624.txt', 'image626.txt', 'image630.txt', 'image627.txt', 'image629.txt', 'image631.txt', 'image622.txt', 'image613.txt', 'image614.txt', 'image633.txt', 'image632.txt', 'image621.txt', 'image620.txt', 'image612.txt', 'image617.txt', 'image619.txt', 'image615.txt', 'image623.txt', 'image616.txt', 'image63.txt', 'image62.txt', 'image635.txt', 'image643.txt', 'image640.txt', 'image646.txt', 'image644.txt', 'image653.txt', 'image641.txt', 'image65.txt', 'image642.txt', 'image638.txt', 'image648.txt', 'image645.txt', 'image64.txt', 'image634.txt', 'image636.txt', 'image637.txt', 'image647.txt', 'image652.txt', 'image649.txt', 'image651.txt', 'image639.txt', 'image650.txt', 'image654.txt', 'image658.txt', 'image668.txt', 'image663.txt', 'image66.txt', 'image662.txt', 'image656.txt', 'image666.txt', 'image667.txt', 'image665.txt', 'image657.txt', 'image664.txt', 'image655.txt', 'image661.txt', 'image660.txt', 'image659.txt']\n",
            "Number of Sketch Files: 631\n",
            "Number of Image Files: 631\n",
            "Number of Prompt Files: 631\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from google.colab import drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# Function to get base names (without file extensions)\n",
        "def get_base_names(file_list):\n",
        "    return {os.path.splitext(file)[0] for file in file_list}\n",
        "\n",
        "# List files in each folder\n",
        "sketch_files = os.listdir(sketch_folder)\n",
        "image_files = os.listdir(image_folder)\n",
        "prompt_files = os.listdir(prompt_folder)\n",
        "\n",
        "# Get base names (i.e., file names without extensions)\n",
        "sketch_base_names = get_base_names(sketch_files)\n",
        "image_base_names = get_base_names(image_files)\n",
        "prompt_base_names = get_base_names(prompt_files)\n",
        "\n",
        "# Find common base names across all three folders\n",
        "common_base_names = sketch_base_names.intersection(image_base_names, prompt_base_names)\n",
        "\n",
        "# Filter files in each folder that match the common base names\n",
        "sketch_files_filtered = [file for file in sketch_files if os.path.splitext(file)[0] in common_base_names]\n",
        "image_files_filtered = [file for file in image_files if os.path.splitext(file)[0] in common_base_names]\n",
        "prompt_files_filtered = [file for file in prompt_files if os.path.splitext(file)[0] in common_base_names]\n",
        "\n",
        "# Display the filtered file names\n",
        "print(\"Filtered Sketch Files:\", sketch_files_filtered)\n",
        "print(\"Filtered Image Files:\", image_files_filtered)\n",
        "print(\"Filtered Prompt Files:\", prompt_files_filtered)\n",
        "\n",
        "# Store the filtered files in respective variables\n",
        "sketch_files = sketch_files_filtered\n",
        "image_files = image_files_filtered\n",
        "prompt_files = prompt_files_filtered\n",
        "\n",
        "print(\"Number of Sketch Files:\", len(sketch_files))\n",
        "print(\"Number of Image Files:\", len(image_files))\n",
        "print(\"Number of Prompt Files:\", len(prompt_files))\n",
        "\n",
        "# Initialize dataset and dataloader with transformations\n",
        "dataset = SketchToImageDataset(sketch_folder, image_folder, prompt_folder, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Reasoning:\n",
        "# - Initializing the dataset instance and using DataLoader to batch data and shuffle it.\n",
        "# - Batching is necessary for efficient GPU processing, and shuffling adds randomness for better training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZYe90AnsuAS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758,
          "referenced_widgets": [
            "5af9a0b8fc05443bafbb9dbf67107d58",
            "1a7aa53aaf8a48c3ac382f4334983f0d",
            "c64837a14f0e4e43a487bcb1479a1547",
            "7715c1108dd34adab8269b6559e2f9c0",
            "8761dee1f9b342d681f09ba5db9b6742",
            "abb18b968dc64ae5a189b23a3e77cdab",
            "d2692cc333fc4b81b5efa86d782df898",
            "99420ca8ae1a40668d4d92c24c28e872",
            "3d3cdaaf155d4e2086a5e1fc9c653226",
            "b75a7ec9927b4e66ba93a8df043c5979",
            "3c1aa041a9b64e509fda33da939cfa25",
            "d04dfa55b0cd423491dc2f9a0140066e",
            "6d676c139d6e4bbfa72eddcb56117f9a",
            "5d1e1c469b85487dac79eac01df09fde",
            "42f4e526a57a4051a45023b551025873",
            "bc3bcaa6bbb6410f8687c39c4aa3ce0e",
            "17d2aaf8f6f746558c5ab84d5df8aec9",
            "05fedefbfd86470e9b13cc2857e665a3",
            "32154364f98844a1a93574b7debd7083",
            "de812259916545c19d91e41b9323056b",
            "28fcedb3b1fe427a9b0d619c28482de6",
            "5a8b3698da1e42fa9e91448ab6d27258",
            "13f908051d2b416fbf10e21cf79baab1",
            "56330b139b124cf0871d3ddbb2dd9b50",
            "4dd540b7c7a7479f8b688b5d87085a18",
            "e8cf0232c6854ce3a6adab4dcb350446",
            "4475f88bc7c5418aa89b32787eccf1fd",
            "fd2a66677ce54c8f9792b7db4d703a3b",
            "1f75efc6175d468481f6c7806b840dd0",
            "cf188c17ee5142e2b28075a1a0aff304",
            "9ba17408358a4be393514cc155a71e87",
            "510449a0ea1c48e7aa4649c4c0364da1",
            "77aeb3a4f9894121812d96073f44a141",
            "ef27ffeb5f3d429485d376658a4032ca",
            "2e94d2d583a94cb783e86ffc923be868",
            "e5c949feefd141c1ba987eea153fb6fd",
            "e496314fe0bb4cd7a27c7a56426b8dcf",
            "b8c2a8fa74654e4da153f64b2518e13e",
            "f9a95f0bcbbe463d891c72db242ddcdf",
            "2101850edd9244aea5f86b243b156fe7",
            "cdc144e8192c4138bef01a1e223d0274",
            "7eb2eeac910840e29c248f43ba6dde3b",
            "0f9fb2231cfd409ea3a3b90c624bb397",
            "3dbb67d76bde46be994d0ab97c0900e4",
            "0da5f2d1e7ae405ba2321a74091a5e47",
            "83cd3e5f4a224afd98e08213750d0a24",
            "673619c4850c48b199841817183f2c19",
            "62748d3f85c24ab7b9ce3179a02ca325",
            "56f46d27d04141ab806f46ae1dacfd15",
            "5a31d62c3d704d0c845e3c48b693cd76",
            "9884bf9762f64e6191422fc2d2d0077e",
            "e7a6061f095b497fbad23815e09a2dde",
            "bccbb605807d4ee1b41314f632483ba6",
            "eb2bafcbcaf04787b1608c5bac3cac19",
            "06bd1486d1b0499dbb7f56d2b06fe30c",
            "22960b20336a4c3b867988ca1f1d232a",
            "da6c64a9affd4997935ff98a26cdc4a4",
            "12ff6cb95288405189782621d5dea0a9",
            "4acf5198bb2a4722bb67c16015c210e4",
            "230d600f64f54f1eaaaa600a3b89c471",
            "8b4caf99947e44159169bdecfb50edea",
            "c5a293cc3ccd4ece949ddb6b16a19df9",
            "70743e7af2fd4215957889434899bde5",
            "39a5b7cfaffe4dd5b206e29935bcb6e4",
            "11807a9968bc4b7e9d6eeba3e0ee576e",
            "0ebfad027fe247f6af0eece055c9f47d",
            "562d4bfd65c04c618a1d15d268bed945",
            "843565eb179c4d73a83975f723b2371a",
            "5a7e273fb33d4b388a7881280d8a090e",
            "0e9ffd1e62114a1892aada0b072d6c76",
            "d4b734b506f3463eae346f01f424ac58",
            "969b60f82a354ba28d155baee293c255",
            "5f523d655bed4508be6de70a907fa9f8",
            "22441075dbd84f6c900c2295d5c71f92",
            "03fe68b9f32445c2b7de6dc316482e49",
            "490d40c726004b2a8f6d281df4c9ae31",
            "31559917ad99484592e1d400a8de4db4",
            "7023d3adf6c041829fb2134873554938",
            "69c0f836e83b488faf9d043503449f01",
            "d8bad9ea6a2342f3b2899f561bd4d290",
            "6c391e2118a44e09a969a7f7d2a7a3fa",
            "cac7c642af8a4f539d350451aa233722",
            "5525a020c7154a959964f7b076488357",
            "5d4f717ae245446b8294c56c900a6598",
            "eea05ac0d4a74cfebce3ff925120e283",
            "1bbce83811b94e3aa88ada564c20d73d",
            "455cfdb319134fc6bd915c31615e2ad9",
            "01e9755e67fa41be9f13d2d4524c2c4d",
            "2c978bc546d64b8cb8798c1f3fc89aeb",
            "2de860b3966444bfb087d194f0f610db",
            "dfd561faafac42698f9b61064042e896",
            "a1682fb6d1b641a7ba716483ccb4ffda",
            "23160b0f0dc9404892e4d8478787c461",
            "bea00dae05484f938d993a78ab9e50f0",
            "3443be8e346d42bd9bedb9cc84de0b55",
            "b3d2392382c94dfab46dbbf1e70dc11f",
            "41a32bcf8000456ab34e5ceb372f1e26",
            "857ae2a7015a4bc2ac4245afcd10a4e5",
            "77de45f8681a4563a02c376d62288561",
            "a2707688a4ea40fca46db2a9d1a5dea2",
            "0d9076ea15c346f59da4867bbb8b6035",
            "5bf6a4f560dd434284eba5ab65974a41",
            "8935c1c741024ce98ea4fef2d57cfaae",
            "d1537c303797496fbad19202c78acaf6",
            "fef115a939cc433a81d51f5951186197",
            "184f72957c324d75b0039f0060c26793",
            "94994cbbce3146b198dcdbcd47b31566",
            "fdf62800f78443f78aaabaa56b2c1619",
            "86d9d138c9a845f5a26a7d5974ed548b",
            "27bf4fec18cd42b88cae6570b5993859",
            "f2f7281055fb453488f1c155f7bb3432",
            "0e2f34dc713240c28dd69b26d592c43c",
            "7551ae8dec1f4849a7f3d6254b1818e7",
            "b31d8fae3f08472e842cb8775c3236b6",
            "251de098ac5744ab9360dc5690e8a03f",
            "de58984a44c64634a2558af489d7aa70",
            "f85fe08ec3474bbaa2dd00aeec83cff8",
            "537f759bbcfb4340b46697742b71a61f",
            "023df8b8c986436182a7fb62fa00dc44",
            "92cf0f6e4b1142ada3c20e303b57cdf9",
            "faf9ef052bec4e8490b0bbfb6a7acf1c",
            "ca2a8ec229234e6fa161652a638e0523",
            "eed61e27f6ff4d9d81f0b04733978816",
            "789c6b192940440cb4d0de8a0397cb19",
            "275241564f4248a0a2dc36b4f5d79916",
            "59553f83a97c428d90d870e824a5161d",
            "b66ec366fd754fbe912750eb3187ee9f",
            "b5fa8184224641139ee7021a507c0ed7",
            "e115417e94314f2c881dcf341c1135da",
            "01e97aa7317e4c6cbf2a36d6fe7d6b9f",
            "6c01de2c792747d5a41f3f73daf95ca4",
            "24fb2092216d45eab43bbd1e48923ffb",
            "945386f05cee4fa3b938a9b599f7561a",
            "4e6a89e114f749839dd29a6956f45782",
            "fc9ee6559e8042a4b00c3b3aacd71891",
            "abdb36aed6e34c38acbb1d3065735576",
            "049f09d6eec640728d87b0e560ca7781",
            "fa971b74ac314087bf950965b228cec1",
            "84bfdfd0c277406dada5560117ee1243",
            "8d50572dc23549f99de9bb87b95e530a",
            "209c8165ea7e4e8ea861e556d3f28516",
            "e85eaf55d5fb4d6780235d25dd2cb09b",
            "2183a1dac672420cbc6956f9688c8abb",
            "e48fcd0886244127bb0c14ad4bb626e3",
            "4a06e78cd250429bbad59ad68eb2b3ac",
            "0c0817ade2b7457cbe418b2bb6114c09",
            "eb06f1b021e94c5da5f3fb48f280f681",
            "e32445e2d2454a34bb072855d6857a84",
            "3ffbd1d10bba431a85cc30fe34a41641",
            "35358f6ccb7042d2b58aac407b6cd440",
            "6212801c1c0f4365887d686725ded172",
            "25be8896b50643a2b19d55f904efbf8c",
            "1b6a9ab0c9c541319d12239c95e72704",
            "fc3fa5de9f384220bce886f42716e777",
            "42377cf44f974391a7b90f263879acac",
            "a14c5f0d195548aea3ac62b0340a5e18",
            "c890ef2b22b64f82974480734efbe9d5",
            "e9a4a7dc0b3544f7a300745e46f87525",
            "59029ed7eb3a4b78a23a4169727d566c",
            "bec11f4e707c42ea8e20186143fe2aeb",
            "8e02e5909cd8480e963f1a4d1f0a33a2",
            "d6ef8ff2b5574cd5ada2cec5942f76fc",
            "e50ae298d29043219fe8c7761d904863",
            "d0c094a5a5174a35b33d9e1bb052a71e",
            "af4e380a8a3b4761af7922be2e1e1c3a",
            "62b949c25e694a6bba6a118229ea4cfb",
            "8bbe9b1d5b824fe187209211ef682010",
            "46a8abcfa2084dc9a7f421ed0985dd43",
            "c0c18a88439e4d5eb4a9759cd1d5f814",
            "0eb92dcbb27a4f23ba9cd0da5fa95b65",
            "1d64f403a62a4b959bba730cdc6f0351",
            "e351ca432f4841a9b8ab3d4ad7ba1b41",
            "a970e9aa6b4f431197f1c1ea6b5ab764",
            "41d6b9aa81f347b8b1fee44aee63b8c3",
            "93ddb363b21242c5b9091e6a6084a69e",
            "e79411fb102c4ff18d2c88eefe2601d8",
            "c72dfbf67e5c4190b34413ef1e12f036",
            "a47890191b9146e3a1f41a5ad7dcc749",
            "2833c32fe6264928b7a9c9ff04e43b33",
            "05d8815c6a48408b8edf6237a4ba918e",
            "ad9aaa478bd544a7b42df5ddb128e9a2",
            "a361bc28776444a1a124e5c60ea4d84c",
            "91dc9b5c2d9d4f1c91f18e0e4757a89c",
            "26ce271167e34bd9837a56eb41fbc08b",
            "294583de0004422e805039d30fa94caa",
            "dffd445613e14dbfad06ba358130c614",
            "15c1af039e7648e0b8895756f1b16480",
            "1ee6ab668b894610ae8233684d35613a",
            "6c1157f514814fae9076e9d2942ebf4a",
            "fe76ce76d6ee4e1885389ff6a5fdf26c",
            "3816aeeec8f145efbc8aec3c95d57cce",
            "6798e243ef8e42538974f9c87b71063a",
            "d9fce0d96a9d4e7e9a440843ce537c5d",
            "b031e260204542b6925bf1b3ec6a5769",
            "daaa93b80b5e4c169e1a6aa71d25cda3",
            "097f9e49117e4ee98990a0c21985363e",
            "af0d765dcf394d04bf19e8b8dc5b46d4",
            "dee0b73f44764d89b1b8cfaeac56e3cb",
            "08457ab478f84666ac65f9a1025dc25b",
            "da05c48746e14d1e9cf528f5cd9bb930",
            "a55dd58544c3410782491fbb9fa36463",
            "7ac0a1b9dfd84485a7eaca671c8610cb",
            "e09ffc6c839e456685cf890c2261d1e1",
            "6eab28e3811544d09464bb3db81c973a",
            "de73542b288b4db08e852a5fe8208bf1",
            "23f6e9e148d34eab8c95a2a8d61d67fa",
            "2ca892d51a55401dbdeb328adbd42155",
            "109b8475eb9246da82dae34e221946bf",
            "28b7ba0103234e11941a5fd4af2afb6f",
            "aa60afb16aca4732b27a89eb7ed551dc",
            "5cdc44913aaa436f9865a044b28d24ab",
            "1c8056de84d346ed8629448eac453ce5",
            "76c0911cc04a41209864ace7e27b22e0",
            "2f0c402d4bcb4c50a4d8c942de27e8b7",
            "a78ba2ec0b2f4aa4a09b98ad73a288dd",
            "20127b92ccc241b7aa5e802b5772ae81",
            "77a10398c1924d8a834ba3f26627616b",
            "a61bbb7a18504b9c8fbf10603fc57028",
            "bc30203cd8ef48938c8dfe0fed8cb09a",
            "cc167425e7694c268dc12bdc9a424db9",
            "a968aa266de244d68cc45338b1aa62f8",
            "b2ee1825d92146fcbb3e69390b3db222",
            "0dbf6f16b384469283b40d5be01706c7",
            "0d4e4e52a589466ab1487289c847201b",
            "127c80d36bc24d45aa9132a7fb173a8f",
            "ad2b6e48025140b59be0e13524eb6034",
            "f9a03a59f3144a6e8e7b497b42c576c4",
            "7d08fcee21724076b37f432369f2525f",
            "01e3fef2b05a4a69abd43cd47beb8d54",
            "e883f8f23f8747d690cabb0da75b0736",
            "e3bb675ccd8944888e7af081f3bfaec9",
            "90577bbaf40445eeb0906a964314005c",
            "a24c088602c6424fa38012d33e868b00",
            "dd459f7dc892497ab76d3cf96f4a28aa",
            "5d2d6884c99f412fb45bf1bd729b8a39",
            "26bc8802722544d69efb0840a44595fb",
            "7651203542ad4f89a4665aa5373b3d31",
            "70a93aae91b84de0a75175c28afa4679",
            "a1ce251bdb20408c935622e7132060ac",
            "b5caf5f283084b0bbcc30b7ae139c7a1",
            "d7ed37e4781442ac9b2e1a4a640103c1",
            "4ad3ddada58c442ca26089723dbede0c"
          ]
        },
        "id": "JPvklYnG-He3",
        "outputId": "812d2cc6-314c-4b48-beb1-683a187b37ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5af9a0b8fc05443bafbb9dbf67107d58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d04dfa55b0cd423491dc2f9a0140066e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13f908051d2b416fbf10e21cf79baab1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef27ffeb5f3d429485d376658a4032ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0da5f2d1e7ae405ba2321a74091a5e47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/2.50G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22960b20336a4c3b867988ca1f1d232a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model_index.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "562d4bfd65c04c618a1d15d268bed945",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7023d3adf6c041829fb2134873554938",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.78G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c978bc546d64b8cb8798c1f3fc89aeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2707688a4ea40fca46db2a9d1a5dea2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "text_encoder/config.json:   0%|          | 0.00/565 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2f7281055fb453488f1c155f7bb3432",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca2a8ec229234e6fa161652a638e0523",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer/tokenizer_config.json:   0%|          | 0.00/737 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "945386f05cee4fa3b938a9b599f7561a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer/special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e48fcd0886244127bb0c14ad4bb626e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "text_encoder_2/config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42377cf44f974391a7b90f263879acac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "scheduler/scheduler_config.json:   0%|          | 0.00/479 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62b949c25e694a6bba6a118229ea4cfb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c72dfbf67e5c4190b34413ef1e12f036",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_2/special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ee6ab668b894610ae8233684d35613a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/10.3G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08457ab478f84666ac65f9a1025dc25b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_2/tokenizer_config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa60afb16aca4732b27a89eb7ed551dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "unet/config.json:   0%|          | 0.00/1.68k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a968aa266de244d68cc45338b1aa62f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90577bbaf40445eeb0906a964314005c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from diffusers import StableDiffusionXLControlNetPipeline, ControlNetModel,AutoencoderKL\n",
        "import torch\n",
        "\n",
        "# Define the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the base model (Stable Diffusion) and the ControlNet model\n",
        "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "controlnet = ControlNetModel.from_pretrained(\"xinsir/controlnet-scribble-sdxl-1.0\", torch_dtype=torch.float16)\n",
        "pipeline = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    controlnet=controlnet,\n",
        "    vae=vae,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# Move pipeline to device\n",
        "pipeline = pipeline.to(device)\n",
        "\n",
        "# Enable slicing to save memory\n",
        "pipeline.vae.enable_slicing()\n",
        "\n",
        "# Reasoning:\n",
        "# - By specifying `controlnet=controlnet`, we ensure that the pipeline receives all expected components.\n",
        "# - Moving to `float16` and enabling slicing helps reduce memory usage, making the pipeline more memory-efficient.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "b6cbd60a005a47579fc3dfe61524e980",
            "717fc2f185054b43b7e52e43697e97f5",
            "8af392ed2c0648349e03660f8b57a07f",
            "0d010e343c844257aa2e30b01bf9d0a7",
            "f78d8386b81a487b81cabc1b204369b3",
            "7eba9d12a12b48c29c8861f52ec2de93",
            "9b42611af4b74026baaecb969a85dcd1",
            "f560d4d5f6ed4245ad98d1c30cdc9f69",
            "1d80471fb38a42b38d1c26b3eaed1bdd",
            "5f66cbfe44144c2c8db29234b8fd5c84",
            "cf8b994c556a4fb4a51f2ef29e2a2fdd",
            "5817fb2a64e74410b26e8c37e3754726",
            "8cc54df5431145499e2200420e543b81",
            "71a9e9494c4541f5b38d5d090b730490",
            "31e8032dbd5e4a90979957ffa6f6c002",
            "0c00ad25b49a4d31b8596b7111ad5af3",
            "14881852ea964905932858987e401e62",
            "424ff9f4606a4b379147aa9ae3ae7a37",
            "87e5a97d7a884bd7a43a8a5109e827bc",
            "c78e91927eeb49da910e1c5d38fdeb09",
            "9797182166d3400bbe33092695ebb9a5",
            "609da650367f4eb284dd76246609f387",
            "724529a2a9bc455eb54ba521c2958dd3",
            "6d50236c70a34e7bb309a95647bed7ca",
            "8ffc7c14d3e14a46aa6688041baae8aa",
            "225de4f3a3df49e781d5bda483b8b165",
            "b9c9cf39e01d4944b32cbc12704478b9",
            "d1af48f50b2d4e4597a0a533b13b43ac",
            "a502d18a75ea4d91875ee43e3655d852",
            "cf53c4823f784f3197492808f7d255d6",
            "7ab72f6aa44f4d1995d87f9b65022415",
            "a07c3dec63bf4d7caf7664d1e6bd58c3",
            "b3ef42edf4634da9936fcd5b5509b514",
            "b2beed56912c4c1cb15a02b6705ead75",
            "6e47838e4a7c4b029aae4e46a3eed770",
            "cb20c491d6d44cd1872a762fbc26b0ed",
            "80c7d211cb294f43af846241818f8445",
            "5017a2228d8847e98e85e4ac58b80f94",
            "366034a52a4a421e869a942150aae645",
            "e6dd15ef979b4c4982176fbf3dae3d3a",
            "9b09e057a6894d98812d5941c75d7b32",
            "23bf412165384b8eba635cf75697cab0",
            "d21d359678ce41caac0be120eb3862e1",
            "09db989912774f888c3ebded60872a8e",
            "aa98614ec7b44763bb602692343d0737",
            "8e6dfcb9c8c642d4b3cc17f5a86bf2b2",
            "3a4822250711479fb2f54a648f795caf",
            "479e7a96e1cd45189aa4640e1ba8fece",
            "534ae29f3b2740f3ba8d787a468fc905",
            "dccfc313a0794460800e0e3be3f7c96d",
            "51f71c046fbb47fbba9153153536a289",
            "88bd0ff9f8784fd1a4ab5995fe915996",
            "eca2b1d049104f71878a211841f13df7",
            "e2b52271b41949d0bd21cbe3035e521d",
            "42dc301bb34c48b2895bc59296b270d3"
          ]
        },
        "id": "gyJOvzrot8fw",
        "outputId": "2161ada9-5302-4a7e-d654-e81eadffb5b6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6cbd60a005a47579fc3dfe61524e980",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5817fb2a64e74410b26e8c37e3754726",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/961k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "724529a2a9bc455eb54ba521c2958dd3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2beed56912c4c1cb15a02b6705ead75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa98614ec7b44763bb602692343d0737",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import CLIPTokenizer\n",
        "\n",
        "# Load tokenizer for text prompts\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "# Reasoning:\n",
        "# - Tokenizer processes text prompts, converting them into a form that the model can interpret.\n",
        "# - We use the CLIP tokenizer as it matches the text encoder in the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpWH_sgPuDBB",
        "outputId": "7fadf4cc-ee33-4f59-e5e9-beeb11edaf33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDVaYtRWuGwy"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "# Define the components to fine-tune\n",
        "params_to_optimize = list(pipeline.unet.parameters()) + list(pipeline.text_encoder.parameters()) + list(pipeline.controlnet.parameters())\n",
        "\n",
        "# Set up optimizer with the selected parameters\n",
        "optimizer = AdamW(params_to_optimize, lr=learning_rate)\n",
        "\n",
        "# Reasoning:\n",
        "# - Only the necessary components (UNet, Text Encoder, and ControlNet) are included in fine-tuning, optimizing memory usage and focus.\n",
        "# - AdamW is chosen due to its effectiveness in fine-tuning transformer-based architectures, like those in the pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvPXiCoFuLYc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZLflQNuV9Kr",
        "outputId": "5f2a2818-e271-4f83-f608-4d4da9b09943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   0%|          | 0/158 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image289.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image289.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image289.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image514.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image514.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image514.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image256.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image256.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image256.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image167.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image167.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image167.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   1%|          | 1/158 [00:10<27:08, 10.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image652.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image652.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image652.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image656.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image656.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image656.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image314.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image314.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image314.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image575.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image575.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image575.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   1%|▏         | 2/158 [00:20<25:54,  9.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image112.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image112.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image112.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image230.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image230.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image230.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image401.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image401.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image401.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image41.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image41.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image41.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   2%|▏         | 3/158 [00:30<26:37, 10.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image108.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image108.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image108.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image480.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image480.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image480.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image352.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image352.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image352.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image350.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image350.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image350.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   3%|▎         | 4/158 [00:40<26:00, 10.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image166.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image166.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image166.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image186.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image186.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image186.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image149.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image149.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image149.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image600.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image600.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image600.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   3%|▎         | 5/158 [00:50<25:46, 10.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image602.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image602.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image602.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image503.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image503.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image503.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image574.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image574.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image574.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image477.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image477.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image477.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   4%|▍         | 6/158 [01:00<25:21, 10.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image437.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image437.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image437.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image110.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image110.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image110.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image198.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image198.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image198.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image130.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image130.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image130.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   4%|▍         | 7/158 [01:10<24:53,  9.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image265.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image265.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image265.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image441.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image441.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image441.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image360.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image360.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image360.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image162.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image162.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image162.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   5%|▌         | 8/158 [01:20<24:43,  9.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image119.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image119.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image119.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image587.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image587.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image587.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image509.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image509.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image509.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image384.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image384.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image384.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   6%|▌         | 9/158 [01:29<24:29,  9.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image581.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image581.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image581.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image239.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image239.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image239.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image452.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image452.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image452.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image410.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image410.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image410.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   6%|▋         | 10/158 [01:40<24:46, 10.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image303.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image303.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image303.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image622.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image622.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image622.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image380.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image380.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image380.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image141.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image141.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image141.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   7%|▋         | 11/158 [01:50<24:33, 10.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image519.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image519.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image519.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image668.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image668.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image668.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image213.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image213.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image213.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image505.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image505.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image505.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   8%|▊         | 12/158 [02:00<24:27, 10.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image195.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image195.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image195.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image153.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image153.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image153.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image252.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image252.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image252.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image449.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image449.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image449.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   8%|▊         | 13/158 [02:10<24:11, 10.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image221.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image221.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image221.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image146.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image146.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image146.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image243.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image243.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image243.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image224.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image224.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image224.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   9%|▉         | 14/158 [02:20<24:22, 10.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image322.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image322.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image322.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image530.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image530.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image530.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image232.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image232.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image232.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image439.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image439.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image439.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   9%|▉         | 15/158 [02:31<24:16, 10.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image659.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image659.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image659.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image123.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image123.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image123.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image312.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image312.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image312.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image63.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image63.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image63.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  10%|█         | 16/158 [02:40<23:37,  9.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image296.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image296.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image296.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image402.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image402.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image402.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image595.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image595.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image595.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image450.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image450.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image450.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  11%|█         | 17/158 [02:49<22:59,  9.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image218.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image218.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image218.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image11.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image11.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image11.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image172.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image172.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image172.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image357.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image357.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image357.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  11%|█▏        | 18/158 [03:00<23:07,  9.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image433.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image433.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image433.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image598.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image598.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image598.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image335.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image335.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image335.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image463.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image463.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image463.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  12%|█▏        | 19/158 [03:10<23:17, 10.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image442.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image442.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image442.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image612.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image612.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image612.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image317.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image317.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image317.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image446.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image446.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image446.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  13%|█▎        | 20/158 [03:20<23:06, 10.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image494.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image494.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image494.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image525.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image525.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image525.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image206.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image206.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image206.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image419.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image419.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image419.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  13%|█▎        | 21/158 [03:30<22:43,  9.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image586.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image586.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image586.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image561.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image561.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image561.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image10.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image10.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image10.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image405.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image405.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image405.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  14%|█▍        | 22/158 [03:40<22:44, 10.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image25.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image25.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image25.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image383.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image383.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image383.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image51.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image51.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image51.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image583.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image583.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image583.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  15%|█▍        | 23/158 [03:50<22:46, 10.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image249.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image249.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image249.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image643.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image643.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image643.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image23.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image23.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image23.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image398.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image398.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image398.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  15%|█▌        | 24/158 [04:01<22:41, 10.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image44.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image44.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image44.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image420.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image420.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image420.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image597.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image597.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image597.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image226.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image226.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image226.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  16%|█▌        | 25/158 [04:10<22:16, 10.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image497.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image497.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image497.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image582.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image582.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image582.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image122.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image122.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image122.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image653.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image653.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image653.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  16%|█▋        | 26/158 [04:20<22:01, 10.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image406.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image406.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image406.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image588.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image588.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image588.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image526.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image526.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image526.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image370.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image370.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image370.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  17%|█▋        | 27/158 [04:30<21:44,  9.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image654.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image654.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image654.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image340.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image340.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image340.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image367.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image367.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image367.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image253.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image253.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image253.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  18%|█▊        | 28/158 [04:40<21:31,  9.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image393.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image393.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image393.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image142.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image142.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image142.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image293.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image293.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image293.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image610.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image610.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image610.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  18%|█▊        | 29/158 [04:50<21:11,  9.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image479.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image479.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image479.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image304.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image304.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image304.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image456.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image456.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image456.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image331.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image331.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image331.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  19%|█▉        | 30/158 [05:00<21:08,  9.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image325.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image325.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image325.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image16.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image16.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image16.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image348.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image348.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image348.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image620.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image620.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image620.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  20%|█▉        | 31/158 [05:09<20:52,  9.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image422.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image422.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image422.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image634.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image634.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image634.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image177.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image177.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image177.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image328.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image328.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image328.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  20%|██        | 32/158 [05:20<21:01, 10.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image572.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image572.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image572.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image36.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image36.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image36.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image260.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image260.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image260.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image511.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image511.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image511.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  21%|██        | 33/158 [05:30<20:49, 10.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image311.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image311.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image311.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image616.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image616.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image616.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image591.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image591.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image591.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image374.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image374.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image374.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  22%|██▏       | 34/158 [05:42<22:07, 10.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image53.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image53.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image53.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image523.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image523.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image523.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image64.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image64.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image64.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image154.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image154.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image154.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  22%|██▏       | 35/158 [05:56<23:40, 11.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image264.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image264.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image264.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image104.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image104.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image104.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image473.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image473.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image473.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image200.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image200.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image200.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  23%|██▎       | 36/158 [06:06<22:58, 11.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image24.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image24.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image24.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image124.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image124.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image124.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image185.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image185.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image185.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image453.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image453.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image453.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  23%|██▎       | 37/158 [06:19<23:28, 11.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image343.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image343.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image343.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image228.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image228.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image228.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image308.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image308.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image308.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image183.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image183.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image183.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  24%|██▍       | 38/158 [06:28<22:03, 11.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image506.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image506.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image506.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image363.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image363.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image363.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image187.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image187.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image187.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image201.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image201.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image201.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  25%|██▍       | 39/158 [06:38<21:07, 10.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image262.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image262.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image262.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image504.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image504.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image504.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image344.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image344.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image344.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image491.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image491.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image491.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  25%|██▌       | 40/158 [06:48<20:26, 10.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image263.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image263.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image263.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image38.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image38.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image38.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image660.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image660.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image660.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image544.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image544.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image544.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  26%|██▌       | 41/158 [06:59<20:43, 10.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image115.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image115.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image115.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image5.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image5.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image5.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image241.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image241.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image241.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image259.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image259.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image259.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  27%|██▋       | 42/158 [07:09<20:19, 10.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image237.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image237.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image237.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image500.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image500.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image500.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image397.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image397.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image397.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image599.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image599.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image599.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  27%|██▋       | 43/158 [07:19<19:31, 10.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image469.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image469.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image469.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image415.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image415.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image415.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image182.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image182.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image182.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image17.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image17.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image17.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  28%|██▊       | 44/158 [07:29<19:23, 10.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image444.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image444.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image444.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image215.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image215.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image215.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image664.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image664.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image664.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image411.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image411.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image411.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  28%|██▊       | 45/158 [07:39<19:09, 10.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image118.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image118.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image118.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image214.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image214.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image214.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image418.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image418.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image418.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image584.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image584.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image584.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  29%|██▉       | 46/158 [07:50<19:12, 10.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image164.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image164.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image164.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image245.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image245.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image245.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image173.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image173.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image173.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image191.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image191.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image191.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  30%|██▉       | 47/158 [08:00<19:07, 10.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image486.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image486.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image486.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image536.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image536.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image536.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image15.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image15.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image15.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image545.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image545.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image545.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  30%|███       | 48/158 [08:10<18:44, 10.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image225.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image225.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image225.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image338.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image338.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image338.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image618.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image618.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image618.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image290.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image290.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image290.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  31%|███       | 49/158 [08:20<18:22, 10.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image235.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image235.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image235.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image470.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image470.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image470.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image254.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image254.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image254.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image492.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image492.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image492.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  32%|███▏      | 50/158 [08:30<18:09, 10.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image403.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image403.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image403.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image425.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image425.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image425.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image454.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image454.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image454.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image542.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image542.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image542.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  32%|███▏      | 51/158 [08:40<17:56, 10.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image389.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image389.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image389.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image579.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image579.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image579.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image269.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image269.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image269.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image498.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image498.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image498.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  33%|███▎      | 52/158 [08:50<17:44, 10.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image129.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image129.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image129.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image138.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image138.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image138.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image533.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image533.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image533.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image279.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image279.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image279.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  34%|███▎      | 53/158 [09:00<17:30, 10.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image288.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image288.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image288.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image40.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image40.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image40.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image396.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image396.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image396.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image339.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image339.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image339.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  34%|███▍      | 54/158 [09:10<17:15,  9.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image299.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image299.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image299.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image306.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image306.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image306.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image202.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image202.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image202.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image321.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image321.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image321.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  35%|███▍      | 55/158 [09:20<17:04,  9.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image661.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image661.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image661.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image379.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image379.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image379.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image457.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image457.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image457.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image4.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image4.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image4.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  35%|███▌      | 56/158 [09:31<17:35, 10.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image246.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image246.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image246.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image300.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image300.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image300.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image569.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image569.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image569.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image567.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image567.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image567.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  36%|███▌      | 57/158 [09:41<17:03, 10.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image220.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image220.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image220.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image551.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image551.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image551.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image522.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image522.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image522.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image462.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image462.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image462.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  37%|███▋      | 58/158 [09:50<16:37,  9.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image609.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image609.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image609.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image416.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image416.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image416.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image56.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image56.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image56.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image292.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image292.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image292.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  37%|███▋      | 59/158 [10:00<16:29, 10.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image436.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image436.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image436.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image62.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image62.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image62.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image209.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image209.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image209.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image381.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image381.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image381.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  38%|███▊      | 60/158 [10:10<16:22, 10.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image644.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image644.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image644.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image282.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image282.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image282.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image65.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image65.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image65.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image629.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image629.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image629.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  39%|███▊      | 61/158 [10:21<16:26, 10.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image603.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image603.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image603.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image105.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image105.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image105.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image562.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image562.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image562.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image528.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image528.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image528.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  39%|███▉      | 62/158 [10:30<15:55,  9.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image626.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image626.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image626.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image181.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image181.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image181.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image270.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image270.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image270.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image596.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image596.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image596.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  40%|███▉      | 63/158 [10:40<15:31,  9.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image205.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image205.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image205.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image46.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image46.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image46.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image658.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image658.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image658.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image485.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image485.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image485.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  41%|████      | 64/158 [10:50<15:25,  9.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image55.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image55.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image55.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image577.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image577.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image577.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image156.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image156.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image156.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image395.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image395.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image395.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  41%|████      | 65/158 [11:00<15:16,  9.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image132.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image132.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image132.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image568.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image568.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image568.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image611.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image611.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image611.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image538.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image538.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image538.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  42%|████▏     | 66/158 [11:09<15:08,  9.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image529.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image529.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image529.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image346.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image346.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image346.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image387.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image387.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image387.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image189.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image189.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image189.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  42%|████▏     | 67/158 [11:19<14:58,  9.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image28.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image28.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image28.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image483.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image483.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image483.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image247.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image247.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image247.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image537.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image537.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image537.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  43%|████▎     | 68/158 [11:30<14:56,  9.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image193.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image193.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image193.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image66.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image66.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image66.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image413.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image413.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image413.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image594.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image594.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image594.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  44%|████▎     | 69/158 [11:40<14:56, 10.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image301.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image301.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image301.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image210.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image210.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image210.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image465.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image465.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image465.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image52.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image52.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image52.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  44%|████▍     | 70/158 [11:50<14:49, 10.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image475.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image475.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image475.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image531.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image531.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image531.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image646.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image646.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image646.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image665.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image665.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image665.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  45%|████▍     | 71/158 [12:00<14:34, 10.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image478.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image478.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image478.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image636.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image636.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image636.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image570.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image570.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image570.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image240.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image240.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image240.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  46%|████▌     | 72/158 [12:09<14:10,  9.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image61.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image61.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image61.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image266.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image266.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image266.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image140.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image140.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image140.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image133.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image133.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image133.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  46%|████▌     | 73/158 [12:20<14:05,  9.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image315.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image315.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image315.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image414.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image414.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image414.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image54.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image54.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image54.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image513.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image513.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image513.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  47%|████▋     | 74/158 [12:30<14:08, 10.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image502.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image502.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image502.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image135.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image135.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image135.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image484.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image484.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image484.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image438.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image438.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image438.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  47%|████▋     | 75/158 [12:41<14:07, 10.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image434.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image434.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image434.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image244.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image244.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image244.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image273.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image273.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image273.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image447.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image447.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image447.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  48%|████▊     | 76/158 [12:51<13:53, 10.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image194.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image194.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image194.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image440.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image440.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image440.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image165.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image165.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image165.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image277.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image277.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image277.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  49%|████▊     | 77/158 [13:00<13:25,  9.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image134.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image134.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image134.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image22.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image22.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image22.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image394.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image394.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image394.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image649.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image649.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image649.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  49%|████▉     | 78/158 [13:10<13:21, 10.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image50.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image50.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image50.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image639.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image639.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image639.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image126.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image126.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image126.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image550.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image550.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image550.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  50%|█████     | 79/158 [13:20<12:57,  9.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image229.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image229.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image229.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image222.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image222.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image222.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image284.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image284.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image284.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image144.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image144.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image144.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  51%|█████     | 80/158 [13:30<12:53,  9.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image21.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image21.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image21.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image14.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image14.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image14.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image107.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image107.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image107.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image287.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image287.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image287.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  51%|█████▏    | 81/158 [13:40<12:50, 10.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image593.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image593.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image593.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image482.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image482.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image482.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image341.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image341.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image341.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image6.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image6.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image6.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  52%|█████▏    | 82/158 [13:50<12:36,  9.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image13.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image13.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image13.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image540.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image540.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image540.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image423.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image423.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image423.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image34.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image34.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image34.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  53%|█████▎    | 83/158 [14:00<12:22,  9.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image180.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image180.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image180.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image362.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image362.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image362.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image145.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image145.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image145.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image459.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image459.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image459.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  53%|█████▎    | 84/158 [14:10<12:19, 10.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image371.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image371.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image371.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image390.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image390.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image390.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image630.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image630.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image630.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image564.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image564.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image564.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  54%|█████▍    | 85/158 [14:20<12:11, 10.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image632.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image632.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image632.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image128.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image128.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image128.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image372.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image372.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image372.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image541.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image541.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image541.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  54%|█████▍    | 86/158 [14:30<12:00, 10.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image516.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image516.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image516.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image409.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image409.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image409.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image143.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image143.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image143.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image638.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image638.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image638.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  55%|█████▌    | 87/158 [14:40<11:49,  9.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image345.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image345.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image345.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image125.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image125.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image125.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image103.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image103.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image103.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image109.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image109.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image109.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  56%|█████▌    | 88/158 [14:49<11:31,  9.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image426.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image426.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image426.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image517.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image517.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image517.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image227.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image227.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image227.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image592.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image592.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image592.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  56%|█████▋    | 89/158 [14:59<11:23,  9.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image608.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image608.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image608.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image624.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image624.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image624.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image451.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image451.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image451.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image116.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image116.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image116.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  57%|█████▋    | 90/158 [15:09<11:14,  9.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image499.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image499.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image499.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image216.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image216.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image216.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image563.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image563.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image563.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image334.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image334.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image334.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  58%|█████▊    | 91/158 [15:19<11:03,  9.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image535.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image535.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image535.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image168.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image168.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image168.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image268.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image268.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image268.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image435.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image435.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image435.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  58%|█████▊    | 92/158 [15:30<11:05, 10.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image576.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image576.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image576.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image127.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image127.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image127.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image272.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image272.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image272.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image474.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image474.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image474.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  59%|█████▉    | 93/158 [15:40<11:03, 10.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image573.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image573.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image573.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image100.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image100.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image100.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image366.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image366.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image366.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image179.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image179.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image179.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  59%|█████▉    | 94/158 [15:49<10:36,  9.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image627.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image627.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image627.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image307.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image307.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image307.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image27.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image27.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image27.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image404.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image404.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image404.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  60%|██████    | 95/158 [15:59<10:24,  9.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image280.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image280.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image280.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image217.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image217.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image217.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image342.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image342.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image342.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image382.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image382.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image382.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  61%|██████    | 96/158 [16:09<10:06,  9.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image547.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image547.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image547.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image58.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image58.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image58.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image18.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image18.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image18.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image351.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image351.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image351.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  61%|██████▏   | 97/158 [16:19<10:00,  9.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image42.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image42.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image42.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image496.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image496.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image496.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image571.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image571.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image571.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image332.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image332.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image332.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  62%|██████▏   | 98/158 [16:29<09:54,  9.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image432.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image432.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image432.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image642.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image642.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image642.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image400.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image400.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image400.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image606.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image606.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image606.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  63%|██████▎   | 99/158 [16:39<09:44,  9.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image481.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image481.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image481.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image617.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image617.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image617.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image539.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image539.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image539.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image176.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image176.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image176.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  63%|██████▎   | 100/158 [16:48<09:32,  9.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image326.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image326.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image326.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image614.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image614.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image614.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image637.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image637.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image637.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image556.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image556.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image556.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  64%|██████▍   | 101/158 [16:59<09:34, 10.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image641.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image641.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image641.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image337.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image337.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image337.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image199.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image199.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image199.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image1.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image1.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image1.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  65%|██████▍   | 102/158 [17:09<09:24, 10.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image20.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image20.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image20.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image520.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image520.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image520.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image233.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image233.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image233.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image275.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image275.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image275.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  65%|██████▌   | 103/158 [17:19<09:12, 10.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image248.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image248.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image248.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image204.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image204.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image204.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image613.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image613.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image613.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image274.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image274.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image274.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  66%|██████▌   | 104/158 [17:29<09:04, 10.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image625.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image625.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image625.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image39.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image39.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image39.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image323.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image323.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image323.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image566.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image566.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image566.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  66%|██████▋   | 105/158 [17:40<08:59, 10.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image309.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image309.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image309.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image196.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image196.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image196.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image549.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image549.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image549.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image163.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image163.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image163.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  67%|██████▋   | 106/158 [17:50<08:49, 10.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image197.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image197.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image197.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image645.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image645.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image645.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image558.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image558.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image558.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image106.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image106.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image106.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  68%|██████▊   | 107/158 [18:00<08:32, 10.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image190.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image190.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image190.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image515.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image515.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image515.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image428.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image428.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image428.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image565.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image565.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image565.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  68%|██████▊   | 108/158 [18:09<08:18,  9.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image417.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image417.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image417.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image174.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image174.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image174.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image408.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image408.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image408.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image114.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image114.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image114.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  69%|██████▉   | 109/158 [18:20<08:11, 10.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image169.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image169.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image169.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image257.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image257.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image257.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image160.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image160.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image160.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image493.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image493.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image493.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  70%|██████▉   | 110/158 [18:29<07:57,  9.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image407.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image407.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image407.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image524.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image524.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image524.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image490.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image490.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image490.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image207.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image207.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image207.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  70%|███████   | 111/158 [18:40<07:50, 10.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image271.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image271.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image271.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image324.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image324.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image324.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image448.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image448.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image448.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image615.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image615.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image615.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  71%|███████   | 112/158 [18:49<07:33,  9.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image150.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image150.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image150.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image170.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image170.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image170.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image468.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image468.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image468.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image175.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image175.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image175.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  72%|███████▏  | 113/158 [18:59<07:25,  9.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image443.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image443.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image443.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image430.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image430.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image430.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image234.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image234.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image234.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image455.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image455.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image455.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  72%|███████▏  | 114/158 [19:10<07:33, 10.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image318.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image318.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image318.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image251.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image251.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image251.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image512.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image512.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image512.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image667.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image667.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image667.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  73%|███████▎  | 115/158 [19:20<07:18, 10.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image159.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image159.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image159.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image281.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image281.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image281.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image255.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image255.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image255.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image651.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image651.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image651.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  73%|███████▎  | 116/158 [19:33<07:43, 11.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image152.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image152.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image152.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image33.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image33.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image33.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image543.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image543.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image543.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image508.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image508.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image508.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  74%|███████▍  | 117/158 [19:43<07:16, 10.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image101.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image101.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image101.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image120.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image120.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image120.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image188.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image188.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image188.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image640.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image640.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image640.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  75%|███████▍  | 118/158 [19:53<06:54, 10.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image291.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image291.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image291.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image666.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image666.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image666.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image427.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image427.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image427.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image648.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image648.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image648.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  75%|███████▌  | 119/158 [20:03<06:41, 10.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image320.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image320.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image320.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image431.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image431.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image431.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image590.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image590.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image590.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image336.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image336.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image336.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  76%|███████▌  | 120/158 [20:13<06:26, 10.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image223.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image223.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image223.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image507.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image507.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image507.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image171.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image171.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image171.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image487.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image487.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image487.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  77%|███████▋  | 121/158 [20:22<06:11, 10.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image378.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image378.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image378.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image388.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image388.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image388.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image560.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image560.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image560.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image589.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image589.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image589.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  77%|███████▋  | 122/158 [20:32<05:55,  9.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image534.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image534.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image534.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image421.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image421.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image421.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image297.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image297.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image297.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image43.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image43.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image43.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  78%|███████▊  | 123/158 [20:42<05:50, 10.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image495.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image495.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image495.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image358.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image358.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image358.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image347.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image347.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image347.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image161.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image161.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image161.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  78%|███████▊  | 124/158 [20:52<05:39,  9.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image211.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image211.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image211.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image548.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image548.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image548.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image635.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image635.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image635.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image412.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image412.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image412.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  79%|███████▉  | 125/158 [21:02<05:28,  9.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image631.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image631.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image631.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image250.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image250.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image250.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image121.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image121.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image121.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image192.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image192.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image192.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  80%|███████▉  | 126/158 [21:12<05:20, 10.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image364.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image364.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image364.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image26.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image26.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image26.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image554.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image554.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image554.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image283.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image283.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image283.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  80%|████████  | 127/158 [21:28<06:07, 11.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image316.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image316.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image316.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image555.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image555.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image555.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image29.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image29.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image29.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image467.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image467.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image467.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  81%|████████  | 128/158 [21:39<05:46, 11.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image136.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image136.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image136.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image621.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image621.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image621.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image238.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image238.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image238.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image392.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image392.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image392.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  82%|████████▏ | 129/158 [21:49<05:23, 11.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image212.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image212.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image212.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image219.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image219.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image219.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image628.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image628.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image628.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image302.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image302.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image302.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  82%|████████▏ | 130/158 [21:59<05:00, 10.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image137.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image137.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image137.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image521.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image521.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image521.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image662.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image662.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image662.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image461.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image461.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image461.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  83%|████████▎ | 131/158 [22:09<04:42, 10.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image310.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image310.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image310.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image333.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image333.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image333.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image373.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image373.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image373.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image657.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image657.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image657.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  84%|████████▎ | 132/158 [22:19<04:29, 10.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image319.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image319.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image319.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image208.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image208.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image208.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image585.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image585.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image585.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image258.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image258.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image258.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  84%|████████▍ | 133/158 [22:29<04:17, 10.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image623.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image623.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image623.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image355.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image355.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image355.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image131.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image131.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image131.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image458.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image458.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image458.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  85%|████████▍ | 134/158 [22:40<04:08, 10.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image31.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image31.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image31.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image471.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image471.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image471.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image285.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image285.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image285.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image261.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image261.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image261.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  85%|████████▌ | 135/158 [22:50<03:55, 10.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image476.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image476.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image476.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image354.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image354.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image354.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image527.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image527.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image527.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image286.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image286.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image286.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  86%|████████▌ | 136/158 [23:00<03:44, 10.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image655.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image655.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image655.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image510.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image510.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image510.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image559.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image559.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image559.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image30.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image30.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image30.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  87%|████████▋ | 137/158 [23:10<03:32, 10.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image386.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image386.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image386.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image242.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image242.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image242.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image276.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image276.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image276.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image327.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image327.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image327.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  87%|████████▋ | 138/158 [23:19<03:19,  9.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image19.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image19.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image19.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image369.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image369.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image369.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image236.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image236.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image236.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image376.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image376.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image376.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  88%|████████▊ | 139/158 [23:30<03:11, 10.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image147.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image147.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image147.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image178.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image178.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image178.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image49.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image49.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image49.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image365.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image365.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image365.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  89%|████████▊ | 140/158 [23:39<02:58,  9.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image155.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image155.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image155.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image604.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image604.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image604.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image295.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image295.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image295.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image399.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image399.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image399.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  89%|████████▉ | 141/158 [23:50<02:51, 10.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image489.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image489.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image489.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image532.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image532.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image532.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image650.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image650.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image650.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image102.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image102.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image102.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  90%|████████▉ | 142/158 [23:59<02:38,  9.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image158.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image158.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image158.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image305.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image305.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image305.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image151.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image151.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image151.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image605.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image605.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image605.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  91%|█████████ | 143/158 [24:09<02:27,  9.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image663.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image663.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image663.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image329.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image329.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image329.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image460.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image460.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image460.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image359.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image359.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image359.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  91%|█████████ | 144/158 [24:19<02:19,  9.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image231.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image231.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image231.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image557.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image557.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image557.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image601.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image601.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image601.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image313.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image313.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image313.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  92%|█████████▏| 145/158 [24:30<02:12, 10.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image552.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image552.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image552.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image488.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image488.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image488.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image267.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image267.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image267.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image361.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image361.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image361.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  92%|█████████▏| 146/158 [24:40<02:00, 10.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image578.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image578.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image578.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image553.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image553.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image553.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image391.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image391.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image391.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image203.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image203.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image203.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  93%|█████████▎| 147/158 [24:50<01:51, 10.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image518.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image518.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image518.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image139.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image139.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image139.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image356.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image356.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image356.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image278.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image278.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image278.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  94%|█████████▎| 148/158 [24:59<01:39,  9.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image298.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image298.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image298.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image184.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image184.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image184.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image148.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image148.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image148.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image45.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image45.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image45.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  94%|█████████▍| 149/158 [25:09<01:29,  9.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image111.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image111.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image111.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image12.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image12.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image12.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image294.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image294.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image294.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image464.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image464.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image464.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  95%|█████████▍| 150/158 [25:19<01:19,  9.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image607.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image607.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image607.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image647.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image647.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image647.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image353.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image353.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image353.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image157.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image157.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image157.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  96%|█████████▌| 151/158 [25:29<01:09,  9.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image375.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image375.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image375.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image472.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image472.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image472.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image57.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image57.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image57.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image117.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image117.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image117.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  96%|█████████▌| 152/158 [25:39<00:59,  9.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image385.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image385.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image385.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image501.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image501.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image501.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image580.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image580.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image580.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image445.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image445.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image445.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  97%|█████████▋| 153/158 [25:50<00:50, 10.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image37.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image37.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image37.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image424.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image424.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image424.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image377.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image377.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image377.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image2.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image2.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image2.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  97%|█████████▋| 154/158 [26:00<00:41, 10.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image368.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image368.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image368.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image349.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image349.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image349.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image47.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image47.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image47.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image619.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image619.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image619.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  98%|█████████▊| 155/158 [26:10<00:30, 10.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image48.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image48.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image48.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image60.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image60.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image60.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image59.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image59.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image59.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image3.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image3.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image3.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  99%|█████████▊| 156/158 [26:20<00:20, 10.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image113.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image113.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image113.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image330.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image330.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image330.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image546.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image546.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image546.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image633.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image633.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image633.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  99%|█████████▉| 157/158 [26:30<00:10, 10.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image466.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image466.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image466.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image35.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image35.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image35.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image429.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image429.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image429.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 158/158 [26:37<00:00, 10.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   1%|          | 1/158 [00:00<00:16,  9.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image371.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image371.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image371.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image562.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image562.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image562.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image289.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image289.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image289.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image412.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image412.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image412.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image350.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image350.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image350.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image217.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image217.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image217.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image564.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image564.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image564.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image38.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image38.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image38.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   1%|▏         | 2/158 [00:00<00:16,  9.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image147.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image147.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image147.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image166.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image166.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image166.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   3%|▎         | 4/158 [00:02<01:54,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image520.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image520.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image520.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image170.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image170.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image170.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image292.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image292.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image292.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image533.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image533.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image533.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image444.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image444.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image444.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image287.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image287.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image287.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image466.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image466.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image466.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image241.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image241.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image241.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   4%|▍         | 6/158 [00:02<00:57,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image554.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image554.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image554.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image296.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image296.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image296.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image272.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image272.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image272.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image295.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image295.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image295.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image472.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image472.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image472.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image614.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image614.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image614.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image234.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image234.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image234.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image330.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image330.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image330.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   5%|▌         | 8/158 [00:03<00:34,  4.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image205.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image205.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image205.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image595.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image595.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image595.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image457.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image457.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image457.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image48.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image48.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image48.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image152.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image152.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image152.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image2.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image2.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image2.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image112.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image112.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image112.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image18.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image18.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image18.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image223.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image223.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image223.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   6%|▋         | 10/158 [00:04<01:06,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image134.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image134.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image134.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image416.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image416.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image416.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image254.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image254.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image254.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image461.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image461.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image461.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image618.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image618.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image618.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image351.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image351.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image351.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image365.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image365.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image365.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image202.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image202.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image202.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   8%|▊         | 12/158 [00:04<00:39,  3.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image142.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image142.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image142.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image482.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image482.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image482.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image310.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image310.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image310.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image627.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image627.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image627.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image357.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image357.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image357.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image373.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image373.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image373.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image248.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image248.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image248.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image187.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image187.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image187.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   9%|▉         | 14/158 [00:05<00:27,  5.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image605.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image605.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image605.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image245.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image245.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image245.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image57.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image57.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image57.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image495.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image495.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image495.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image522.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image522.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image522.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image347.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image347.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image347.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image306.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image306.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image306.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  10%|█         | 16/158 [00:05<00:22,  6.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image427.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image427.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image427.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image184.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image184.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image184.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image19.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image19.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image19.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image256.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image256.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image256.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image604.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image604.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image604.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image477.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image477.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image477.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image497.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image497.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image497.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  11%|█▏        | 18/158 [00:05<00:18,  7.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image600.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image600.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image600.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image16.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image16.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image16.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image286.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image286.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image286.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image409.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image409.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image409.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image262.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image262.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image262.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image599.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image599.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image599.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image539.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image539.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image539.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image233.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image233.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image233.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image338.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image338.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image338.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  13%|█▎        | 20/158 [00:05<00:16,  8.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image421.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image421.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image421.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image650.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image650.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image650.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image247.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image247.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image247.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image443.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image443.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image443.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image3.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image3.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image3.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image403.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image403.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image403.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image424.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image424.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image424.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image60.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image60.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image60.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  14%|█▍        | 22/158 [00:06<00:16,  8.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image195.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image195.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image195.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image46.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image46.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image46.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image662.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image662.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image662.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image609.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image609.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image609.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image105.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image105.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image105.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image191.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image191.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image191.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image544.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image544.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image544.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  15%|█▌        | 24/158 [00:06<00:15,  8.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image476.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image476.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image476.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image549.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image549.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image549.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image177.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image177.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image177.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image652.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image652.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image652.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image325.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image325.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image325.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image158.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image158.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image158.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image462.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image462.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image462.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image109.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image109.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image109.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  16%|█▋        | 26/158 [00:06<00:14,  9.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image572.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image572.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image572.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image507.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image507.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image507.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image13.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image13.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image13.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image6.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image6.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image6.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image118.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image118.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image118.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image622.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image622.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image622.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image122.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image122.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image122.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image219.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image219.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image219.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  17%|█▋        | 27/158 [00:06<00:14,  8.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image535.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image535.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image535.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image210.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image210.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image210.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image252.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image252.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image252.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image645.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image645.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image645.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image346.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image346.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image346.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image49.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image49.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image49.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image123.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image123.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image123.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  18%|█▊        | 29/158 [00:06<00:15,  8.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image577.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image577.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image577.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image415.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image415.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image415.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image127.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image127.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image127.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image181.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image181.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image181.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image244.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image244.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image244.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image524.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image524.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image524.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image573.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image573.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image573.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  20%|█▉        | 31/158 [00:07<00:14,  8.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image422.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image422.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image422.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image379.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image379.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image379.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image621.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image621.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image621.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image140.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image140.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image140.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image632.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image632.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image632.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image394.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image394.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image394.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image227.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image227.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image227.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image236.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image236.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image236.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image249.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image249.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image249.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  21%|██        | 33/158 [00:07<00:13,  9.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image392.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image392.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image392.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image385.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image385.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image385.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image229.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image229.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image229.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image571.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image571.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image571.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image270.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image270.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image270.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image124.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image124.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image124.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image343.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image343.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image343.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  22%|██▏       | 35/158 [00:07<00:13,  8.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image168.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image168.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image168.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image383.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image383.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image383.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image115.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image115.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image115.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image588.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image588.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image588.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image428.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image428.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image428.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image307.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image307.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image307.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image592.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image592.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image592.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image161.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image161.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image161.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  23%|██▎       | 37/158 [00:07<00:13,  9.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image213.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image213.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image213.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image337.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image337.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image337.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image490.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image490.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image490.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image326.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image326.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image326.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image355.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image355.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image355.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image566.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image566.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image566.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image157.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image157.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image157.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image207.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image207.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image207.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  25%|██▍       | 39/158 [00:07<00:12,  9.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image341.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image341.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image341.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image10.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image10.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image10.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image31.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image31.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image31.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image601.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image601.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image601.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image283.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image283.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image283.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image575.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image575.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image575.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image332.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image332.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image332.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  26%|██▌       | 41/158 [00:08<00:13,  8.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image557.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image557.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image557.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image630.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image630.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image630.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image154.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image154.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image154.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image574.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image574.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image574.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image200.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image200.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image200.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image1.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image1.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image1.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image50.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image50.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image50.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image298.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image298.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image298.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  27%|██▋       | 43/158 [00:08<00:12,  9.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image381.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image381.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image381.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image294.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image294.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image294.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image130.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image130.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image130.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image138.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image138.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image138.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image504.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image504.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image504.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image455.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image455.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image455.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image29.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image29.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image29.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image348.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image348.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image348.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  28%|██▊       | 44/158 [00:08<00:12,  9.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image633.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image633.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image633.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image315.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image315.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image315.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image372.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image372.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image372.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image297.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image297.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image297.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image552.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image552.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image552.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image35.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image35.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image35.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image156.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image156.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image156.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image135.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image135.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image135.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  30%|██▉       | 47/158 [00:08<00:12,  9.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image500.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image500.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image500.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image160.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image160.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image160.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image117.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image117.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image117.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image221.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image221.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image221.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image155.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image155.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image155.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image331.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image331.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image331.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image513.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image513.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image513.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image509.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image509.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image509.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  31%|███       | 49/158 [00:09<00:11,  9.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image176.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image176.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image176.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image634.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image634.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image634.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image576.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image576.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image576.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image237.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image237.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image237.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image212.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image212.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image212.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image641.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image641.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image641.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image528.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image528.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image528.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  32%|███▏      | 50/158 [00:09<00:11,  9.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image485.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image485.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image485.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image386.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image386.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image386.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image362.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image362.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image362.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image279.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image279.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image279.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image516.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image516.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image516.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image165.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image165.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image165.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image63.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image63.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image63.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  33%|███▎      | 52/158 [00:09<00:11,  9.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image354.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image354.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image354.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image175.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image175.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image175.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image52.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image52.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image52.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image446.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image446.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image446.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image266.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image266.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image266.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image5.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image5.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image5.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image277.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image277.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image277.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image40.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image40.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image40.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  34%|███▍      | 54/158 [00:09<00:11,  9.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image417.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image417.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image417.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image133.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image133.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image133.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image493.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image493.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image493.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image312.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image312.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image312.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image321.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image321.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image321.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image384.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image384.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image384.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image536.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image536.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image536.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image278.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image278.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image278.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image499.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image499.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image499.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  35%|███▌      | 56/158 [00:09<00:10,  9.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image30.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image30.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image30.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image222.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image222.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image222.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image340.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image340.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image340.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image149.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image149.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image149.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image501.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image501.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image501.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image484.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image484.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image484.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image649.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image649.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image649.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  36%|███▌      | 57/158 [00:09<00:10,  9.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image643.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image643.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image643.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image475.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image475.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image475.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image220.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image220.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image220.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image667.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image667.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image667.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image666.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image666.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image666.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image579.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image579.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image579.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image116.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image116.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image116.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image260.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image260.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image260.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  38%|███▊      | 60/158 [00:10<00:10,  9.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image519.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image519.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image519.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image258.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image258.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image258.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image101.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image101.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image101.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image141.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image141.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image141.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image317.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image317.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image317.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image612.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image612.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image612.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image498.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image498.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image498.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image642.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image642.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image642.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  39%|███▉      | 62/158 [00:10<00:10,  9.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image646.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image646.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image646.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image437.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image437.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image437.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image281.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image281.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image281.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image503.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image503.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image503.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image25.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image25.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image25.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image110.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image110.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image110.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image214.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image214.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image214.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  41%|████      | 64/158 [00:10<00:10,  9.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image290.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image290.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image290.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image565.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image565.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image565.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image300.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image300.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image300.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image282.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image282.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image282.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image367.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image367.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image367.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image413.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image413.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image413.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image314.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image314.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image314.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image474.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image474.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image474.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  42%|████▏     | 66/158 [00:10<00:09,  9.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image399.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image399.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image399.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image487.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image487.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image487.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image411.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image411.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image411.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image378.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image378.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image378.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image53.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image53.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image53.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image611.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image611.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image611.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image590.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image590.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image590.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image518.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image518.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image518.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  43%|████▎     | 68/158 [00:11<00:09,  9.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image452.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image452.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image452.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image602.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image602.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image602.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image447.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image447.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image447.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image593.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image593.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image593.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image568.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image568.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image568.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image329.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image329.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image329.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image327.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image327.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image327.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  44%|████▍     | 70/158 [00:11<00:09,  8.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image41.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image41.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image41.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image232.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image232.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image232.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image339.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image339.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image339.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image638.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image638.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image638.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image628.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image628.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image628.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image529.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image529.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image529.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image225.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image225.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image225.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image146.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image146.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image146.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  46%|████▌     | 72/158 [00:11<00:09,  9.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image473.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image473.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image473.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image188.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image188.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image188.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image263.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image263.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image263.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image551.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image551.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image551.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image288.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image288.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image288.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image639.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image639.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image639.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image660.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image660.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image660.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  46%|████▌     | 73/158 [00:11<00:09,  8.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image370.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image370.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image370.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image486.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image486.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image486.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image319.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image319.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image319.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image555.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image555.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image555.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image644.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image644.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image644.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image654.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image654.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image654.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image525.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image525.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image525.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  47%|████▋     | 75/158 [00:11<00:09,  8.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image594.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image594.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image594.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image126.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image126.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image126.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image218.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image218.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image218.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image264.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image264.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image264.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image463.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image463.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image463.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image430.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image430.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image430.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image656.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image656.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image656.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image640.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image640.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image640.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  49%|████▊     | 77/158 [00:12<00:09,  8.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image280.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image280.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image280.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image578.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image578.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image578.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image597.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image597.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image597.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image496.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image496.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image496.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image54.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image54.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image54.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image546.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image546.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image546.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image491.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image491.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image491.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image661.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image661.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image661.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  50%|█████     | 79/158 [00:12<00:08,  9.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image121.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image121.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image121.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image17.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image17.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image17.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image434.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image434.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image434.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image45.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image45.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image45.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image190.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image190.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image190.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image657.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image657.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image657.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image648.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image648.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image648.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  51%|█████▏    | 81/158 [00:12<00:08,  8.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image435.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image435.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image435.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image344.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image344.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image344.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image610.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image610.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image610.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image243.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image243.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image243.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image129.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image129.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image129.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image436.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image436.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image436.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image153.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image153.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image153.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image617.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image617.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image617.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  53%|█████▎    | 83/158 [00:12<00:08,  9.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image517.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image517.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image517.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image164.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image164.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image164.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image259.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image259.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image259.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image361.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image361.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image361.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image616.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image616.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image616.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image39.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image39.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image39.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image363.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image363.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image363.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image284.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image284.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image284.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  54%|█████▍    | 85/158 [00:12<00:08,  8.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image179.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image179.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image179.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image328.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image328.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image328.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image308.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image308.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image308.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image209.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image209.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image209.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image4.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image4.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image4.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image511.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image511.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image511.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image489.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image489.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image489.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  54%|█████▍    | 86/158 [00:13<00:08,  8.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image668.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image668.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image668.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image359.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image359.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image359.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image358.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image358.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image358.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image349.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image349.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image349.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image459.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image459.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image459.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image596.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image596.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image596.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image438.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image438.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image438.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image250.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image250.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image250.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image376.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image376.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image376.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  56%|█████▋    | 89/158 [00:13<00:07,  9.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image465.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image465.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image465.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image530.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image530.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image530.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image431.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image431.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image431.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image198.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image198.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image198.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image663.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image663.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image663.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image558.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image558.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image558.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image631.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image631.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image631.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image62.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image62.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image62.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  58%|█████▊    | 91/158 [00:13<00:07,  9.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image169.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image169.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image169.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image186.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image186.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image186.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image603.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image603.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image603.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image108.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image108.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image108.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image512.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image512.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image512.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image44.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image44.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image44.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image61.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image61.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image61.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image356.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image356.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image356.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  59%|█████▉    | 93/158 [00:13<00:06,  9.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image567.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image567.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image567.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image193.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image193.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image193.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image47.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image47.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image47.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image488.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image488.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image488.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image215.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image215.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image215.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image26.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image26.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image26.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image454.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image454.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image454.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image613.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image613.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image613.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  60%|██████    | 95/158 [00:14<00:06,  9.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image194.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image194.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image194.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image433.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image433.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image433.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image665.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image665.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image665.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image345.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image345.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image345.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image320.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image320.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image320.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image397.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image397.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image397.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image132.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image132.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image132.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image508.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image508.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image508.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  61%|██████▏   | 97/158 [00:14<00:06,  9.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image559.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image559.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image559.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image527.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image527.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image527.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image37.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image37.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image37.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image653.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image653.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image653.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image425.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image425.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image425.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image448.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image448.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image448.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image111.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image111.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image111.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image120.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image120.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image120.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  63%|██████▎   | 99/158 [00:14<00:06,  9.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image550.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image550.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image550.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image199.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image199.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image199.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image185.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image185.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image185.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image318.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image318.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image318.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image468.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image468.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image468.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image587.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image587.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image587.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image183.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image183.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image183.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image407.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image407.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image407.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  63%|██████▎   | 100/158 [00:14<00:06,  9.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image368.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image368.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image368.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image388.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image388.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image388.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image65.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image65.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image65.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image624.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image624.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image624.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image545.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image545.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image545.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image375.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image375.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image375.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image12.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image12.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image12.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image647.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image647.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image647.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  65%|██████▌   | 103/158 [00:14<00:06,  9.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image625.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image625.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image625.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image128.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image128.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image128.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image106.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image106.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image106.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image304.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image304.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image304.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image22.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image22.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image22.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image521.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image521.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image521.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image426.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image426.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image426.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  66%|██████▋   | 105/158 [00:15<00:05,  9.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image102.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image102.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image102.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image311.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image311.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image311.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image14.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image14.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image14.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image253.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image253.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image253.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image534.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image534.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image534.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image171.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image171.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image171.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image64.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image64.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image64.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  68%|██████▊   | 107/158 [00:15<00:05,  8.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image560.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image560.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image560.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image114.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image114.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image114.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image419.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image419.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image419.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image400.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image400.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image400.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image239.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image239.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image239.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image174.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image174.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image174.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image582.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image582.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image582.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  68%|██████▊   | 108/158 [00:15<00:05,  9.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image563.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image563.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image563.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image402.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image402.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image402.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image460.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image460.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image460.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image377.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image377.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image377.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image526.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image526.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image526.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image21.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image21.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image21.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image285.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image285.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image285.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image180.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image180.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image180.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  70%|██████▉   | 110/158 [00:15<00:05,  8.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image471.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image471.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image471.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image414.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image414.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image414.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image299.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image299.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image299.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image136.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image136.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image136.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image324.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image324.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image324.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image591.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image591.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image591.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image585.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image585.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image585.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image182.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image182.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image182.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  71%|███████   | 112/158 [00:15<00:05,  9.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image494.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image494.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image494.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image242.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image242.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image242.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image391.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image391.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image391.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image34.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image34.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image34.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image506.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image506.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image506.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image515.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image515.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image515.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image540.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image540.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image540.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image267.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image267.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image267.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  72%|███████▏  | 114/158 [00:16<00:04,  9.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image410.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image410.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image410.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image395.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image395.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image395.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image390.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image390.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image390.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image583.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image583.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image583.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image366.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image366.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image366.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image470.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image470.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image470.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image43.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image43.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image43.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  73%|███████▎  | 116/158 [00:16<00:04,  9.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image335.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image335.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image335.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image441.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image441.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image441.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image584.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image584.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image584.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image342.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image342.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image342.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image637.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image637.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image637.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image107.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image107.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image107.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image33.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image33.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image33.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image458.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image458.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image458.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  75%|███████▍  | 118/158 [00:16<00:04,  9.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image353.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image353.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image353.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image492.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image492.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image492.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image442.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image442.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image442.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image479.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image479.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image479.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image196.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image196.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image196.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image137.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image137.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image137.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image11.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image11.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image11.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image523.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image523.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image523.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  76%|███████▌  | 120/158 [00:16<00:04,  8.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image66.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image66.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image66.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image598.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image598.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image598.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image159.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image159.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image159.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image480.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image480.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image480.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image439.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image439.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image439.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image364.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image364.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image364.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image301.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image301.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image301.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  77%|███████▋  | 122/158 [00:16<00:03,  9.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image541.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image541.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image541.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image313.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image313.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image313.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image274.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image274.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image274.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image382.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image382.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image382.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image406.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image406.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image406.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image450.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image450.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image450.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image131.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image131.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image131.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image389.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image389.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image389.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  78%|███████▊  | 124/158 [00:17<00:03,  9.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image119.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image119.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image119.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image28.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image28.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image28.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image502.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image502.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image502.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image589.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image589.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image589.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image323.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image323.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image323.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image42.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image42.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image42.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image659.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image659.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image659.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  80%|███████▉  | 126/158 [00:17<00:03,  9.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image510.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image510.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image510.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image352.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image352.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image352.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image246.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image246.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image246.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image268.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image268.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image268.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image273.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image273.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image273.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image20.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image20.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image20.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image570.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image570.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image570.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image231.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image231.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image231.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  80%|████████  | 127/158 [00:17<00:03,  8.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image251.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image251.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image251.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image655.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image655.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image655.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image255.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image255.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image255.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image228.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image228.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image228.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image396.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image396.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image396.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image453.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image453.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image453.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image553.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image553.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image553.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image211.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image211.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image211.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  82%|████████▏ | 130/158 [00:17<00:02,  9.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image125.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image125.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image125.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image615.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image615.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image615.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image230.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image230.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image230.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image626.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image626.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image626.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image224.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image224.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image224.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image606.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image606.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image606.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image145.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image145.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image145.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image58.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image58.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image58.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  83%|████████▎ | 131/158 [00:17<00:02,  9.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image607.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image607.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image607.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image537.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image537.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image537.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image538.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image538.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image538.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image322.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image322.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image322.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image543.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image543.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image543.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image456.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image456.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image456.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image336.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image336.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image336.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  84%|████████▍ | 133/158 [00:18<00:02,  9.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image405.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image405.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image405.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image192.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image192.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image192.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image104.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image104.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image104.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image143.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image143.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image143.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image305.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image305.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image305.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image208.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image208.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image208.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image548.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image548.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image548.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image178.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image178.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image178.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  85%|████████▍ | 134/158 [00:18<00:02,  9.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image226.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image226.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image226.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image608.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image608.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image608.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image408.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image408.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image408.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image151.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image151.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image151.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image51.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image51.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image51.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image464.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image464.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image464.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image15.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image15.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image15.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image24.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image24.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image24.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  87%|████████▋ | 137/158 [00:18<00:02,  9.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image271.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image271.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image271.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image334.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image334.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image334.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image333.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image333.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image333.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image586.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image586.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image586.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image203.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image203.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image203.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image580.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image580.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image580.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image658.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image658.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image658.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  88%|████████▊ | 139/158 [00:18<00:02,  8.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image309.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image309.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image309.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image59.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image59.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image59.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image291.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image291.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image291.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image569.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image569.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image569.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image547.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image547.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image547.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image316.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image316.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image316.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image398.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image398.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image398.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  89%|████████▊ | 140/158 [00:18<00:02,  8.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image173.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image173.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image173.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image269.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image269.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image269.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image623.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image623.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image623.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image167.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image167.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image167.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image235.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image235.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image235.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image423.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image423.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image423.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image257.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image257.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image257.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image172.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image172.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image172.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  91%|█████████ | 143/158 [00:19<00:01,  9.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image148.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image148.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image148.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image144.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image144.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image144.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image303.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image303.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image303.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image620.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image620.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image620.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image420.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image420.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image420.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image469.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image469.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image469.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image635.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image635.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image635.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  92%|█████████▏| 145/158 [00:19<00:01,  9.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image481.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image481.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image481.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image664.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image664.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image664.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image103.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image103.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image103.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image261.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image261.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image261.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image204.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image204.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image204.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image197.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image197.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image197.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image23.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image23.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image23.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image27.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image27.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image27.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  93%|█████████▎| 147/158 [00:19<00:01,  9.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image581.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image581.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image581.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image478.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image478.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image478.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image100.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image100.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image100.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image556.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image556.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image556.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image440.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image440.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image440.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image445.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image445.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image445.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image206.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image206.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image206.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image201.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image201.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image201.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  94%|█████████▍| 149/158 [00:19<00:00,  9.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image139.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image139.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image139.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image505.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image505.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image505.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image293.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image293.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image293.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image401.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image401.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image401.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image429.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image429.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image429.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image514.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image514.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image514.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image302.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image302.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image302.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  95%|█████████▍| 150/158 [00:20<00:00,  9.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image636.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image636.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image636.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image451.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image451.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image451.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image393.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image393.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image393.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image55.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image55.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image55.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image162.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image162.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image162.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image432.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image432.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image432.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image240.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image240.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image240.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image629.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image629.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image629.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  96%|█████████▌| 152/158 [00:20<00:00,  9.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image467.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image467.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image467.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image404.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image404.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image404.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image238.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image238.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image238.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image542.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image542.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image542.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image532.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image532.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image532.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image651.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image651.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image651.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image619.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image619.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image619.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image189.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image189.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image189.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  97%|█████████▋| 154/158 [00:20<00:00,  8.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image150.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image150.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image150.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image276.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image276.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image276.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image369.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image369.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image369.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image163.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image163.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image163.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image531.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image531.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image531.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image275.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image275.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image275.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image418.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image418.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image418.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  99%|█████████▊| 156/158 [00:20<00:00,  9.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image56.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image56.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image56.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image36.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image36.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image36.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image113.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image113.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image113.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image216.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image216.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image216.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image449.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image449.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image449.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image374.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image374.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image374.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image265.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image265.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image265.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image380.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image380.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image380.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 158/158 [00:20<00:00,  7.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image561.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image561.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image561.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image483.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image483.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image483.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image387.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image387.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image387.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image360.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image360.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image360.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   1%|          | 1/158 [00:00<00:17,  9.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image176.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image176.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image176.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image265.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image265.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image265.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image361.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image361.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image361.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image24.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image24.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image24.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image619.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image619.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image619.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image558.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image558.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image558.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   2%|▏         | 3/158 [00:05<04:18,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image448.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image448.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image448.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image444.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image444.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image444.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image575.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image575.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image575.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image138.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image138.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image138.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image437.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image437.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image437.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image224.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image224.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image224.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image353.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image353.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image353.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image294.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image294.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image294.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   3%|▎         | 4/158 [00:05<02:41,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image5.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image5.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image5.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image135.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image135.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image135.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image301.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image301.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image301.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image612.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image612.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image612.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image131.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image131.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image131.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image614.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image614.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image614.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image338.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image338.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image338.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image658.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image658.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image658.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   4%|▍         | 7/158 [00:05<01:04,  2.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image465.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image465.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image465.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image662.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image662.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image662.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image314.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image314.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image314.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image280.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image280.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image280.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image634.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image634.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image634.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image608.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image608.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image608.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image105.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image105.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image105.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image18.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image18.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image18.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   5%|▌         | 8/158 [00:05<00:50,  2.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image656.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image656.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image656.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image216.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image216.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image216.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image388.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image388.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image388.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image293.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image293.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image293.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image615.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image615.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image615.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image468.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image468.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image468.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image564.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image564.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image564.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image475.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image475.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image475.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   6%|▋         | 10/158 [00:05<00:34,  4.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image134.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image134.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image134.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image425.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image425.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image425.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image27.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image27.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image27.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image661.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image661.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image661.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image225.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image225.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image225.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image206.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image206.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image206.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image186.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image186.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image186.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image528.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image528.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image528.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   8%|▊         | 13/158 [00:06<00:23,  6.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image367.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image367.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image367.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image646.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image646.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image646.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image413.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image413.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image413.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image469.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image469.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image469.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image643.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image643.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image643.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image566.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image566.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image566.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image392.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image392.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image392.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image493.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image493.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image493.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   9%|▉         | 15/158 [00:06<00:20,  6.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image48.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image48.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image48.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image310.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image310.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image310.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image142.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image142.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image142.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image642.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image642.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image642.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image452.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image452.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image452.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image54.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image54.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image54.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image187.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image187.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image187.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image197.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image197.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image197.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  11%|█         | 17/158 [00:06<00:17,  7.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image508.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image508.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image508.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image182.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image182.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image182.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image331.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image331.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image331.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image207.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image207.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image207.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image647.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image647.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image647.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image408.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image408.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image408.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image377.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image377.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image377.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image409.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image409.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image409.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  12%|█▏        | 19/158 [00:06<00:16,  8.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image396.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image396.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image396.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image335.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image335.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image335.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image288.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image288.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image288.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image274.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image274.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image274.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image446.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image446.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image446.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image621.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image621.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image621.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image393.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image393.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image393.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  13%|█▎        | 21/158 [00:07<00:15,  8.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image553.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image553.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image553.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image45.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image45.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image45.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image118.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image118.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image118.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image453.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image453.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image453.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image457.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image457.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image457.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image384.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image384.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image384.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image570.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image570.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image570.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image292.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image292.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image292.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  15%|█▍        | 23/158 [00:07<00:15,  8.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image273.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image273.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image273.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image28.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image28.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image28.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image379.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image379.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image379.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image124.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image124.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image124.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image555.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image555.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image555.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image102.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image102.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image102.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image360.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image360.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image360.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image441.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image441.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image441.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  15%|█▌        | 24/158 [00:07<00:15,  8.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image237.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image237.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image237.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image585.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image585.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image585.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image431.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image431.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image431.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image526.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image526.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image526.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image422.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image422.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image422.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image464.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image464.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image464.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image230.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image230.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image230.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  16%|█▋        | 26/158 [00:07<00:15,  8.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image627.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image627.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image627.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image532.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image532.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image532.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image299.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image299.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image299.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image160.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image160.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image160.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image631.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image631.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image631.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image523.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image523.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image523.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image602.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image602.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image602.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image279.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image279.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image279.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  17%|█▋        | 27/158 [00:07<00:14,  8.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image64.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image64.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image64.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image624.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image624.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image624.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image101.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image101.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image101.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image552.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image552.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image552.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image653.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image653.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image653.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image3.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image3.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image3.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image606.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image606.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image606.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image349.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image349.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image349.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  19%|█▉        | 30/158 [00:08<00:13,  9.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image491.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image491.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image491.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image443.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image443.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image443.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image372.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image372.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image372.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image376.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image376.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image376.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image23.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image23.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image23.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image194.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image194.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image194.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image271.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image271.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image271.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image607.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image607.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image607.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  20%|██        | 32/158 [00:08<00:14,  8.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image495.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image495.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image495.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image22.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image22.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image22.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image306.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image306.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image306.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image317.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image317.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image317.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image518.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image518.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image518.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image369.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image369.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image369.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image580.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image580.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image580.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  22%|██▏       | 34/158 [00:08<00:13,  9.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image458.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image458.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image458.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image394.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image394.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image394.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image260.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image260.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image260.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image406.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image406.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image406.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image355.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image355.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image355.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image238.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image238.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image238.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image665.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image665.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image665.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image302.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image302.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image302.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  23%|██▎       | 36/158 [00:08<00:13,  9.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image325.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image325.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image325.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image481.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image481.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image481.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image104.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image104.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image104.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image155.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image155.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image155.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image219.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image219.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image219.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image549.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image549.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image549.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image258.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image258.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image258.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  23%|██▎       | 37/158 [00:08<00:13,  9.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image168.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image168.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image168.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image378.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image378.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image378.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image12.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image12.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image12.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image277.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image277.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image277.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image365.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image365.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image365.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image153.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image153.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image153.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image390.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image390.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image390.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image255.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image255.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image255.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  25%|██▌       | 40/158 [00:09<00:12,  9.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image156.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image156.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image156.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image264.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image264.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image264.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image470.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image470.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image470.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image496.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image496.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image496.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image103.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image103.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image103.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image640.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image640.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image640.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image497.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image497.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image497.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image10.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image10.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image10.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  27%|██▋       | 42/158 [00:09<00:12,  9.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image577.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image577.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image577.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image232.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image232.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image232.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image370.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image370.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image370.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image163.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image163.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image163.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image222.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image222.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image222.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image31.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image31.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image31.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image371.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image371.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image371.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image330.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image330.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image330.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  28%|██▊       | 44/158 [00:09<00:12,  9.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image339.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image339.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image339.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image58.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image58.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image58.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image51.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image51.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image51.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image313.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image313.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image313.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image501.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image501.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image501.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image659.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image659.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image659.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image459.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image459.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image459.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image183.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image183.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image183.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  29%|██▉       | 46/158 [00:09<00:12,  9.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image41.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image41.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image41.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image100.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image100.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image100.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image269.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image269.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image269.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image519.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image519.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image519.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image108.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image108.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image108.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image527.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image527.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image527.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image362.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image362.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image362.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image307.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image307.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image307.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  30%|███       | 48/158 [00:10<00:12,  9.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image626.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image626.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image626.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image125.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image125.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image125.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image128.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image128.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image128.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image438.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image438.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image438.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image57.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image57.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image57.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image228.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image228.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image228.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image535.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image535.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image535.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  32%|███▏      | 50/158 [00:10<00:11,  9.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image235.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image235.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image235.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image490.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image490.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image490.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image243.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image243.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image243.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image318.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image318.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image318.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image152.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image152.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image152.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image149.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image149.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image149.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image49.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image49.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image49.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image375.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image375.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image375.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  33%|███▎      | 52/158 [00:10<00:11,  9.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image666.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image666.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image666.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image374.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image374.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image374.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image341.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image341.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image341.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image632.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image632.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image632.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image556.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image556.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image556.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image563.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image563.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image563.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image296.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image296.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image296.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image515.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image515.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image515.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  34%|███▎      | 53/158 [00:10<00:11,  9.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image290.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image290.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image290.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image169.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image169.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image169.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image589.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image589.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image589.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image143.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image143.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image143.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image587.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image587.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image587.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image529.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image529.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image529.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image536.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image536.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image536.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  34%|███▍      | 54/158 [00:10<00:11,  8.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image421.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image421.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image421.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image336.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image336.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image336.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image620.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image620.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image620.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image185.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image185.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image185.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image447.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image447.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image447.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image567.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image567.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image567.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image204.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image204.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image204.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image513.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image513.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image513.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  36%|███▌      | 57/158 [00:11<00:10,  9.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image154.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image154.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image154.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image345.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image345.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image345.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image44.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image44.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image44.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image195.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image195.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image195.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image633.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image633.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image633.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image522.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image522.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image522.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image239.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image239.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image239.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image591.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image591.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image591.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  37%|███▋      | 58/158 [00:11<00:10,  9.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image356.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image356.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image356.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image262.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image262.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image262.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image167.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image167.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image167.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image505.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image505.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image505.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image590.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image590.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image590.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image283.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image283.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image283.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image461.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image461.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image461.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image221.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image221.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image221.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  39%|███▊      | 61/158 [00:11<00:10,  9.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image184.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image184.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image184.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image132.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image132.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image132.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image455.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image455.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image455.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image281.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image281.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image281.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image637.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image637.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image637.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image226.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image226.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image226.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image162.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image162.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image162.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image610.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image610.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image610.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  40%|███▉      | 63/158 [00:11<00:10,  8.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image148.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image148.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image148.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image215.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image215.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image215.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image429.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image429.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image429.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image628.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image628.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image628.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image668.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image668.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image668.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image266.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image266.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image266.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image548.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image548.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image548.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image35.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image35.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image35.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  41%|████      | 65/158 [00:11<00:09,  9.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image309.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image309.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image309.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image664.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image664.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image664.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image451.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image451.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image451.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image433.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image433.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image433.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image428.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image428.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image428.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image613.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image613.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image613.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image520.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image520.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image520.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  42%|████▏     | 66/158 [00:12<00:10,  8.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image250.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image250.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image250.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image649.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image649.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image649.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image506.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image506.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image506.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image366.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image366.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image366.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image157.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image157.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image157.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image583.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image583.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image583.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image249.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image249.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image249.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image218.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image218.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image218.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  44%|████▎     | 69/158 [00:12<00:09,  9.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image368.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image368.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image368.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image114.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image114.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image114.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image50.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image50.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image50.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image484.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image484.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image484.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image504.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image504.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image504.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image531.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image531.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image531.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image551.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image551.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image551.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image205.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image205.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image205.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  45%|████▍     | 71/158 [00:12<00:09,  9.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image119.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image119.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image119.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image397.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image397.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image397.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image538.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image538.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image538.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image434.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image434.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image434.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image463.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image463.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image463.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image530.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image530.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image530.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image285.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image285.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image285.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image440.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image440.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image440.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  46%|████▌     | 73/158 [00:12<00:09,  9.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image544.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image544.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image544.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image487.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image487.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image487.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image644.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image644.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image644.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image59.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image59.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image59.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image630.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image630.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image630.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image253.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image253.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image253.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image179.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image179.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image179.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  47%|████▋     | 75/158 [00:13<00:09,  9.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image541.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image541.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image541.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image426.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image426.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image426.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image435.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image435.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image435.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image116.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image116.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image116.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image601.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image601.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image601.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image213.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image213.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image213.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image245.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image245.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image245.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image539.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image539.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image539.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  49%|████▊     | 77/158 [00:13<00:09,  8.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image193.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image193.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image193.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image581.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image581.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image581.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image525.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image525.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image525.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image466.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image466.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image466.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image297.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image297.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image297.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image246.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image246.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image246.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image478.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image478.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image478.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image126.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image126.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image126.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  50%|█████     | 79/158 [00:13<00:08,  9.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image46.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image46.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image46.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image358.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image358.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image358.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image635.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image635.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image635.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image47.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image47.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image47.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image227.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image227.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image227.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image401.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image401.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image401.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image492.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image492.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image492.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image618.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image618.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image618.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  51%|█████▏    | 81/158 [00:13<00:08,  9.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image174.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image174.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image174.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image6.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image6.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image6.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image295.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image295.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image295.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image56.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image56.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image56.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image20.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image20.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image20.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image524.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image524.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image524.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image166.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image166.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image166.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image40.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image40.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image40.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image2.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image2.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image2.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image15.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image15.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image15.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image63.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image63.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image63.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image278.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image278.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image278.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image247.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image247.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image247.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image198.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image198.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image198.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  53%|█████▎    | 84/158 [00:14<00:08,  8.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image178.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image178.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image178.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image569.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image569.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image569.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image55.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image55.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image55.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image616.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image616.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image616.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image120.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image120.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image120.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image663.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image663.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image663.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image328.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image328.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image328.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image29.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image29.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image29.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  54%|█████▍    | 86/158 [00:14<00:07,  9.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image578.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image578.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image578.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image333.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image333.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image333.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image565.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image565.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image565.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image480.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image480.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image480.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image19.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image19.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image19.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image241.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image241.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image241.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image359.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image359.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image359.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image494.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image494.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image494.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  56%|█████▌    | 88/158 [00:14<00:08,  8.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image121.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image121.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image121.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image593.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image593.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image593.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image209.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image209.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image209.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image571.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image571.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image571.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image343.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image343.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image343.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image347.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image347.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image347.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  57%|█████▋    | 90/158 [00:14<00:07,  8.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image43.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image43.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image43.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image510.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image510.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image510.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image196.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image196.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image196.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image30.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image30.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image30.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image122.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image122.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image122.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image107.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image107.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image107.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image21.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image21.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image21.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image202.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image202.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image202.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  58%|█████▊    | 91/158 [00:14<00:07,  8.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image147.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image147.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image147.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image502.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image502.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image502.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image26.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image26.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image26.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image418.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image418.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image418.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image595.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image595.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image595.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image33.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image33.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image33.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image405.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image405.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image405.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image512.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image512.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image512.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  59%|█████▉    | 94/158 [00:15<00:07,  8.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image175.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image175.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image175.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image25.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image25.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image25.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image348.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image348.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image348.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image192.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image192.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image192.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image332.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image332.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image332.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image398.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image398.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image398.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image261.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image261.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image261.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  61%|██████    | 96/158 [00:15<00:06,  8.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image340.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image340.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image340.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image573.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image573.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image573.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image268.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image268.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image268.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image572.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image572.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image572.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image161.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image161.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image161.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image514.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image514.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image514.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image208.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image208.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image208.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image542.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image542.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image542.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  61%|██████▏   | 97/158 [00:15<00:06,  9.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image415.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image415.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image415.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image467.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image467.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image467.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image308.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image308.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image308.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image289.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image289.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image289.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image654.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image654.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image654.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image483.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image483.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image483.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image144.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image144.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image144.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  63%|██████▎   | 99/158 [00:15<00:06,  9.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image106.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image106.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image106.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image474.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image474.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image474.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image305.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image305.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image305.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image62.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image62.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image62.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image248.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image248.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image248.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image533.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image533.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image533.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image231.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image231.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image231.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image320.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image320.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image320.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  64%|██████▍   | 101/158 [00:15<00:06,  8.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image34.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image34.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image34.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image316.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image316.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image316.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image363.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image363.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image363.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image180.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image180.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image180.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image477.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image477.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image477.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image655.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image655.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image655.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image667.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image667.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image667.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image4.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image4.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image4.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  65%|██████▌   | 103/158 [00:16<00:06,  9.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image511.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image511.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image511.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image188.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image188.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image188.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image560.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image560.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image560.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image516.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image516.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image516.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image14.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image14.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image14.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image233.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image233.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image233.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image557.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image557.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image557.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image600.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image600.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image600.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  66%|██████▋   | 105/158 [00:16<00:05,  9.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image291.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image291.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image291.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image427.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image427.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image427.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image592.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image592.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image592.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image65.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image65.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image65.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image158.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image158.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image158.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image352.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image352.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image352.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image410.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image410.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image410.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image639.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image639.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image639.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  68%|██████▊   | 107/158 [00:16<00:05,  9.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image304.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image304.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image304.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image141.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image141.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image141.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image599.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image599.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image599.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image39.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image39.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image39.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image342.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image342.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image342.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image357.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image357.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image357.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image561.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image561.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image561.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image420.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image420.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image420.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  69%|██████▉   | 109/158 [00:16<00:05,  9.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image52.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image52.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image52.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image123.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image123.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image123.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image112.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image112.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image112.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image584.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image584.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image584.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image117.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image117.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image117.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image130.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image130.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image130.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image146.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image146.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image146.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image482.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image482.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image482.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  70%|███████   | 111/158 [00:17<00:05,  9.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image386.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image386.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image386.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image311.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image311.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image311.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image251.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image251.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image251.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image625.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image625.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image625.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image373.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image373.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image373.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image657.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image657.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image657.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  72%|███████▏  | 113/158 [00:17<00:05,  8.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image414.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image414.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image414.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image66.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image66.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image66.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image16.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image16.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image16.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image145.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image145.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image145.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image129.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image129.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image129.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image652.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image652.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image652.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image648.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image648.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image648.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  73%|███████▎  | 115/158 [00:17<00:04,  9.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image387.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image387.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image387.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image327.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image327.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image327.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image423.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image423.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image423.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image136.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image136.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image136.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image473.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image473.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image473.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image322.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image322.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image322.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image263.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image263.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image263.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image17.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image17.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image17.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  73%|███████▎  | 116/158 [00:17<00:04,  9.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image165.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image165.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image165.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image171.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image171.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image171.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image36.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image36.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image36.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image596.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image596.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image596.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image424.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image424.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image424.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image545.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image545.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image545.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image540.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image540.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image540.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  74%|███████▍  | 117/158 [00:17<00:04,  8.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image499.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image499.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image499.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image242.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image242.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image242.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image382.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image382.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image382.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image150.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image150.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image150.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image417.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image417.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image417.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image485.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image485.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image485.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image503.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image503.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image503.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image159.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image159.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image159.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  76%|███████▌  | 120/158 [00:18<00:04,  9.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image256.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image256.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image256.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image454.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image454.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image454.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image500.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image500.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image500.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image416.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image416.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image416.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image37.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image37.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image37.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image217.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image217.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image217.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image651.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image651.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image651.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image594.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image594.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image594.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  77%|███████▋  | 121/158 [00:18<00:03,  9.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image350.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image350.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image350.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image559.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image559.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image559.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image321.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image321.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image321.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image611.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image611.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image611.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image201.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image201.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image201.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image326.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image326.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image326.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image303.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image303.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image303.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image344.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image344.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image344.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  78%|███████▊  | 124/158 [00:18<00:03,  9.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image164.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image164.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image164.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image312.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image312.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image312.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image240.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image240.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image240.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image298.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image298.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image298.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image229.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image229.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image229.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image110.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image110.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image110.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image537.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image537.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image537.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image181.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image181.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image181.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  80%|███████▉  | 126/158 [00:18<00:03,  9.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image605.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image605.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image605.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image53.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image53.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image53.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image203.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image203.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image203.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image588.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image588.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image588.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image509.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image509.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image509.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image337.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image337.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image337.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image139.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image139.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image139.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image488.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image488.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image488.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  81%|████████  | 128/158 [00:18<00:03,  9.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image334.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image334.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image334.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image234.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image234.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image234.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image479.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image479.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image479.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image400.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image400.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image400.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image252.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image252.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image252.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image450.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image450.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image450.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image1.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image1.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image1.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  82%|████████▏ | 130/158 [00:19<00:03,  9.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image641.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image641.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image641.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image534.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image534.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image534.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image521.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image521.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image521.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image42.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image42.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image42.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image442.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image442.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image442.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image60.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image60.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image60.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image300.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image300.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image300.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image636.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image636.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image636.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  84%|████████▎ | 132/158 [00:19<00:02,  9.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image244.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image244.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image244.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image597.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image597.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image597.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image115.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image115.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image115.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image170.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image170.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image170.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image177.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image177.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image177.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image445.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image445.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image445.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image11.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image11.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image11.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image191.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image191.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image191.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  85%|████████▍ | 134/158 [00:19<00:02,  8.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image456.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image456.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image456.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image402.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image402.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image402.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image275.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image275.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image275.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image385.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image385.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image385.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image486.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image486.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image486.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image172.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image172.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image172.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image617.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image617.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image617.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  86%|████████▌ | 136/158 [00:19<00:02,  9.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image127.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image127.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image127.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image284.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image284.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image284.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image267.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image267.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image267.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image404.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image404.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image404.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image364.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image364.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image364.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image354.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image354.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image354.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image389.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image389.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image389.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image383.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image383.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image383.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  87%|████████▋ | 138/158 [00:20<00:02,  9.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image650.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image650.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image650.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image562.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image562.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image562.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image211.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image211.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image211.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image472.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image472.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image472.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image13.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image13.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image13.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image200.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image200.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image200.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image391.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image391.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image391.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image543.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image543.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image543.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  89%|████████▊ | 140/158 [00:20<00:01,  9.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image137.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image137.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image137.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image432.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image432.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image432.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image399.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image399.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image399.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image236.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image236.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image236.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image462.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image462.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image462.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image259.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image259.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image259.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image489.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image489.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image489.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image199.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image199.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image199.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  90%|████████▉ | 142/158 [00:20<00:01,  9.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image351.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image351.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image351.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image582.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image582.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image582.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image272.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image272.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image272.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image546.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image546.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image546.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image598.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image598.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image598.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image586.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image586.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image586.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image395.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image395.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image395.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image603.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image603.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image603.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image660.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image660.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image660.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  91%|█████████ | 144/158 [00:20<00:01,  9.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image190.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image190.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image190.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image282.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image282.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image282.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image61.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image61.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image61.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image319.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image319.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image319.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image498.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image498.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image498.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image550.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image550.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image550.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image257.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image257.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image257.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image460.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image460.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image460.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  92%|█████████▏| 145/158 [00:20<00:01,  9.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image38.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image38.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image38.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image151.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image151.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image151.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image412.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image412.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image412.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image645.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image645.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image645.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image579.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image579.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image579.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image315.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image315.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image315.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image547.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image547.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image547.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image574.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image574.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image574.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  94%|█████████▎| 148/158 [00:21<00:01,  9.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image623.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image623.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image623.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image287.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image287.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image287.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image436.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image436.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image436.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image554.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image554.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image554.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image113.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image113.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image113.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image109.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image109.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image109.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image449.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image449.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image449.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image220.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image220.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image220.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  95%|█████████▍| 150/158 [00:21<00:00,  9.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image189.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image189.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image189.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image173.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image173.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image173.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image419.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image419.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image419.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image223.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image223.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image223.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image507.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image507.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image507.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image609.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image609.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image609.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image286.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image286.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image286.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  96%|█████████▌| 152/158 [00:21<00:00,  8.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image276.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image276.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image276.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image622.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image622.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image622.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image140.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image140.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image140.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image254.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image254.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image254.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image411.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image411.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image411.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image210.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image210.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image210.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image576.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image576.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image576.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  97%|█████████▋| 154/158 [00:21<00:00,  9.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image346.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image346.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image346.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image324.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image324.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image324.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image430.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image430.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image430.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image604.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image604.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image604.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image111.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image111.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image111.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image381.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image381.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image381.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image380.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image380.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image380.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image323.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image323.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image323.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  98%|█████████▊| 155/158 [00:21<00:00,  8.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image638.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image638.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image638.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image133.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image133.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image133.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image471.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image471.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image471.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image517.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image517.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image517.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image568.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image568.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image568.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image407.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image407.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image407.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image403.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image403.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image403.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image476.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image476.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image476.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 158/158 [00:22<00:00,  7.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image629.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image629.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image629.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image212.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image212.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image212.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image439.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image439.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image439.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image329.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image329.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image329.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image214.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image214.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image214.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image270.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image270.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image270.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   1%|          | 1/158 [00:00<00:18,  8.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image616.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image616.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image616.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image129.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image129.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image129.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image297.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image297.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image297.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image60.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image60.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image60.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image422.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image422.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image422.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image394.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image394.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image394.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image1.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image1.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image1.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image400.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image400.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image400.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   2%|▏         | 3/158 [00:00<00:18,  8.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image655.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image655.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image655.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image397.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image397.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image397.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image239.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image239.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image239.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image523.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image523.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image523.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image574.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image574.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image574.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image660.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image660.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image660.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image211.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image211.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image211.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   3%|▎         | 4/158 [00:00<00:18,  8.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image141.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image141.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image141.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image43.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image43.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image43.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   4%|▍         | 6/158 [00:04<02:34,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image113.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image113.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image113.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image57.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image57.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image57.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image315.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image315.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image315.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image612.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image612.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image612.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image282.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image282.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image282.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image132.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image132.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image132.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image170.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image170.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image170.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image630.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image630.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image630.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   4%|▍         | 7/158 [00:04<01:48,  1.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image411.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image411.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image411.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image150.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image150.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image150.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image551.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image551.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image551.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image352.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image352.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image352.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image661.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image661.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image661.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image596.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image596.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image596.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image3.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image3.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image3.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image391.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image391.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image391.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   6%|▋         | 10/158 [00:04<00:50,  2.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image542.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image542.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image542.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image332.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image332.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image332.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image641.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image641.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image641.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image504.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image504.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image504.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image182.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image182.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image182.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image447.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image447.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image447.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image649.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image649.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image649.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image319.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image319.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image319.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   7%|▋         | 11/158 [00:05<00:41,  3.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image495.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image495.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image495.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image279.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image279.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image279.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image316.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image316.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image316.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image576.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image576.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image576.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image312.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image312.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image312.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image207.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image207.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image207.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image363.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image363.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image363.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   8%|▊         | 13/158 [00:05<00:29,  4.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image210.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image210.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image210.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image66.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image66.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image66.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image444.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image444.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image444.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image534.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image534.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image534.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image431.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image431.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image431.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image490.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image490.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image490.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image399.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image399.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image399.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image563.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image563.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image563.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   9%|▉         | 15/158 [00:05<00:22,  6.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image50.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image50.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image50.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image369.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image369.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image369.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image307.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image307.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image307.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image578.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image578.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image578.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image221.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image221.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image221.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image136.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image136.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image136.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image374.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image374.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image374.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image587.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image587.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image587.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  10%|█         | 16/158 [00:05<00:21,  6.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image432.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image432.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image432.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image2.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image2.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image2.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image617.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image617.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image617.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image270.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image270.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image270.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image209.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image209.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image209.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image191.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image191.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image191.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image386.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image386.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image386.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image492.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image492.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image492.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  12%|█▏        | 19/158 [00:05<00:16,  8.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image61.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image61.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image61.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image614.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image614.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image614.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image625.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image625.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image625.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image424.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image424.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image424.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image405.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image405.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image405.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image645.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image645.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image645.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image117.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image117.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image117.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image508.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image508.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image508.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  13%|█▎        | 21/158 [00:06<00:15,  8.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image392.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image392.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image392.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image602.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image602.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image602.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image597.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image597.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image597.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image149.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image149.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image149.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image293.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image293.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image293.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image35.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image35.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image35.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image592.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image592.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image592.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image15.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image15.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image15.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  14%|█▍        | 22/158 [00:06<00:15,  8.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image328.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image328.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image328.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image18.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image18.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image18.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image648.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image648.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image648.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image156.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image156.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image156.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image468.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image468.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image468.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image545.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image545.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image545.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image198.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image198.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image198.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image16.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image16.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image16.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  15%|█▌        | 24/158 [00:06<00:14,  9.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image462.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image462.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image462.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image194.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image194.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image194.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image302.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image302.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image302.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image185.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image185.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image185.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image376.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image376.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image376.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image173.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image173.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image173.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image430.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image430.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image430.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image331.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image331.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image331.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  17%|█▋        | 27/158 [00:06<00:14,  9.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image306.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image306.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image306.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image568.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image568.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image568.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image219.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image219.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image219.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image577.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image577.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image577.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image610.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image610.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image610.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image329.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image329.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image329.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image575.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image575.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image575.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  18%|█▊        | 28/158 [00:06<00:14,  8.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image158.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image158.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image158.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image463.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image463.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image463.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image507.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image507.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image507.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image608.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image608.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image608.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image540.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image540.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image540.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image114.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image114.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image114.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image524.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image524.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image524.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image593.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image593.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image593.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  20%|█▉        | 31/158 [00:07<00:13,  9.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image48.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image48.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image48.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image171.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image171.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image171.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image335.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image335.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image335.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image30.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image30.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image30.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image122.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image122.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image122.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image434.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image434.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image434.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image310.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image310.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image310.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image572.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image572.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image572.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  21%|██        | 33/158 [00:07<00:13,  9.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image371.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image371.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image371.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image193.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image193.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image193.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image138.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image138.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image138.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image377.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image377.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image377.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image484.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image484.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image484.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image345.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image345.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image345.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image308.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image308.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image308.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  22%|██▏       | 34/158 [00:07<00:13,  8.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image177.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image177.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image177.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image204.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image204.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image204.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image109.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image109.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image109.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image301.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image301.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image301.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image167.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image167.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image167.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image216.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image216.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image216.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image322.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image322.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image322.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image535.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image535.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image535.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  23%|██▎       | 37/158 [00:07<00:13,  9.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image230.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image230.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image230.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image413.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image413.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image413.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image624.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image624.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image624.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image482.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image482.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image482.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image261.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image261.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image261.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image175.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image175.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image175.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image287.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image287.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image287.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image20.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image20.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image20.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  25%|██▍       | 39/158 [00:08<00:12,  9.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image382.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image382.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image382.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image441.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image441.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image441.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image488.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image488.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image488.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image27.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image27.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image27.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image273.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image273.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image273.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image370.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image370.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image370.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image514.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image514.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image514.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image420.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image420.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image420.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  25%|██▌       | 40/158 [00:08<00:12,  9.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image305.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image305.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image305.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image511.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image511.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image511.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image25.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image25.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image25.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image47.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image47.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image47.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image526.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image526.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image526.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image168.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image168.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image168.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image155.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image155.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image155.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image461.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image461.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image461.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  27%|██▋       | 43/158 [00:08<00:12,  9.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image502.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image502.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image502.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image384.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image384.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image384.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image139.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image139.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image139.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image518.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image518.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image518.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image223.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image223.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image223.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image425.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image425.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image425.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image254.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image254.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image254.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image295.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image295.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image295.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  28%|██▊       | 45/158 [00:08<00:12,  9.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image653.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image653.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image653.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image179.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image179.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image179.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image603.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image603.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image603.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image255.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image255.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image255.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image454.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image454.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image454.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image383.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image383.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image383.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image401.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image401.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image401.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  30%|██▉       | 47/158 [00:08<00:12,  9.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image234.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image234.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image234.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image396.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image396.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image396.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image59.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image59.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image59.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image409.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image409.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image409.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image241.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image241.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image241.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image339.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image339.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image339.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image228.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image228.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image228.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image657.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image657.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image657.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  31%|███       | 49/158 [00:09<00:11,  9.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image53.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image53.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image53.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image269.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image269.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image269.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image157.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image157.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image157.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image38.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image38.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image38.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image569.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image569.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image569.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image565.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image565.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image565.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image124.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image124.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image124.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image466.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image466.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image466.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  32%|███▏      | 50/158 [00:09<00:11,  9.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image174.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image174.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image174.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image226.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image226.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image226.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image500.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image500.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image500.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image309.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image309.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image309.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image349.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image349.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image349.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image344.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image344.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image344.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image570.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image570.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image570.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  33%|███▎      | 52/158 [00:09<00:11,  8.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image475.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image475.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image475.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image433.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image433.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image433.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image64.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image64.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image64.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image101.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image101.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image101.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image181.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image181.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image181.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image104.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image104.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image104.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image300.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image300.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image300.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image22.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image22.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image22.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  34%|███▍      | 54/158 [00:09<00:11,  9.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image256.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image256.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image256.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image44.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image44.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image44.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image217.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image217.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image217.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image477.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image477.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image477.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image107.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image107.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image107.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image487.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image487.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image487.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image252.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image252.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image252.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image343.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image343.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image343.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  35%|███▍      | 55/158 [00:09<00:11,  9.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image529.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image529.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image529.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image398.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image398.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image398.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image233.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image233.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image233.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image187.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image187.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image187.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image663.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image663.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image663.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image324.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image324.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image324.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image65.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image65.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image65.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image265.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image265.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image265.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  37%|███▋      | 58/158 [00:10<00:10,  9.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image594.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image594.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image594.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image267.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image267.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image267.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image215.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image215.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image215.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image601.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image601.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image601.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image668.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image668.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image668.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image643.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image643.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image643.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image197.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image197.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image197.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image238.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image238.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image238.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  38%|███▊      | 60/158 [00:10<00:10,  9.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image605.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image605.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image605.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image285.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image285.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image285.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image437.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image437.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image437.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image142.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image142.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image142.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image428.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image428.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image428.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image184.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image184.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image184.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image258.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image258.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image258.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  39%|███▊      | 61/158 [00:10<00:10,  9.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image618.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image618.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image618.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image272.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image272.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image272.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image244.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image244.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image244.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image152.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image152.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image152.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image619.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image619.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image619.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image390.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image390.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image390.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image242.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image242.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image242.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image521.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image521.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image521.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  41%|████      | 64/158 [00:10<00:10,  8.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image245.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image245.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image245.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image189.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image189.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image189.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image249.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image249.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image249.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image544.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image544.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image544.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image604.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image604.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image604.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image435.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image435.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image435.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image111.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image111.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image111.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  42%|████▏     | 66/158 [00:11<00:10,  8.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image536.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image536.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image536.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image460.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image460.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image460.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image445.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image445.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image445.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image600.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image600.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image600.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image346.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image346.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image346.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image17.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image17.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image17.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image416.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image416.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image416.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image119.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image119.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image119.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  43%|████▎     | 68/158 [00:11<00:10,  8.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image635.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image635.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image635.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image532.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image532.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image532.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image656.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image656.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image656.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image340.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image340.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image340.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image427.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image427.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image427.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image403.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image403.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image403.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image426.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image426.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image426.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  44%|████▎     | 69/158 [00:11<00:11,  8.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image522.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image522.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image522.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image623.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image623.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image623.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image581.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image581.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image581.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image549.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image549.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image549.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image247.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image247.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image247.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image123.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image123.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image123.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image153.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image153.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image153.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  45%|████▍     | 71/158 [00:11<00:10,  8.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image664.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image664.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image664.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image213.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image213.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image213.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image214.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image214.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image214.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image354.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image354.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image354.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image49.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image49.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image49.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image472.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image472.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image472.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image486.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image486.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image486.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  46%|████▌     | 73/158 [00:11<00:09,  8.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image250.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image250.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image250.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image334.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image334.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image334.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image450.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image450.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image450.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image120.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image120.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image120.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image4.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image4.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image4.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image196.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image196.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image196.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image326.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image326.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image326.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  47%|████▋     | 75/158 [00:12<00:10,  8.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image229.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image229.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image229.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image203.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image203.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image203.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image364.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image364.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image364.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image137.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image137.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image137.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image494.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image494.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image494.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image438.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image438.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image438.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  48%|████▊     | 76/158 [00:12<00:09,  8.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image260.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image260.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image260.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image320.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image320.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image320.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image519.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image519.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image519.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image264.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image264.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image264.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image205.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image205.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image205.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image659.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image659.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image659.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image208.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image208.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image208.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image276.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image276.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image276.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  49%|████▉     | 78/158 [00:12<00:09,  8.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image110.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image110.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image110.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image347.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image347.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image347.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image579.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image579.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image579.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image271.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image271.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image271.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image406.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image406.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image406.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image598.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image598.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image598.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image412.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image412.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image412.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image162.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image162.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image162.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  51%|█████     | 80/158 [00:12<00:08,  8.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image268.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image268.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image268.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image220.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image220.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image220.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image639.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image639.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image639.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image266.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image266.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image266.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image341.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image341.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image341.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image144.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image144.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image144.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image151.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image151.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image151.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  52%|█████▏    | 82/158 [00:12<00:08,  9.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image498.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image498.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image498.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image580.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image580.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image580.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image615.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image615.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image615.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image414.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image414.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image414.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image277.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image277.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image277.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image128.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image128.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image128.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image14.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image14.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image14.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image218.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image218.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image218.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  53%|█████▎    | 84/158 [00:13<00:08,  9.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image294.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image294.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image294.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image257.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image257.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image257.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image259.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image259.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image259.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image585.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image585.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image585.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image517.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image517.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image517.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image195.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image195.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image195.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image190.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image190.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image190.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  54%|█████▍    | 86/158 [00:13<00:08,  8.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image225.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image225.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image225.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image115.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image115.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image115.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image118.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image118.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image118.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image567.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image567.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image567.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image105.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image105.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image105.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image476.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image476.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image476.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image410.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image410.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image410.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  55%|█████▌    | 87/158 [00:13<00:08,  8.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image62.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image62.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image62.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image19.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image19.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image19.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image506.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image506.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image506.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image556.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image556.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image556.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image478.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image478.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image478.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image39.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image39.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image39.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image658.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image658.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image658.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image451.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image451.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image451.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  57%|█████▋    | 90/158 [00:13<00:07,  9.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image163.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image163.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image163.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image387.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image387.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image387.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image637.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image637.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image637.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image402.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image402.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image402.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image365.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image365.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image365.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image510.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image510.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image510.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image10.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image10.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image10.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image464.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image464.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image464.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  58%|█████▊    | 91/158 [00:13<00:07,  9.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image263.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image263.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image263.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image515.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image515.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image515.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image555.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image555.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image555.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image199.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image199.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image199.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image367.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image367.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image367.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image164.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image164.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image164.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image172.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image172.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image172.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  59%|█████▉    | 93/158 [00:14<00:07,  8.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image421.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image421.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image421.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image58.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image58.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image58.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image281.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image281.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image281.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image63.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image63.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image63.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image654.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image654.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image654.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image13.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image13.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image13.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image240.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image240.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image240.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image325.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image325.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image325.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  60%|██████    | 95/158 [00:14<00:07,  9.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image106.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image106.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image106.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image41.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image41.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image41.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image467.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image467.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image467.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image201.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image201.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image201.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image236.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image236.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image236.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image404.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image404.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image404.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image161.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image161.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image161.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image418.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image418.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image418.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  61%|██████▏   | 97/158 [00:14<00:07,  8.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image651.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image651.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image651.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image480.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image480.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image480.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image528.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image528.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image528.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image289.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image289.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image289.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image496.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image496.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image496.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image183.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image183.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image183.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image479.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image479.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image479.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  63%|██████▎   | 99/158 [00:14<00:06,  8.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image188.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image188.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image188.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image337.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image337.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image337.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image33.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image33.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image33.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image165.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image165.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image165.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image465.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image465.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image465.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image224.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image224.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image224.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image599.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image599.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image599.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image362.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image362.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image362.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  64%|██████▍   | 101/158 [00:15<00:06,  9.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image573.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image573.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image573.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image584.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image584.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image584.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image633.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image633.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image633.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image548.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image548.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image548.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image358.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image358.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image358.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image493.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image493.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image493.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image483.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image483.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image483.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  65%|██████▌   | 103/158 [00:15<00:06,  8.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image330.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image330.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image330.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image353.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image353.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image353.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image323.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image323.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image323.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image499.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image499.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image499.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image634.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image634.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image634.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image505.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image505.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image505.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image148.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image148.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image148.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  66%|██████▋   | 105/158 [00:15<00:05,  8.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image314.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image314.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image314.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image227.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image227.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image227.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image36.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image36.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image36.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image251.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image251.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image251.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image586.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image586.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image586.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image54.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image54.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image54.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image456.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image456.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image456.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image440.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image440.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image440.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  67%|██████▋   | 106/158 [00:15<00:05,  8.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image564.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image564.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image564.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image537.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image537.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image537.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image629.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image629.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image629.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image313.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image313.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image313.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image458.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image458.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image458.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image489.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image489.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image489.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image644.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image644.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image644.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  68%|██████▊   | 108/158 [00:15<00:05,  8.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image636.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image636.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image636.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image134.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image134.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image134.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image321.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image321.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image321.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image166.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image166.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image166.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image539.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image539.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image539.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image642.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image642.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image642.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image646.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image646.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image646.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image125.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image125.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image125.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  70%|██████▉   | 110/158 [00:16<00:05,  9.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image621.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image621.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image621.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image439.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image439.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image439.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image562.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image562.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image562.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image275.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image275.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image275.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image280.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image280.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image280.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image650.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image650.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image650.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image24.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image24.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image24.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image186.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image186.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image186.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  71%|███████   | 112/158 [00:16<00:04,  9.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image202.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image202.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image202.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image415.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image415.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image415.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image103.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image103.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image103.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image121.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image121.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image121.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image359.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image359.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image359.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image356.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image356.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image356.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image595.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image595.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image595.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image631.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image631.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image631.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  72%|███████▏  | 114/158 [00:16<00:04,  9.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image546.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image546.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image546.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image126.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image126.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image126.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image235.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image235.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image235.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image368.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image368.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image368.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image662.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image662.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image662.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image176.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image176.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image176.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image501.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image501.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image501.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image298.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image298.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image298.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  73%|███████▎  | 116/158 [00:16<00:04,  9.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image446.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image446.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image446.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image571.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image571.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image571.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image336.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image336.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image336.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image342.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image342.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image342.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image178.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image178.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image178.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image520.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image520.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image520.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image589.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image589.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image589.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image525.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image525.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image525.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  75%|███████▍  | 118/158 [00:16<00:04,  9.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image40.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image40.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image40.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image512.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image512.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image512.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image448.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image448.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image448.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image652.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image652.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image652.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image351.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image351.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image351.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image408.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image408.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image408.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image42.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image42.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image42.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  76%|███████▌  | 120/158 [00:17<00:04,  8.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image102.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image102.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image102.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image372.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image372.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image372.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image429.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image429.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image429.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image286.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image286.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image286.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image348.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image348.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image348.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image243.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image243.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image243.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image449.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image449.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image449.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  77%|███████▋  | 122/158 [00:17<00:04,  8.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image566.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image566.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image566.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image626.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image626.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image626.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image361.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image361.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image361.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image262.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image262.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image262.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image560.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image560.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image560.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image620.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image620.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image620.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image283.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image283.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image283.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image375.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image375.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image375.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  78%|███████▊  | 123/158 [00:17<00:03,  9.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image457.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image457.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image457.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image366.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image366.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image366.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image558.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image558.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image558.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image378.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image378.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image378.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image45.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image45.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image45.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image606.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image606.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image606.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image474.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image474.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image474.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image485.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image485.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image485.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  80%|███████▉  | 126/158 [00:17<00:03,  9.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image509.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image509.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image509.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image628.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image628.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image628.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image232.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image232.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image232.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image380.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image380.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image380.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image355.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image355.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image355.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image407.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image407.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image407.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image292.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image292.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image292.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image212.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image212.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image212.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  81%|████████  | 128/158 [00:17<00:03,  9.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image379.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image379.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image379.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image278.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image278.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image278.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image180.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image180.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image180.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image609.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image609.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image609.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image417.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image417.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image417.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image28.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image28.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image28.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image547.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image547.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image547.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image583.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image583.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image583.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  82%|████████▏ | 130/158 [00:18<00:02,  9.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image31.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image31.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image31.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image29.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image29.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image29.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image491.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image491.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image491.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image640.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image640.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image640.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image607.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image607.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image607.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image530.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image530.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image530.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image553.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image553.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image553.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image303.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image303.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image303.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image133.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image133.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image133.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  84%|████████▎ | 132/158 [00:18<00:02,  9.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image470.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image470.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image470.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image350.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image350.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image350.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image622.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image622.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image622.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image442.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image442.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image442.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image206.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image206.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image206.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image452.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image452.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image452.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image6.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image6.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image6.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  85%|████████▍ | 134/158 [00:18<00:02,  9.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image393.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image393.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image393.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image613.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image613.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image613.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image192.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image192.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image192.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image666.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image666.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image666.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image318.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image318.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image318.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image538.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image538.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image538.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image455.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image455.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image455.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image550.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image550.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image550.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  86%|████████▌ | 136/158 [00:18<00:02,  9.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image34.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image34.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image34.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image389.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image389.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image389.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image159.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image159.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image159.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image471.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image471.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image471.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image108.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image108.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image108.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image160.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image160.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image160.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image112.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image112.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image112.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image127.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image127.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image127.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  87%|████████▋ | 138/158 [00:19<00:02,  8.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image453.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image453.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image453.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image588.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image588.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image588.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image288.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image288.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image288.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image231.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image231.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image231.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image253.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image253.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image253.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image56.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image56.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image56.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image311.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image311.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image311.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  89%|████████▊ | 140/158 [00:19<00:01,  9.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image436.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image436.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image436.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image299.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image299.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image299.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image459.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image459.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image459.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image381.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image381.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image381.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image140.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image140.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image140.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image665.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image665.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image665.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image357.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image357.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image357.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image632.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image632.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image632.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  90%|████████▉ | 142/158 [00:19<00:01,  9.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image503.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image503.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image503.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image469.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image469.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image469.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image246.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image246.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image246.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image627.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image627.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image627.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image296.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image296.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image296.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image317.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image317.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image317.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image360.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image360.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image360.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image557.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image557.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image557.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  91%|█████████ | 144/158 [00:19<00:01,  9.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image145.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image145.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image145.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image37.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image37.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image37.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image527.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image527.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image527.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image52.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image52.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image52.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image290.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image290.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image290.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image333.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image333.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image333.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image423.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image423.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image423.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image481.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image481.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image481.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  92%|█████████▏| 146/158 [00:19<00:01,  9.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image373.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image373.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image373.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image582.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image582.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image582.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image154.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image154.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image154.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image419.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image419.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image419.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image559.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image559.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image559.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image667.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image667.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image667.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image130.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image130.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image130.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image131.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image131.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image131.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image513.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image513.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image513.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image23.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image23.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image23.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image338.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image338.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image338.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image143.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image143.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image143.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image248.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image248.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image248.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image116.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image116.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image116.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image147.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image147.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image147.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  94%|█████████▍| 149/158 [00:20<00:00,  9.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image497.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image497.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image497.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image385.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image385.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image385.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image274.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image274.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image274.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image473.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image473.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image473.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image395.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image395.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image395.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image443.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image443.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image443.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image531.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image531.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image531.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image200.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image200.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image200.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  96%|█████████▌| 151/158 [00:20<00:00,  9.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image21.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image21.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image21.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image590.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image590.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image590.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image146.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image146.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image146.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image304.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image304.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image304.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image388.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image388.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image388.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image291.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image291.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image291.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image55.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image55.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image55.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image51.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image51.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image51.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  97%|█████████▋| 153/158 [00:20<00:00,  9.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image516.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image516.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image516.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image12.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image12.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image12.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image533.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image533.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image533.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image543.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image543.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image543.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image5.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image5.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image5.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image327.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image327.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image327.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image561.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image561.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image561.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  98%|█████████▊| 155/158 [00:20<00:00,  8.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image135.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image135.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image135.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image100.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image100.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image100.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image169.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image169.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image169.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image222.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image222.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image222.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image647.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image647.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image647.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image552.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image552.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image552.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image26.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image26.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image26.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image237.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image237.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image237.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  99%|█████████▉| 157/158 [00:21<00:00,  9.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image554.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image554.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image554.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image638.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image638.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image638.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image11.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image11.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image11.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image46.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image46.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image46.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image591.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image591.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image591.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image284.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image284.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image284.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image541.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image541.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image541.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image611.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image611.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image611.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining: 100%|██████████| 158/158 [00:21<00:00,  7.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   1%|          | 1/158 [00:00<00:16,  9.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image151.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image151.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image151.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image205.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image205.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image205.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image534.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image534.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image534.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image406.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image406.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image406.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image16.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image16.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image16.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image380.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image380.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image380.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   1%|▏         | 2/158 [00:04<07:27,  2.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image354.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image354.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image354.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image442.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image442.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image442.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image527.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image527.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image527.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image483.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image483.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image483.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image608.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image608.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image608.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image36.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image36.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image36.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image656.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image656.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image656.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image173.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image173.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image173.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   3%|▎         | 5/158 [00:05<02:04,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image54.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image54.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image54.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image31.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image31.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image31.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image57.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image57.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image57.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image572.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image572.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image572.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image231.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image231.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image231.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image451.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image451.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image451.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image267.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image267.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image267.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image265.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image265.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image265.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   4%|▍         | 7/158 [00:05<01:08,  2.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image21.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image21.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image21.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image255.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image255.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image255.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image520.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image520.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image520.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image154.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image154.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image154.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image242.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image242.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image242.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image665.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image665.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image665.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image30.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image30.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image30.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   5%|▌         | 8/158 [00:05<00:52,  2.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image340.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image340.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image340.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image440.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image440.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image440.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image44.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image44.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image44.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image494.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image494.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image494.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image645.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image645.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image645.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image165.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image165.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image165.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image515.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image515.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image515.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   6%|▋         | 10/158 [00:05<00:33,  4.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image17.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image17.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image17.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image609.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image609.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image609.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image614.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image614.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image614.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image235.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image235.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image235.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image418.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image418.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image418.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image438.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image438.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image438.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image375.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image375.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image375.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image271.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image271.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image271.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   8%|▊         | 12/158 [00:05<00:23,  6.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image285.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image285.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image285.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image552.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image552.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image552.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image450.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image450.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image450.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image595.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image595.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image595.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image121.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image121.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image121.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image219.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image219.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image219.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image458.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image458.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image458.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image592.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image592.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image592.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   9%|▉         | 14/158 [00:06<00:19,  7.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image25.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image25.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image25.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image650.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image650.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image650.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image547.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image547.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image547.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image661.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image661.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image661.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image153.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image153.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image153.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image529.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image529.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image529.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image435.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image435.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image435.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image23.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image23.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image23.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   9%|▉         | 15/158 [00:06<00:18,  7.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image302.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image302.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image302.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image629.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image629.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image629.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image350.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image350.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image350.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image130.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image130.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image130.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image596.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image596.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image596.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image622.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image622.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image622.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image41.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image41.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image41.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image536.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image536.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image536.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  11%|█▏        | 18/158 [00:06<00:15,  8.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image374.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image374.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image374.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image256.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image256.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image256.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image63.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image63.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image63.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image584.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image584.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image584.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image385.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image385.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image385.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image452.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image452.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image452.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image329.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image329.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image329.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image51.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image51.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image51.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  13%|█▎        | 20/158 [00:06<00:16,  8.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image469.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image469.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image469.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image578.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image578.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image578.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image149.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image149.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image149.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image585.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image585.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image585.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image170.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image170.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image170.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image273.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image273.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image273.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  14%|█▍        | 22/158 [00:07<00:15,  8.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image188.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image188.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image188.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image102.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image102.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image102.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image491.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image491.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image491.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image20.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image20.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image20.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image227.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image227.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image227.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image351.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image351.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image351.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image346.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image346.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image346.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  15%|█▍        | 23/158 [00:07<00:15,  8.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image124.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image124.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image124.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image567.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image567.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image567.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image434.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image434.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image434.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image471.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image471.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image471.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image362.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image362.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image362.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image294.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image294.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image294.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image495.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image495.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image495.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  16%|█▌        | 25/158 [00:07<00:14,  8.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image649.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image649.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image649.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image134.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image134.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image134.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image395.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image395.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image395.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image500.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image500.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image500.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image221.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image221.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image221.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image144.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image144.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image144.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image312.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image312.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image312.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image467.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image467.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image467.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  18%|█▊        | 28/158 [00:07<00:13,  9.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image499.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image499.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image499.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image583.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image583.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image583.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image524.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image524.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image524.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image553.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image553.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image553.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image169.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image169.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image169.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image432.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image432.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image432.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image540.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image540.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image540.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image361.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image361.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image361.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  18%|█▊        | 29/158 [00:07<00:13,  9.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image253.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image253.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image253.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image518.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image518.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image518.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image522.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image522.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image522.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image357.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image357.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image357.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image278.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image278.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image278.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image615.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image615.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image615.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image62.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image62.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image62.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image396.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image396.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image396.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  20%|█▉        | 31/158 [00:08<00:13,  9.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image299.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image299.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image299.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image582.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image582.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image582.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image627.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image627.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image627.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image453.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image453.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image453.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image214.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image214.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image214.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image555.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image555.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image555.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image29.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image29.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image29.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image196.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image196.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image196.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  21%|██        | 33/158 [00:08<00:13,  9.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image611.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image611.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image611.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image381.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image381.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image381.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image45.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image45.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image45.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image46.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image46.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image46.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image126.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image126.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image126.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image35.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image35.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image35.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image143.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image143.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image143.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image404.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image404.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image404.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  22%|██▏       | 34/158 [00:08<00:13,  9.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image371.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image371.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image371.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image26.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image26.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image26.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image339.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image339.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image339.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image648.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image648.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image648.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image155.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image155.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image155.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image465.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image465.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image465.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image569.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image569.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image569.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image162.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image162.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image162.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  23%|██▎       | 37/158 [00:08<00:13,  9.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image14.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image14.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image14.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image545.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image545.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image545.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image472.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image472.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image472.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image388.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image388.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image388.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image372.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image372.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image372.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image10.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image10.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image10.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image589.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image589.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image589.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  25%|██▍       | 39/158 [00:08<00:13,  9.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image662.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image662.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image662.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image261.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image261.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image261.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image604.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image604.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image604.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image492.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image492.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image492.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image189.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image189.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image189.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image514.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image514.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image514.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image295.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image295.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image295.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image148.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image148.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image148.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  26%|██▌       | 41/158 [00:09<00:12,  9.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image663.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image663.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image663.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image138.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image138.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image138.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image560.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image560.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image560.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image293.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image293.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image293.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image115.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image115.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image115.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image600.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image600.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image600.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image180.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image180.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image180.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image37.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image37.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image37.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  27%|██▋       | 43/158 [00:09<00:12,  9.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image516.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image516.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image516.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image159.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image159.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image159.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image537.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image537.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image537.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image496.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image496.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image496.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image668.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image668.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image668.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image488.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image488.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image488.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image101.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image101.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image101.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  28%|██▊       | 44/158 [00:09<00:12,  9.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image192.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image192.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image192.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image56.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image56.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image56.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image603.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image603.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image603.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image651.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image651.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image651.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image563.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image563.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image563.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image632.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image632.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image632.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image549.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image549.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image549.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image222.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image222.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image222.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  30%|██▉       | 47/158 [00:09<00:11,  9.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image200.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image200.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image200.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image462.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image462.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image462.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image139.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image139.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image139.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image408.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image408.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image408.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image207.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image207.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image207.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image128.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image128.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image128.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image415.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image415.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image415.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image59.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image59.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image59.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  31%|███       | 49/158 [00:10<00:12,  8.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image116.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image116.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image116.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image183.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image183.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image183.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image161.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image161.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image161.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image426.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image426.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image426.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image519.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image519.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image519.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image249.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image249.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image249.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image164.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image164.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image164.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  32%|███▏      | 51/158 [00:10<00:11,  9.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image591.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image591.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image591.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image39.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image39.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image39.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image405.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image405.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image405.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image147.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image147.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image147.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image654.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image654.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image654.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image112.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image112.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image112.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image245.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image245.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image245.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image174.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image174.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image174.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  34%|███▎      | 53/158 [00:10<00:11,  8.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image107.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image107.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image107.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image168.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image168.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image168.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image241.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image241.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image241.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image391.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image391.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image391.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image551.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image551.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image551.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image137.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image137.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image137.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image275.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image275.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image275.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  34%|███▍      | 54/158 [00:10<00:12,  8.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image191.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image191.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image191.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image311.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image311.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image311.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image27.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image27.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image27.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image546.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image546.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image546.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image390.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image390.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image390.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image376.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image376.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image376.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image556.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image556.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image556.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  35%|███▌      | 56/158 [00:10<00:11,  8.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image58.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image58.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image58.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image400.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image400.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image400.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image133.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image133.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image133.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image607.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image607.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image607.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image463.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image463.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image463.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image564.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image564.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image564.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image624.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image624.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image624.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  36%|███▌      | 57/158 [00:10<00:11,  8.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image637.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image637.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image637.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image307.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image307.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image307.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image136.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image136.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image136.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image412.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image412.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image412.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image539.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image539.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image539.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image103.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image103.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image103.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image616.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image616.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image616.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image280.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image280.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image280.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  38%|███▊      | 60/158 [00:11<00:10,  9.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image332.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image332.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image332.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image325.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image325.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image325.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image52.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image52.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image52.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image218.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image218.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image218.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image262.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image262.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image262.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image301.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image301.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image301.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image652.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image652.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image652.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  39%|███▊      | 61/158 [00:11<00:10,  8.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image141.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image141.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image141.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image243.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image243.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image243.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image194.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image194.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image194.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image18.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image18.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image18.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image383.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image383.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image383.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image283.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image283.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image283.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image421.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image421.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image421.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image424.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image424.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image424.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  40%|███▉      | 63/158 [00:11<00:10,  9.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image647.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image647.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image647.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image114.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image114.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image114.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image363.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image363.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image363.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image441.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image441.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image441.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image176.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image176.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image176.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image166.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image166.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image166.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image353.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image353.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image353.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  41%|████      | 65/158 [00:11<00:10,  9.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image643.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image643.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image643.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image127.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image127.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image127.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image558.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image558.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image558.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image402.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image402.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image402.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image195.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image195.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image195.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image480.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image480.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image480.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image239.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image239.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image239.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image246.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image246.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image246.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  42%|████▏     | 67/158 [00:12<00:10,  8.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image557.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image557.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image557.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image530.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image530.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image530.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image479.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image479.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image479.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image175.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image175.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image175.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image455.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image455.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image455.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image197.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image197.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image197.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image356.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image356.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image356.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image158.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image158.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image158.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  44%|████▎     | 69/158 [00:12<00:09,  9.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image399.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image399.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image399.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image202.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image202.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image202.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image322.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image322.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image322.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image4.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image4.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image4.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image525.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image525.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image525.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image386.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image386.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image386.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image152.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image152.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image152.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  45%|████▍     | 71/158 [00:12<00:09,  9.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image466.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image466.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image466.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image12.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image12.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image12.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image365.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image365.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image365.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image477.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image477.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image477.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image543.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image543.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image543.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image268.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image268.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image268.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image586.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image586.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image586.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  46%|████▌     | 73/158 [00:12<00:09,  8.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image336.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image336.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image336.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image274.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image274.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image274.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image503.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image503.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image503.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image129.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image129.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image129.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image447.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image447.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image447.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image561.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image561.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image561.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image233.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image233.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image233.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image313.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image313.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image313.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  47%|████▋     | 75/158 [00:12<00:08,  9.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image185.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image185.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image185.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image292.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image292.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image292.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image370.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image370.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image370.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image203.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image203.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image203.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image347.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image347.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image347.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image587.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image587.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image587.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image208.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image208.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image208.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image2.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image2.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image2.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  49%|████▊     | 77/158 [00:13<00:09,  8.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image658.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image658.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image658.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image597.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image597.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image597.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image140.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image140.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image140.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image574.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image574.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image574.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image266.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image266.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image266.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image457.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image457.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image457.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image289.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image289.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image289.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  50%|█████     | 79/158 [00:13<00:08,  8.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image123.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image123.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image123.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image131.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image131.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image131.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image360.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image360.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image360.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image470.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image470.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image470.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image213.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image213.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image213.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image554.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image554.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image554.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image309.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image309.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image309.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image167.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image167.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image167.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  51%|█████     | 80/158 [00:13<00:08,  8.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image19.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image19.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image19.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image298.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image298.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image298.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image579.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image579.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image579.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image577.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image577.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image577.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image228.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image228.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image228.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image497.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image497.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image497.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image349.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image349.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image349.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  51%|█████▏    | 81/158 [00:13<00:08,  8.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image199.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image199.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image199.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image65.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image65.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image65.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image317.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image317.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image317.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image393.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image393.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image393.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image47.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image47.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image47.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image211.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image211.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image211.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image252.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image252.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image252.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image178.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image178.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image178.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  53%|█████▎    | 84/158 [00:13<00:08,  8.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image229.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image229.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image229.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image230.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image230.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image230.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image576.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image576.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image576.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image179.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image179.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image179.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image225.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image225.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image225.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image204.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image204.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image204.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image550.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image550.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image550.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image334.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image334.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image334.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  54%|█████▍    | 86/158 [00:14<00:08,  8.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image286.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image286.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image286.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image364.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image364.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image364.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image269.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image269.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image269.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image247.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image247.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image247.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image187.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image187.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image187.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image634.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image634.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image634.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image236.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image236.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image236.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image617.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image617.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image617.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  56%|█████▌    | 88/158 [00:14<00:07,  9.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image439.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image439.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image439.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image328.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image328.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image328.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image532.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image532.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image532.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image464.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image464.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image464.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image613.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image613.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image613.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image206.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image206.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image206.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image427.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image427.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image427.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  57%|█████▋    | 90/158 [00:14<00:07,  8.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image240.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image240.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image240.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image181.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image181.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image181.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image105.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image105.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image105.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image216.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image216.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image216.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image425.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image425.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image425.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image355.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image355.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image355.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image15.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image15.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image15.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image43.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image43.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image43.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  58%|█████▊    | 92/158 [00:14<00:07,  9.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image419.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image419.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image419.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image433.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image433.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image433.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image49.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image49.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image49.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image193.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image193.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image193.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image251.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image251.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image251.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image510.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image510.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image510.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image260.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image260.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image260.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  59%|█████▉    | 94/158 [00:15<00:07,  9.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image625.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image625.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image625.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image414.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image414.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image414.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image623.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image623.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image623.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image413.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image413.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image413.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image66.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image66.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image66.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image411.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image411.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image411.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image34.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image34.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image34.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image125.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image125.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image125.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  61%|██████    | 96/158 [00:15<00:06,  9.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image220.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image220.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image220.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image156.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image156.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image156.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image287.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image287.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image287.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image276.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image276.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image276.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image171.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image171.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image171.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image493.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image493.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image493.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image132.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image132.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image132.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image653.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image653.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image653.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  62%|██████▏   | 98/158 [00:15<00:06,  9.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image234.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image234.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image234.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image436.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image436.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image436.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image281.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image281.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image281.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image542.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image542.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image542.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image437.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image437.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image437.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image113.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image113.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image113.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image533.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image533.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image533.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image337.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image337.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image337.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  63%|██████▎   | 100/158 [00:15<00:06,  8.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image507.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image507.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image507.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image359.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image359.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image359.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image120.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image120.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image120.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image330.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image330.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image330.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image621.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image621.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image621.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image619.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image619.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image619.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image573.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image573.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image573.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  64%|██████▍   | 101/158 [00:15<00:06,  8.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image635.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image635.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image635.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image163.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image163.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image163.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image342.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image342.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image342.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image333.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image333.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image333.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image272.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image272.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image272.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image344.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image344.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image344.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image106.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image106.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image106.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  65%|██████▌   | 103/158 [00:16<00:06,  9.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image667.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image667.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image667.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image473.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image473.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image473.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image142.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image142.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image142.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image223.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image223.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image223.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image160.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image160.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image160.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image111.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image111.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image111.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image559.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image559.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image559.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image48.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image48.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image48.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  66%|██████▋   | 105/158 [00:16<00:05,  9.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image666.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image666.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image666.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image384.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image384.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image384.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image409.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image409.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image409.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image217.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image217.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image217.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image122.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image122.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image122.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image61.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image61.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image61.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image636.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image636.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image636.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  68%|██████▊   | 107/158 [00:16<00:05,  8.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image348.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image348.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image348.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image135.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image135.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image135.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image11.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image11.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image11.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image201.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image201.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image201.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image282.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image282.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image282.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image526.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image526.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image526.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image146.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image146.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image146.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image523.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image523.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image523.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  69%|██████▉   | 109/158 [00:16<00:05,  9.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image504.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image504.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image504.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image420.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image420.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image420.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image382.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image382.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image382.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image459.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image459.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image459.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image335.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image335.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image335.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image303.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image303.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image303.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image431.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image431.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image431.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image198.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image198.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image198.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  70%|███████   | 111/158 [00:16<00:05,  9.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image184.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image184.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image184.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image512.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image512.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image512.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image566.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image566.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image566.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image224.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image224.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image224.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image28.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image28.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image28.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image182.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image182.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image182.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image511.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image511.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image511.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  71%|███████   | 112/158 [00:17<00:05,  8.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image259.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image259.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image259.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image263.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image263.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image263.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image387.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image387.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image387.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image444.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image444.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image444.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image501.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image501.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image501.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image498.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image498.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image498.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image602.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image602.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image602.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image630.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image630.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image630.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  73%|███████▎  | 115/158 [00:17<00:04,  9.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image484.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image484.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image484.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image172.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image172.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image172.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image481.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image481.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image481.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image528.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image528.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image528.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image24.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image24.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image24.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image108.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image108.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image108.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image306.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image306.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image306.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image352.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image352.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image352.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  74%|███████▍  | 117/158 [00:17<00:04,  9.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image631.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image631.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image631.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image620.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image620.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image620.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image422.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image422.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image422.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image506.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image506.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image506.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image290.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image290.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image290.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image445.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image445.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image445.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image628.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image628.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image628.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  75%|███████▍  | 118/158 [00:17<00:04,  8.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image392.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image392.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image392.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image5.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image5.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image5.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image565.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image565.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image565.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image250.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image250.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image250.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image377.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image377.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image377.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image490.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image490.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image490.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image104.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image104.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image104.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  76%|███████▌  | 120/158 [00:17<00:04,  8.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image3.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image3.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image3.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image588.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image588.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image588.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image640.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image640.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image640.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image505.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image505.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image505.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image177.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image177.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image177.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image401.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image401.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image401.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image264.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image264.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image264.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image226.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image226.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image226.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  77%|███████▋  | 122/158 [00:18<00:04,  8.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image657.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image657.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image657.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image389.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image389.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image389.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image320.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image320.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image320.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image341.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image341.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image341.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image633.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image633.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image633.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image642.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image642.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image642.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image575.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image575.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image575.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  78%|███████▊  | 124/158 [00:18<00:03,  8.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image417.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image417.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image417.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image571.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image571.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image571.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image270.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image270.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image270.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image489.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image489.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image489.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image610.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image610.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image610.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image373.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image373.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image373.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image53.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image53.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image53.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image508.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image508.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image508.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  80%|███████▉  | 126/158 [00:18<00:03,  9.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image644.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image644.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image644.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image606.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image606.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image606.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image593.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image593.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image593.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image257.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image257.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image257.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image254.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image254.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image254.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image109.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image109.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image109.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image449.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image449.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image449.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  81%|████████  | 128/158 [00:18<00:03,  9.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image410.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image410.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image410.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image210.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image210.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image210.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image655.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image655.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image655.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image157.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image157.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image157.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image300.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image300.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image300.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image660.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image660.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image660.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image238.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image238.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image238.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  82%|████████▏ | 129/158 [00:18<00:03,  8.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image394.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image394.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image394.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image446.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image446.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image446.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image599.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image599.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image599.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image64.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image64.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image64.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image366.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image366.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image366.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image6.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image6.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image6.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image476.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image476.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image476.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image456.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image456.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image456.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  84%|████████▎ | 132/158 [00:19<00:02,  9.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image308.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image308.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image308.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image580.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image580.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image580.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image378.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image378.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image378.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image517.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image517.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image517.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image601.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image601.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image601.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image502.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image502.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image502.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image544.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image544.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image544.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image327.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image327.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image327.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  84%|████████▍ | 133/158 [00:19<00:02,  9.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image288.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image288.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image288.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image397.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image397.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image397.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image117.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image117.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image117.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image538.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image538.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image538.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image323.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image323.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image323.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image416.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image416.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image416.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image343.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image343.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image343.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  85%|████████▌ | 135/158 [00:19<00:02,  9.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image369.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image369.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image369.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image478.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image478.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image478.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image119.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image119.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image119.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image562.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image562.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image562.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image639.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image639.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image639.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image291.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image291.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image291.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image460.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image460.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image460.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image590.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image590.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image590.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  87%|████████▋ | 137/158 [00:19<00:02,  9.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image475.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image475.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image475.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image232.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image232.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image232.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image638.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image638.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image638.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image321.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image321.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image321.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image279.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image279.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image279.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image319.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image319.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image319.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image22.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image22.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image22.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image110.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image110.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image110.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  88%|████████▊ | 139/158 [00:20<00:02,  9.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image316.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image316.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image316.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image626.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image626.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image626.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image612.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image612.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image612.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image430.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image430.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image430.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image541.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image541.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image541.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image296.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image296.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image296.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image33.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image33.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image33.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  89%|████████▉ | 141/158 [00:20<00:01,  9.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image186.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image186.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image186.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image398.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image398.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image398.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image326.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image326.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image326.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image474.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image474.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image474.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image304.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image304.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image304.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image454.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image454.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image454.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image531.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image531.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image531.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image315.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image315.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image315.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  91%|█████████ | 143/158 [00:20<00:01,  9.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image659.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image659.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image659.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image485.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image485.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image485.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image461.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image461.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image461.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image209.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image209.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image209.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image367.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image367.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image367.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image664.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image664.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image664.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image215.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image215.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image215.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image468.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image468.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image468.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  92%|█████████▏| 145/158 [00:20<00:01,  9.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image40.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image40.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image40.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image237.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image237.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image237.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image310.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image310.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image310.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image535.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image535.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image535.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image605.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image605.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image605.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image338.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image338.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image338.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image368.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image368.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image368.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  93%|█████████▎| 147/158 [00:20<00:01,  8.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image443.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image443.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image443.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image150.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image150.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image150.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image60.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image60.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image60.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image13.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image13.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image13.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image486.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image486.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image486.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image277.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image277.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image277.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image428.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image428.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image428.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image305.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image305.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image305.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  94%|█████████▍| 149/158 [00:21<00:00,  9.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image38.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image38.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image38.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image358.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image358.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image358.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image212.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image212.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image212.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image581.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image581.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image581.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image379.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image379.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image379.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image594.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image594.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image594.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image55.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image55.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image55.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image423.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image423.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image423.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  96%|█████████▌| 151/158 [00:21<00:00,  9.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image258.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image258.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image258.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image641.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image641.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image641.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image598.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image598.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image598.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image345.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image345.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image345.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image646.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image646.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image646.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image487.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image487.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image487.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image570.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image570.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image570.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:  96%|█████████▌| 152/158 [00:21<00:00,  9.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image244.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image244.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image244.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image448.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image448.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image448.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image190.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image190.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image190.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image513.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image513.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image513.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image248.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image248.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image248.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image521.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image521.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image521.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image324.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image324.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image324.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image50.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image50.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image50.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image568.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image568.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image568.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  98%|█████████▊| 155/158 [00:21<00:00,  9.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image548.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image548.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image548.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image42.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image42.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image42.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image284.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image284.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image284.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image318.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image318.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image318.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image509.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image509.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image509.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image407.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image407.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image407.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image145.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image145.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image145.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image482.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image482.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image482.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  99%|█████████▉| 157/158 [00:21<00:00,  9.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image100.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image100.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image100.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image314.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image314.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image314.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image1.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image1.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image1.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image429.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image429.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image429.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image403.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image403.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image403.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image297.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image297.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image297.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image618.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image618.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image618.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining: 100%|██████████| 158/158 [00:22<00:00,  7.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image331.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image331.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image331.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Loading files: /content/drive/MyDrive/Create_Dataset/Create_Dataset/sketches/image118.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/images/image118.png, /content/drive/MyDrive/Create_Dataset/Create_Dataset/prompts/image118.txt\n",
            "Loaded sketch image: (512, 512), Loaded target image: (512, 512)\n",
            "Error during pipeline forward pass: image must be passed and be one of PIL image, numpy array, torch tensor, list of PIL images, list of numpy arrays or list of torch tensors, but is <class 'NoneType'>\n"
          ]
        }
      ],
      "source": [
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "# Define a transform to convert tensors to PIL images if needed (but not used here)\n",
        "# to_pil = transforms.ToPILImage()\n",
        "\n",
        "pipeline.to(device)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    # Set the models to train mode\n",
        "    pipeline.unet.train()\n",
        "    pipeline.text_encoder.train()\n",
        "    pipeline.controlnet.train()\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "        # Move data to device\n",
        "        sketch_images = batch['sketch'].to(device)\n",
        "        target_images = batch['image'].to(device)\n",
        "        prompts = batch['prompt']\n",
        "\n",
        "        # Tokenize text prompts\n",
        "        text_inputs = tokenizer(prompts, padding=\"max_length\", return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # Check if any data is missing\n",
        "        if sketch_images is None or target_images is None or text_inputs is None:\n",
        "            print(f\"Skipping batch {idx} due to missing data.\")\n",
        "            continue\n",
        "\n",
        "        # Forward pass\n",
        "        try:\n",
        "            outputs = pipeline(\n",
        "                images=target_images,\n",
        "                controlnet_cond=sketch_images,\n",
        "                prompt=prompts\n",
        "            )\n",
        "        except TypeError as e:\n",
        "            print(f\"Error during pipeline forward pass: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Convert the output images to tensors if necessary for loss calculation\n",
        "        output_images_tensor = outputs.images.to(device)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = torch.nn.functional.mse_loss(output_images_tensor, target_images)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print loss for each batch\n",
        "        print(f\"Loss: {loss.item()}\")\n",
        "\n",
        "    # Save checkpoint\n",
        "    pipeline.save_pretrained(f\"./model_checkpoint_epoch_{epoch+1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUf1cpxFw006",
        "outputId": "3639d013-2aea-46e5-9323-f61b4f014bc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuning complete.\n",
            "Model saved.\n"
          ]
        }
      ],
      "source": [
        "print(\"Fine-tuning complete.\")\n",
        "pipeline.save_pretrained(\"/content/final_model\")\n",
        "print(\"Model saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hus0G8SwxHcQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "0ebd5ff9b1fd49a48795d4faed79f1b4",
            "651ac9e7c8da4913890851f0d46644ad",
            "0820a82049d74d42ac2a87d144a5036d",
            "d5e0146742494b25be31f0272addfbc4",
            "47e0b39a9f774990aaf0985f8136dd30",
            "39ba0971bd864003aaaeef3b76957bcb",
            "4756da0158d54d818ee776a92c0d71e9",
            "805d3573401f488fa951d27736d1f5aa",
            "214620b7e45541a9b610308d26b019d7",
            "56fd2848df154b749e0ae3a8b4245933",
            "7479119f365246149078ba560aa95ac7",
            "5729bd7b54bd45588e24515e13f7e936",
            "18b0b95cef9c431a8df7c1f47692716c",
            "4fb53e7c0f40450a86ff3a5bb8b3d0f6",
            "e4ace33ba3ee41ae873641644bea0308",
            "bc7b3b571d0a4039bb06560632565aa2",
            "8f205555d1ca4ac8bdafeba061d55e42",
            "3640701102ea495eacec6e17e284b7f1",
            "9291f15e4e0845388abc1d71d5fd7ab4",
            "90d71ed7cb3442578cd7b096536fccf9",
            "0c7100d5a4a14f0e802cc12cd444cab3",
            "e617b650e35a49aeac2ff5ba669e379e"
          ]
        },
        "id": "Nld7oK63RJIo",
        "outputId": "81372f8c-78b6-4ba5-dcc4-ab942ae0f517"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ebd5ff9b1fd49a48795d4faed79f1b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "It seems like you have activated model offloading by calling `enable_model_cpu_offload`, but are now manually moving the pipeline to GPU. It is strongly recommended against doing so as memory gains from offloading are likely to be lost. Offloading automatically takes care of moving the individual components vae, text_encoder, text_encoder_2, tokenizer, tokenizer_2, unet, controlnet, scheduler, feature_extractor, image_encoder to GPU when needed. To make sure offloading works as expected, you should consider moving the pipeline back to CPU: `pipeline.to('cpu')` or removing the move altogether if you use offloading.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5729bd7b54bd45588e24515e13f7e936",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image saved successfully!\n"
          ]
        }
      ],
      "source": [
        "from diffusers import StableDiffusionXLControlNetPipeline, ControlNetModel\n",
        "from transformers import CLIPTokenizer\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Load model and tokenizers\n",
        "model_path = \"/content/final_model\"\n",
        "controlnet_path = \"xinsir/controlnet-scribble-sdxl-1.0\"\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "# Load ControlNet\n",
        "controlnet = ControlNetModel.from_pretrained(controlnet_path, torch_dtype=torch.float16)\n",
        "\n",
        "# Initialize the pipeline with ControlNet\n",
        "pipeline = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
        "    model_path,\n",
        "    tokenizer=tokenizer,\n",
        "    tokenizer_2=tokenizer,\n",
        "    controlnet=controlnet,\n",
        "    torch_dtype=torch.float16  # Use float16 precision\n",
        ")\n",
        "\n",
        "# Apply memory optimizations\n",
        "pipeline.enable_attention_slicing(\"auto\")  # Enable memory efficient attention\n",
        "pipeline.enable_model_cpu_offload()  # Offload layers to CPU when not in use\n",
        "\n",
        "# Move pipeline to GPU\n",
        "pipeline.to(\"cpu\")\n",
        "\n",
        "# Load and preprocess the sketch image\n",
        "sketch_image_path = \"/content/drive/MyDrive/check1.png\"\n",
        "try:\n",
        "    sketch_image = Image.open(sketch_image_path).convert(\"RGB\")\n",
        "    sketch_image = sketch_image.resize((512, 512))\n",
        "    sketch_image = torch.from_numpy(np.array(sketch_image)).permute(2, 0, 1).unsqueeze(0).to(\"cuda\").half()\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Error loading the sketch image: {e}\")\n",
        "\n",
        "# Define the prompt\n",
        "prompt = \"A colored textile pattern that looks similar to the sketch pattern I gave, a pleasing textile pattern.\"\n",
        "\n",
        "# Generate the output\n",
        "with torch.no_grad():\n",
        "    output = pipeline(\n",
        "        prompt=prompt,\n",
        "        image=sketch_image,\n",
        "        controlnet_conditioning_scale=1.0,\n",
        "        guidance_scale=7.5,\n",
        "    )\n",
        "\n",
        "# Display and save the output image\n",
        "output_image = output.images[0]\n",
        "output_image.show()\n",
        "output_image.save(\"/content/drive/MyDrive/generated_image.png\")\n",
        "print(\"Image saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2fo_EKV193e",
        "outputId": "54754df1-45d8-4672-8e53-1879e283a237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/282.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m276.5/282.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.4/282.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/510.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.0/510.0 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install diffusers transformers controlnet-aux --quiet\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --quiet\n",
        "!pip install opencv-python-headless pillow --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 897,
          "referenced_widgets": [
            "59d739c76f9f4511a885cc6cc1a4924e",
            "044f65dd855c48acb0f87c358455b5d8",
            "59d32a27ecaf40ddb53f25525eeef6dc",
            "f8c0c5bafcb74519877418328024c161",
            "0b83863d3e904622a0af54740f7698d4",
            "63384619ed4b4d9584cbd7006b18eb43",
            "8d8267f6a8994dac870c094ec7ee882b",
            "2702bf6d999b4d809f2a3a94b4d98c4f",
            "44b348752a8e49eb944c4758b854267e",
            "769b124249a64db483011693172b3728",
            "f6acc6f583814459b92c6732eb4a6489",
            "952eef74193b450bba4ce4139df2245e",
            "1086f2a7d8d646ffa27d63c56ad9413a",
            "d8a58d67f42c4d0685b10dae8bd7f359",
            "681b9dd0d3634b3fa52009cb36553369",
            "06f0c83e9608449a9846d362f5c69bcd",
            "c17c57de7e334cdeb5301895a50ade72",
            "abbd17d9f5794093b18ed245b6d67768",
            "db87273869e9478bbc848186727eb70c",
            "ecd71d48780846aa83f6e740aab08c38",
            "45e9999d81fb40359095d28ec6dc0f54",
            "d97fe47f723c441ca563e9fdf60390ad",
            "4fe3689205494c669a9ff315ca26e8ad",
            "781a4acc44c4476c9b7ed3b7937b5f4d",
            "6edce9449b0c4ef9a704e609314994d7",
            "b7558040759a40db8e55395f94bbb23b",
            "5cc8891593754a75a3b1d81e1458cfdc",
            "55026358f3a1440b8b1b2a96b01e27cf",
            "2bdc3c82c13146ada1b2a8261245f5c7",
            "779ccb06116a4c7ab631d5f8e739f816",
            "768cf24ae7534ec5ba89f089dca41c41",
            "f3371dadb6f84d69a7145642052e5621",
            "2751d0bdbbeb48418f9fe9fb0d415bc4",
            "fcd1c7c99d9143a581de4012a424e32b",
            "15d85fb5b0174b938ab8fca8357ff1db",
            "9d24c846f7f54219b935c8fae320e236",
            "27dbbb8acc50431d9f61fee633383e4c",
            "391266aa5965470caadf361de11c92c4",
            "8b404badcde74f9eb40227311a07ccbb",
            "0f6171f1f05149c39abb23d473085e91",
            "076269715a2140eaa549ddb8863ed854",
            "f223769289a5462e851c4e72958b3099",
            "0e5f7d0f709f487c8859e26145ad44be",
            "e697e70e4c5f45aba7038f2df017f98f",
            "bcffd6ad9f7b4694aa8343f76449b406",
            "ede2ac99c29946518c9441f75438b221",
            "ac11cd34bd2f4a9685dcb421f13a0c66",
            "e2173be2c6d6418f90683b2f3750bcf1",
            "00711f6476c0452e8c53e038e8cc1b6f",
            "af420b380d1c4671a8b895d415a09e1c",
            "cb01922c589843348b8891a2559fc020",
            "41725e1c7ec24043a10a0d9259e2589d",
            "0113d7bfcf734340b2d58f046fd1a3a2",
            "a6c77bb9fe9d4bb6bbb0860782da86ef",
            "7e85f97d98b64f688818f91658f6fbe2",
            "007ad1171aca404bba3f2749fe165677",
            "64288953735d47c8a8b219536dc3d23b",
            "51ccdbe91a0346b9aae36b2b92c51033",
            "06d6f31c844e4da39bdc21e3bdd74081",
            "52a5da1f67db43d5b1ba693f0e7b5266",
            "8432a23539f947bb8e8d2b7732af1bc9",
            "6f352b15666a44c0bcd91d99b7851d07",
            "8f101f427915497398e25f8c7c921b65",
            "7003c4c2b647416993fd82a41963dda4",
            "4234d7175c264d7eaf4d6c32dc2dc669",
            "40a5d8f8280d4d4a9466091f17a1e9c9",
            "2228b0c7195e49d78cd66b182bd61797",
            "3a29d1fbd6644af3b89007c66bc65ee4",
            "747be79329d84728a6d3f8af9c393557",
            "a209a454daf54dfdb819439b7b871758",
            "069aac0963e9489584d1cdcff4176f1d",
            "0e6456d5d3a14e0cb1289b9a13730b74",
            "3add4f4359364a2b846d14e81626f38f",
            "6e22ef5b91ad408987330c36c62908f1",
            "79d596731844453eb5e6ce5355857843",
            "a45f88abf4fe4a5794875106f2cab296",
            "10d9e2a49a8e4215882b576343feba50",
            "1aa0c29da19243b1acc29e854d8f3a91",
            "457e085df8cc4b389577bc860f3e8e73",
            "0708d8f9b27340f9856fe62bee0aba86",
            "ec0bc06282b6467e84d9d078f3311aa7",
            "81347750927d4a68853f150d3315687c",
            "a4bcbdd42a214a089aa0704c0603f9b5",
            "056de1d8d2094d248796c12d831a7a08",
            "a52d8d49fc864dc9ba8449a1308e964c",
            "06dd03cee3a246589680b0d8400e2e71",
            "1f5e0d4fcb864777ba1e26183bf95ec2",
            "30e0493ca3064d658957fd02b749fb3a",
            "48b2c1f1e7434b92b00b3d23236949cb",
            "d7b9259bce924c95b977531f6f796f0c",
            "921f89d8a5be4fd3b231d833e0c3534a",
            "0972f5f45b3d4d6d997794adaf42d988",
            "b714b3a199744e58adce7508c9f9ca23",
            "a88f88408e5a4f048425d404ff020b9f",
            "f0d382cbab6247f5abc187f90dae17e3",
            "93d2fcd8a2ce4c73890e99df0fe00b5e",
            "e4ba3dd178d44d62b8b0fa6bcf67118f",
            "25cad132d92c44d09d08e283e2268481",
            "1f3ebbbf009943b48a6fae48fa92f596",
            "e28a840d071e447c9232a95e99a634ec",
            "776725c48b0c491691670ded8de55dee",
            "76a0764a524f43dfa93819ca9ecff5ba",
            "8d32100bc2564dee8b7cc2b043e73db8",
            "77f37be86c8445c9a3c2f4de58534736",
            "9bd9508dcbe349d6ac68129082bf74b6",
            "2e81d536c7b24c558564409c2c18eb87",
            "7048bcf07fc14c84a7bc549ab1fa12a8",
            "8d5b1f21b53f4a1aa077617579523d7b",
            "011d2ccd58c6484e92ccdf11461abd2b",
            "4d57aed7f42b4d60b6cdfba08fcfdb8e",
            "f8501cd6f1a14b7da61018ffa37bbd07",
            "6498f1599d75411eafba907fbc946ad8",
            "d352f6d57b39431f8e612a9cfb26f3ff",
            "ee43e34fa59c43c8a6a08f5bbd605509",
            "3f77fdb9c7d649b5b4e7528ea74fef83",
            "a338a3c5ca594e8581bd25830a82a4f6",
            "74657ba839584071ade50a4025552d56",
            "ffab9401c2b041a0a6d1864de946e7b5",
            "58fd0e73b79d4788a70e692a08a338d7",
            "c98d688caac44e129c8920dc6fc06388",
            "fc608c71d5a7488689ebdb07bef6aaa5",
            "dfea8e343e4b473b8657c9b51909ee10",
            "ff2c9ccafee04cfeab5db052b7c97ab3",
            "a635f43a1d674bc698e4ccbf1a6bd8d9",
            "a71f6326ad5f441fa21a00e7e6b92dfb",
            "76c5ff27de444c50916e8436f86821c8",
            "a2869e04e2fc44348a8767a2b0eba392",
            "5b727c3656a14c5c8a533d1e8a0d1345",
            "7ed265597290420fa2f768ea7102bc0b",
            "129f124d7e704403ae4638d57ba1f175",
            "80856a2836544aa7933e580a2c7e6871",
            "aeeaa36ba00e47e8a142de1650e007d9",
            "d3c69b48c0de4b90b6d063d1828ea87b",
            "eed149a5d2cb44faaf19063c537225c4",
            "d0f1df4a66334726a30db120f31f9ace",
            "32c8c134d2c849ff84edb613b68c1d44",
            "49b97361d95a49b0bd085705e86d2f08",
            "29a54fda5730418bb83df4884697f9a1",
            "55caa26773134bdbbb04d4102156e831",
            "b3f2bf8ab34947d28a18259bf8300a7a",
            "0b4dc249702c46cf8667c2dbf851a4ba",
            "4126701d0b9b4ff2babee7cd8dfaa21b",
            "22d1697b59a44b5e908acfef3de1ace9",
            "cb3768ff817041418edbee5ff21a0888",
            "c01da5c6733e4b519756c41bf2a6538a",
            "cc2636365f1d4b79995def48a3f7d9d2",
            "174c36947efb414f9c9007b09a1a03d4",
            "b96f876d38c3485b928c546c7f4de239",
            "9e46975ddeb24c2bab80d628f7563627",
            "08521b337d754fc88cbab3546096259e",
            "eaa2b30fda18435393630336641f4221",
            "72b45a7433b34f9c82891d999eeebc31",
            "e8a53a5eb2c1410898ef886454c0d8df",
            "3a269414e7d04c2199bd5daabdc2cd8a",
            "70d7bb3d3eda4aa2a9325e3fc7fd2bb7",
            "67d303b7feca4aee926acfbdb1981079",
            "4caa3bbcd51e4861ab84ef9e46bd9f0c",
            "188a3c5f2d554f38b24e3eac7a2d5653",
            "750607a260504a21b1d891a952ee53d6",
            "168115c4992146998042eb2ade6c329a",
            "b35ebbea6c4f4919acea89d40f5e3916",
            "501968f2e8c3402188552c66db9ebe68",
            "30ef25fb25e84e6a86c3351e02fad380",
            "f7402fe98378473bbe4fdc0d0340230d",
            "01c6da52ed2246ffa329839fa67d299c",
            "45477907cd70476ebc3972945776bcd4",
            "c58a6f9e4667468dbc2d4d8a61c5dcee",
            "7548d4e6447e42b5a136ff95dfe642fb",
            "53935857af824144b9cb1cdbc013e5ed",
            "be8d39aa24ec49408a8d16e346693e32",
            "30dff80ba7cf4563a09bd42f0b35167d",
            "bf4edd1beda747b39ce268c7a0954675",
            "f9559abe488d4441aa394de5cb003b38",
            "7eb5e119c73f4414829f4609cfb6bd0d",
            "835ebe7535a24630b43a4dda6164008f",
            "fddbc3b3a75e40ecbdfbf387820de538",
            "093b3b9299894229880c7b37d6708237",
            "ca1dadcb959b4f65bc8b34db9c6fc114",
            "ef06048f2b534ddc8d75927a42325c18",
            "ceef3ff67eb84efba8470c157b18d0a9",
            "366376049a324426866bd1e3c1c83125",
            "e26b8b28f40948c7add10d9658e30bda",
            "420e9e6ae622439ca44c809600fc3970",
            "11af2a41f18f4387976ce896eb90766e",
            "9532e5c867ef46d3a9fd2a26608014eb",
            "c67b7ee1a09f4bb1b0a386de7b380153",
            "19ea31f2360f4fc3852725ec09190db1",
            "dec52e2dfb334ae0abc2738d56f4a04e",
            "f53e9fc6c5d640c0807b6d8819b5db9d",
            "21e65a844f754ce2ab2336e8b2ff75ca",
            "b863d51c1d1e4123be7839905346da64",
            "8a8c5d9e487b446ba727726beb92b699",
            "0459b3f8e0a6421584573955f38b6ef6",
            "64855f125ae44fe78ff31fa825ff09b1",
            "3c72786637634cadafc6e7828d408dd1",
            "0b1fe36c5ae442358a6163b3e9f0c11d",
            "86d7a7f904724067bb576d6b7583b371",
            "39d5f4be9b41435eabb7786257f3a7c8",
            "7dce93d1135048f8b3bb31d0c90d3791",
            "dd7bd3ae52804a6aaca5db7837c80bd3",
            "a9a6a95546904cdeb97bce62ef9a45eb",
            "0dd5f42206d9428398a6ea9fd86a3374",
            "67cf61f197e94ac78779e90d638837f3",
            "5f28259fbc214a98965194a9da82d82f",
            "747b84b1adde4962b8d9d36c1d6d44c0",
            "b9705a6f9bd54243829d4a681272af55",
            "ae64ef0fe22e4497ad6a69dc93edd004",
            "2ed20a6749c44673b6cbc97022c97ac3",
            "4d1f4966b6894e4081330050e8c7b7d1",
            "4ef6691309754418ad14b3dd324a75a3",
            "7df71b3d187441e8a615c2f74789d491",
            "d494e712bd994fa3a5071adb6fccfc55",
            "107d82afd6664e6b929b63895a0572ce",
            "57fd398fbd66433fadc3bffd797f4ff2",
            "85f308672ea34437a617f10bc702ea54",
            "5c6f705b9c0844148af76adef7ac22bb",
            "e2970c4f298248ed923804c0dff3e0cf",
            "525948aaa8d042768b2c2010d5838cdd",
            "71ce1ae673ec4c1c843c2af85cc4e9db",
            "6ebc0201d1304a95be3740b545ce961c",
            "d4fac2a0bcdc41a8b9026c650ab454bd",
            "85fe24efb45843b8b960e9961b5d6c70",
            "eb74834bf3d94106b91726d290000635",
            "b036f81726244db2b749f9c23c9cfd2e",
            "09e3149c33b7427fb5d6bd3d2667e246",
            "e9cd41740dc24239b99914e36432d729",
            "0aed79556aa346d682e09e1653c6a843",
            "b51f68ac4d994356bcabf124bc9971b1",
            "3bbdc47ad28341c999676d974b4ca14d",
            "7ee88877b1354a50aad77c6d5ec03e64",
            "655b1ece6bb24255a6d476f69cf1a3a7",
            "beded9de684b4821b3818a4b4a12dd43",
            "0ef949bb877a409dadf9720c9057cf07",
            "c0846654957143ae8c1cf7f7f0a9a3bb",
            "4fa08ee7392d4a378fd20a273780de04",
            "fd5ad7745d8241e98da69a479332b36b",
            "7ebbdf5a04f84542bfdba07ae251a1aa",
            "f9cb1e8477c54863bc2061d2844d55dc",
            "cbba41afe0e04b39ae3da6029955645b",
            "ca1bed64d245432a9e25be3afc017583",
            "6f52b05b37b34e23b47462fc18726e9c",
            "7bc430ca7a0c44ec922764ed43b82ba1"
          ]
        },
        "id": "ZiWDXT6dkfBt",
        "outputId": "b0611380-5a5e-4c80-d54b-c71830529cd4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59d739c76f9f4511a885cc6cc1a4924e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "scheduler/scheduler_config.json:   0%|          | 0.00/681 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "952eef74193b450bba4ce4139df2245e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "controlnet/config.json:   0%|          | 0.00/1.34k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fe3689205494c669a9ff315ca26e8ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/2.50G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcd1c7c99d9143a581de4012a424e32b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcffd6ad9f7b4694aa8343f76449b406",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "007ad1171aca404bba3f2749fe165677",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model_index.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2228b0c7195e49d78cd66b182bd61797",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1aa0c29da19243b1acc29e854d8f3a91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48b2c1f1e7434b92b00b3d23236949cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "text_encoder/config.json:   0%|          | 0.00/565 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e28a840d071e447c9232a95e99a634ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8501cd6f1a14b7da61018ffa37bbd07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "text_encoder_2/config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfea8e343e4b473b8657c9b51909ee10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3c69b48c0de4b90b6d063d1828ea87b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer/tokenizer_config.json:   0%|          | 0.00/737 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb3768ff817041418edbee5ff21a0888",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer/special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70d7bb3d3eda4aa2a9325e3fc7fd2bb7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.78G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45477907cd70476ebc3972945776bcd4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_2/special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "093b3b9299894229880c7b37d6708237",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_2/tokenizer_config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dec52e2dfb334ae0abc2738d56f4a04e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "unet/config.json:   0%|          | 0.00/1.68k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7dce93d1135048f8b3bb31d0c90d3791",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ef6691309754418ad14b3dd324a75a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/10.3G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Keyword arguments {'safety_checker': None} are not expected by StableDiffusionXLControlNetPipeline and will be ignored.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4fac2a0bcdc41a8b9026c650ab454bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
            "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
            "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
            "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
            "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "beded9de684b4821b3818a4b4a12dd43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Import libraries\n",
        "from diffusers import ControlNetModel, StableDiffusionXLControlNetPipeline, AutoencoderKL, EulerAncestralDiscreteScheduler\n",
        "from controlnet_aux import HEDdetector\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import os\n",
        "from google.colab import drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# Function to apply Non-Maximum Suppression (NMS)\n",
        "def nms(x, t, s):\n",
        "    x = cv2.GaussianBlur(x.astype(np.float32), (0, 0), s)\n",
        "    f1 = np.array([[0, 0, 0], [1, 1, 1], [0, 0, 0]], dtype=np.uint8)\n",
        "    f2 = np.array([[0, 1, 0], [0, 1, 0], [0, 1, 0]], dtype=np.uint8)\n",
        "    f3 = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]], dtype=np.uint8)\n",
        "    f4 = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0]], dtype=np.uint8)\n",
        "\n",
        "    y = np.zeros_like(x)\n",
        "    for f in [f1, f2, f3, f4]:\n",
        "        np.putmask(y, cv2.dilate(x, kernel=f) == x, x)\n",
        "\n",
        "    z = np.zeros_like(y, dtype=np.uint8)\n",
        "    z[y > t] = 255\n",
        "    return z\n",
        "\n",
        "# Set up model parameters\n",
        "controlnet_conditioning_scale = 1.0\n",
        "prompt = \"A high-quality rightly colored detailed version of the sketch, realistic and vibrant like a textle pattern.\"\n",
        "negative_prompt = 'lowres, bad anatomy, bad hands, missing fingers, extra digit, low quality'\n",
        "\n",
        "# Load the scheduler and model\n",
        "#eulera_scheduler = EulerAncestralDiscreteScheduler.from_pretrained(\"/content/final_model\", subfolder=\"scheduler\")\n",
        "eulera_scheduler = EulerAncestralDiscreteScheduler.from_pretrained(\"fyp1/sketchToImage\", subfolder=\"scheduler\")\n",
        "\n",
        "#controlnet = ControlNetModel.from_pretrained(\"/content/final_model/controlnet\", torch_dtype=torch.float16)\n",
        "controlnet = ControlNetModel.from_pretrained(\"fyp1/sketchToImage\", subfolder=\"controlnet\", torch_dtype=torch.float16)\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "\n",
        "pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    controlnet=controlnet,\n",
        "    vae=vae,\n",
        "    safety_checker=None,\n",
        "    torch_dtype=torch.float16,\n",
        "    scheduler=eulera_scheduler,\n",
        ").to(\"cpu\")\n",
        "\n",
        "# Load your pencil sketch\n",
        "uploaded_sketch_path = \"/content/drive/MyDrive/image19.png\"  # Update with your sketch path\n",
        "controlnet_img = Image.open(uploaded_sketch_path).convert(\"L\")  # Ensure it's grayscale\n",
        "\n",
        "# Pre-process sketch\n",
        "controlnet_img = controlnet_img.resize((1024, 1024))\n",
        "\n",
        "# Run the pipeline to generate the image from your sketch\n",
        "images = pipe(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    image=controlnet_img,\n",
        "    controlnet_conditioning_scale=controlnet_conditioning_scale,\n",
        "    width=1024,\n",
        "    height=1024,\n",
        "    num_inference_steps=30,\n",
        ").images\n",
        "\n",
        "# Save and display the generated image\n",
        "output_path = \"/content/drive/MyDrive/generated_image.png\"\n",
        "images[0].save(output_path)\n",
        "images[0].show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha9sQrrZQYUm",
        "outputId": "a540b119-94e4-408b-df59-80ebd0010a80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Fine-tuning complete. Model saved to /content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "pipeline.save_pretrained('/content/drive/MyDrive')\n",
        "print(f\"Fine-tuning complete. Model saved to {'/content/drive/MyDrive'}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "125b-cvD7VFybKwcikBiL2Tg1sEwo1RdU",
      "authorship_tag": "ABX9TyMX1gQ9XQMD+ADEPT25u9gl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00711f6476c0452e8c53e038e8cc1b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "007ad1171aca404bba3f2749fe165677": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64288953735d47c8a8b219536dc3d23b",
              "IPY_MODEL_51ccdbe91a0346b9aae36b2b92c51033",
              "IPY_MODEL_06d6f31c844e4da39bdc21e3bdd74081"
            ],
            "layout": "IPY_MODEL_52a5da1f67db43d5b1ba693f0e7b5266"
          }
        },
        "0113d7bfcf734340b2d58f046fd1a3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "011d2ccd58c6484e92ccdf11461abd2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01c6da52ed2246ffa329839fa67d299c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01e3fef2b05a4a69abd43cd47beb8d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01e9755e67fa41be9f13d2d4524c2c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01e97aa7317e4c6cbf2a36d6fe7d6b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "023df8b8c986436182a7fb62fa00dc44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03fe68b9f32445c2b7de6dc316482e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "044f65dd855c48acb0f87c358455b5d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63384619ed4b4d9584cbd7006b18eb43",
            "placeholder": "​",
            "style": "IPY_MODEL_8d8267f6a8994dac870c094ec7ee882b",
            "value": "scheduler/scheduler_config.json: 100%"
          }
        },
        "0459b3f8e0a6421584573955f38b6ef6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "049f09d6eec640728d87b0e560ca7781": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "056de1d8d2094d248796c12d831a7a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05d8815c6a48408b8edf6237a4ba918e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dffd445613e14dbfad06ba358130c614",
            "placeholder": "​",
            "style": "IPY_MODEL_15c1af039e7648e0b8895756f1b16480",
            "value": " 460/460 [00:00&lt;00:00, 27.7kB/s]"
          }
        },
        "05fedefbfd86470e9b13cc2857e665a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "069aac0963e9489584d1cdcff4176f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06bd1486d1b0499dbb7f56d2b06fe30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06d6f31c844e4da39bdc21e3bdd74081": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4234d7175c264d7eaf4d6c32dc2dc669",
            "placeholder": "​",
            "style": "IPY_MODEL_40a5d8f8280d4d4a9466091f17a1e9c9",
            "value": " 609/609 [00:00&lt;00:00, 20.8kB/s]"
          }
        },
        "06dd03cee3a246589680b0d8400e2e71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06f0c83e9608449a9846d362f5c69bcd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0708d8f9b27340f9856fe62bee0aba86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a52d8d49fc864dc9ba8449a1308e964c",
            "max": 492265168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06dd03cee3a246589680b0d8400e2e71",
            "value": 492265168
          }
        },
        "076269715a2140eaa549ddb8863ed854": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0820a82049d74d42ac2a87d144a5036d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_805d3573401f488fa951d27736d1f5aa",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_214620b7e45541a9b610308d26b019d7",
            "value": 8
          }
        },
        "08457ab478f84666ac65f9a1025dc25b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da05c48746e14d1e9cf528f5cd9bb930",
              "IPY_MODEL_a55dd58544c3410782491fbb9fa36463",
              "IPY_MODEL_7ac0a1b9dfd84485a7eaca671c8610cb"
            ],
            "layout": "IPY_MODEL_e09ffc6c839e456685cf890c2261d1e1"
          }
        },
        "08521b337d754fc88cbab3546096259e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "093b3b9299894229880c7b37d6708237": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca1dadcb959b4f65bc8b34db9c6fc114",
              "IPY_MODEL_ef06048f2b534ddc8d75927a42325c18",
              "IPY_MODEL_ceef3ff67eb84efba8470c157b18d0a9"
            ],
            "layout": "IPY_MODEL_366376049a324426866bd1e3c1c83125"
          }
        },
        "0972f5f45b3d4d6d997794adaf42d988": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25cad132d92c44d09d08e283e2268481",
            "placeholder": "​",
            "style": "IPY_MODEL_1f3ebbbf009943b48a6fae48fa92f596",
            "value": " 565/565 [00:00&lt;00:00, 5.07kB/s]"
          }
        },
        "097f9e49117e4ee98990a0c21985363e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09db989912774f888c3ebded60872a8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09e3149c33b7427fb5d6bd3d2667e246": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aed79556aa346d682e09e1653c6a843": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b1fe36c5ae442358a6163b3e9f0c11d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b4dc249702c46cf8667c2dbf851a4ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b83863d3e904622a0af54740f7698d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c00ad25b49a4d31b8596b7111ad5af3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c0817ade2b7457cbe418b2bb6114c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6212801c1c0f4365887d686725ded172",
            "max": 575,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25be8896b50643a2b19d55f904efbf8c",
            "value": 575
          }
        },
        "0c7100d5a4a14f0e802cc12cd444cab3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d010e343c844257aa2e30b01bf9d0a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f66cbfe44144c2c8db29234b8fd5c84",
            "placeholder": "​",
            "style": "IPY_MODEL_cf8b994c556a4fb4a51f2ef29e2a2fdd",
            "value": " 905/905 [00:00&lt;00:00, 73.6kB/s]"
          }
        },
        "0d4e4e52a589466ab1487289c847201b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e883f8f23f8747d690cabb0da75b0736",
            "placeholder": "​",
            "style": "IPY_MODEL_e3bb675ccd8944888e7af081f3bfaec9",
            "value": " 335M/335M [00:02&lt;00:00, 120MB/s]"
          }
        },
        "0d9076ea15c346f59da4867bbb8b6035": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fef115a939cc433a81d51f5951186197",
            "placeholder": "​",
            "style": "IPY_MODEL_184f72957c324d75b0039f0060c26793",
            "value": "text_encoder/config.json: 100%"
          }
        },
        "0da5f2d1e7ae405ba2321a74091a5e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83cd3e5f4a224afd98e08213750d0a24",
              "IPY_MODEL_673619c4850c48b199841817183f2c19",
              "IPY_MODEL_62748d3f85c24ab7b9ce3179a02ca325"
            ],
            "layout": "IPY_MODEL_56f46d27d04141ab806f46ae1dacfd15"
          }
        },
        "0dbf6f16b384469283b40d5be01706c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d08fcee21724076b37f432369f2525f",
            "max": 334643268,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01e3fef2b05a4a69abd43cd47beb8d54",
            "value": 334643268
          }
        },
        "0dd5f42206d9428398a6ea9fd86a3374": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ed20a6749c44673b6cbc97022c97ac3",
            "placeholder": "​",
            "style": "IPY_MODEL_4d1f4966b6894e4081330050e8c7b7d1",
            "value": " 335M/335M [00:07&lt;00:00, 53.6MB/s]"
          }
        },
        "0e2f34dc713240c28dd69b26d592c43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de58984a44c64634a2558af489d7aa70",
            "placeholder": "​",
            "style": "IPY_MODEL_f85fe08ec3474bbaa2dd00aeec83cff8",
            "value": "tokenizer/merges.txt: 100%"
          }
        },
        "0e5f7d0f709f487c8859e26145ad44be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e6456d5d3a14e0cb1289b9a13730b74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e9ffd1e62114a1892aada0b072d6c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_490d40c726004b2a8f6d281df4c9ae31",
            "placeholder": "​",
            "style": "IPY_MODEL_31559917ad99484592e1d400a8de4db4",
            "value": " 17/17 [00:56&lt;00:00,  3.79s/it]"
          }
        },
        "0eb92dcbb27a4f23ba9cd0da5fa95b65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ebd5ff9b1fd49a48795d4faed79f1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_651ac9e7c8da4913890851f0d46644ad",
              "IPY_MODEL_0820a82049d74d42ac2a87d144a5036d",
              "IPY_MODEL_d5e0146742494b25be31f0272addfbc4"
            ],
            "layout": "IPY_MODEL_47e0b39a9f774990aaf0985f8136dd30"
          }
        },
        "0ebfad027fe247f6af0eece055c9f47d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ef949bb877a409dadf9720c9057cf07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ebbdf5a04f84542bfdba07ae251a1aa",
            "placeholder": "​",
            "style": "IPY_MODEL_f9cb1e8477c54863bc2061d2844d55dc",
            "value": "  0%"
          }
        },
        "0f6171f1f05149c39abb23d473085e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f9fb2231cfd409ea3a3b90c624bb397": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "107d82afd6664e6b929b63895a0572ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71ce1ae673ec4c1c843c2af85cc4e9db",
            "placeholder": "​",
            "style": "IPY_MODEL_6ebc0201d1304a95be3740b545ce961c",
            "value": " 10.3G/10.3G [01:24&lt;00:00, 217MB/s]"
          }
        },
        "1086f2a7d8d646ffa27d63c56ad9413a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c17c57de7e334cdeb5301895a50ade72",
            "placeholder": "​",
            "style": "IPY_MODEL_abbd17d9f5794093b18ed245b6d67768",
            "value": "controlnet/config.json: 100%"
          }
        },
        "109b8475eb9246da82dae34e221946bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10d9e2a49a8e4215882b576343feba50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11807a9968bc4b7e9d6eeba3e0ee576e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11af2a41f18f4387976ce896eb90766e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "127c80d36bc24d45aa9132a7fb173a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "129f124d7e704403ae4638d57ba1f175": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12ff6cb95288405189782621d5dea0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70743e7af2fd4215957889434899bde5",
            "max": 609,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39a5b7cfaffe4dd5b206e29935bcb6e4",
            "value": 609
          }
        },
        "13f908051d2b416fbf10e21cf79baab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56330b139b124cf0871d3ddbb2dd9b50",
              "IPY_MODEL_4dd540b7c7a7479f8b688b5d87085a18",
              "IPY_MODEL_e8cf0232c6854ce3a6adab4dcb350446"
            ],
            "layout": "IPY_MODEL_4475f88bc7c5418aa89b32787eccf1fd"
          }
        },
        "14881852ea964905932858987e401e62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15c1af039e7648e0b8895756f1b16480": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15d85fb5b0174b938ab8fca8357ff1db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b404badcde74f9eb40227311a07ccbb",
            "placeholder": "​",
            "style": "IPY_MODEL_0f6171f1f05149c39abb23d473085e91",
            "value": "config.json: 100%"
          }
        },
        "168115c4992146998042eb2ade6c329a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "174c36947efb414f9c9007b09a1a03d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8a53a5eb2c1410898ef886454c0d8df",
            "placeholder": "​",
            "style": "IPY_MODEL_3a269414e7d04c2199bd5daabdc2cd8a",
            "value": " 472/472 [00:00&lt;00:00, 3.32kB/s]"
          }
        },
        "17d2aaf8f6f746558c5ab84d5df8aec9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "184f72957c324d75b0039f0060c26793": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "188a3c5f2d554f38b24e3eac7a2d5653": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7402fe98378473bbe4fdc0d0340230d",
            "placeholder": "​",
            "style": "IPY_MODEL_01c6da52ed2246ffa329839fa67d299c",
            "value": " 2.78G/2.78G [00:40&lt;00:00, 64.0MB/s]"
          }
        },
        "18b0b95cef9c431a8df7c1f47692716c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f205555d1ca4ac8bdafeba061d55e42",
            "placeholder": "​",
            "style": "IPY_MODEL_3640701102ea495eacec6e17e284b7f1",
            "value": "100%"
          }
        },
        "19ea31f2360f4fc3852725ec09190db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a7aa53aaf8a48c3ac382f4334983f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abb18b968dc64ae5a189b23a3e77cdab",
            "placeholder": "​",
            "style": "IPY_MODEL_d2692cc333fc4b81b5efa86d782df898",
            "value": ""
          }
        },
        "1aa0c29da19243b1acc29e854d8f3a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_457e085df8cc4b389577bc860f3e8e73",
              "IPY_MODEL_0708d8f9b27340f9856fe62bee0aba86",
              "IPY_MODEL_ec0bc06282b6467e84d9d078f3311aa7"
            ],
            "layout": "IPY_MODEL_81347750927d4a68853f150d3315687c"
          }
        },
        "1b6a9ab0c9c541319d12239c95e72704": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bbce83811b94e3aa88ada564c20d73d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c8056de84d346ed8629448eac453ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77a10398c1924d8a834ba3f26627616b",
            "max": 1680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a61bbb7a18504b9c8fbf10603fc57028",
            "value": 1680
          }
        },
        "1d64f403a62a4b959bba730cdc6f0351": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d80471fb38a42b38d1c26b3eaed1bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ee6ab668b894610ae8233684d35613a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c1157f514814fae9076e9d2942ebf4a",
              "IPY_MODEL_fe76ce76d6ee4e1885389ff6a5fdf26c",
              "IPY_MODEL_3816aeeec8f145efbc8aec3c95d57cce"
            ],
            "layout": "IPY_MODEL_6798e243ef8e42538974f9c87b71063a"
          }
        },
        "1f3ebbbf009943b48a6fae48fa92f596": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f5e0d4fcb864777ba1e26183bf95ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f75efc6175d468481f6c7806b840dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20127b92ccc241b7aa5e802b5772ae81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "209c8165ea7e4e8ea861e556d3f28516": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2101850edd9244aea5f86b243b156fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "214620b7e45541a9b610308d26b019d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2183a1dac672420cbc6956f9688c8abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21e65a844f754ce2ab2336e8b2ff75ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c72786637634cadafc6e7828d408dd1",
            "max": 1680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b1fe36c5ae442358a6163b3e9f0c11d",
            "value": 1680
          }
        },
        "2228b0c7195e49d78cd66b182bd61797": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a29d1fbd6644af3b89007c66bc65ee4",
              "IPY_MODEL_747be79329d84728a6d3f8af9c393557",
              "IPY_MODEL_a209a454daf54dfdb819439b7b871758"
            ],
            "layout": "IPY_MODEL_069aac0963e9489584d1cdcff4176f1d"
          }
        },
        "22441075dbd84f6c900c2295d5c71f92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "225de4f3a3df49e781d5bda483b8b165": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a07c3dec63bf4d7caf7664d1e6bd58c3",
            "placeholder": "​",
            "style": "IPY_MODEL_b3ef42edf4634da9936fcd5b5509b514",
            "value": " 525k/525k [00:00&lt;00:00, 1.16MB/s]"
          }
        },
        "22960b20336a4c3b867988ca1f1d232a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da6c64a9affd4997935ff98a26cdc4a4",
              "IPY_MODEL_12ff6cb95288405189782621d5dea0a9",
              "IPY_MODEL_4acf5198bb2a4722bb67c16015c210e4"
            ],
            "layout": "IPY_MODEL_230d600f64f54f1eaaaa600a3b89c471"
          }
        },
        "22d1697b59a44b5e908acfef3de1ace9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "230d600f64f54f1eaaaa600a3b89c471": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23160b0f0dc9404892e4d8478787c461": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23bf412165384b8eba635cf75697cab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23f6e9e148d34eab8c95a2a8d61d67fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24fb2092216d45eab43bbd1e48923ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "251de098ac5744ab9360dc5690e8a03f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25be8896b50643a2b19d55f904efbf8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25cad132d92c44d09d08e283e2268481": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26bc8802722544d69efb0840a44595fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26ce271167e34bd9837a56eb41fbc08b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2702bf6d999b4d809f2a3a94b4d98c4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2751d0bdbbeb48418f9fe9fb0d415bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "275241564f4248a0a2dc36b4f5d79916": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c01de2c792747d5a41f3f73daf95ca4",
            "placeholder": "​",
            "style": "IPY_MODEL_24fb2092216d45eab43bbd1e48923ffb",
            "value": " 737/737 [00:00&lt;00:00, 17.8kB/s]"
          }
        },
        "27bf4fec18cd42b88cae6570b5993859": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27dbbb8acc50431d9f61fee633383e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e5f7d0f709f487c8859e26145ad44be",
            "placeholder": "​",
            "style": "IPY_MODEL_e697e70e4c5f45aba7038f2df017f98f",
            "value": " 631/631 [00:00&lt;00:00, 21.7kB/s]"
          }
        },
        "2833c32fe6264928b7a9c9ff04e43b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26ce271167e34bd9837a56eb41fbc08b",
            "max": 460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_294583de0004422e805039d30fa94caa",
            "value": 460
          }
        },
        "28b7ba0103234e11941a5fd4af2afb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28fcedb3b1fe427a9b0d619c28482de6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "294583de0004422e805039d30fa94caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29a54fda5730418bb83df4884697f9a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bdc3c82c13146ada1b2a8261245f5c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c978bc546d64b8cb8798c1f3fc89aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2de860b3966444bfb087d194f0f610db",
              "IPY_MODEL_dfd561faafac42698f9b61064042e896",
              "IPY_MODEL_a1682fb6d1b641a7ba716483ccb4ffda"
            ],
            "layout": "IPY_MODEL_23160b0f0dc9404892e4d8478787c461"
          }
        },
        "2ca892d51a55401dbdeb328adbd42155": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2de860b3966444bfb087d194f0f610db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bea00dae05484f938d993a78ab9e50f0",
            "placeholder": "​",
            "style": "IPY_MODEL_3443be8e346d42bd9bedb9cc84de0b55",
            "value": "model.safetensors: 100%"
          }
        },
        "2e81d536c7b24c558564409c2c18eb87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e94d2d583a94cb783e86ffc923be868": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9a95f0bcbbe463d891c72db242ddcdf",
            "placeholder": "​",
            "style": "IPY_MODEL_2101850edd9244aea5f86b243b156fe7",
            "value": "config.json: 100%"
          }
        },
        "2ed20a6749c44673b6cbc97022c97ac3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f0c402d4bcb4c50a4d8c942de27e8b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30dff80ba7cf4563a09bd42f0b35167d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30e0493ca3064d658957fd02b749fb3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30ef25fb25e84e6a86c3351e02fad380": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31559917ad99484592e1d400a8de4db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31e8032dbd5e4a90979957ffa6f6c002": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9797182166d3400bbe33092695ebb9a5",
            "placeholder": "​",
            "style": "IPY_MODEL_609da650367f4eb284dd76246609f387",
            "value": " 961k/961k [00:00&lt;00:00, 2.09MB/s]"
          }
        },
        "32154364f98844a1a93574b7debd7083": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32c8c134d2c849ff84edb613b68c1d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4126701d0b9b4ff2babee7cd8dfaa21b",
            "placeholder": "​",
            "style": "IPY_MODEL_22d1697b59a44b5e908acfef3de1ace9",
            "value": " 737/737 [00:00&lt;00:00, 3.67kB/s]"
          }
        },
        "3443be8e346d42bd9bedb9cc84de0b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35358f6ccb7042d2b58aac407b6cd440": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3640701102ea495eacec6e17e284b7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "366034a52a4a421e869a942150aae645": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "366376049a324426866bd1e3c1c83125": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3816aeeec8f145efbc8aec3c95d57cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af0d765dcf394d04bf19e8b8dc5b46d4",
            "placeholder": "​",
            "style": "IPY_MODEL_dee0b73f44764d89b1b8cfaeac56e3cb",
            "value": " 10.3G/10.3G [00:54&lt;00:00, 237MB/s]"
          }
        },
        "391266aa5965470caadf361de11c92c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39a5b7cfaffe4dd5b206e29935bcb6e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39ba0971bd864003aaaeef3b76957bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39d5f4be9b41435eabb7786257f3a7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a269414e7d04c2199bd5daabdc2cd8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a29d1fbd6644af3b89007c66bc65ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e6456d5d3a14e0cb1289b9a13730b74",
            "placeholder": "​",
            "style": "IPY_MODEL_3add4f4359364a2b846d14e81626f38f",
            "value": "Fetching 16 files: 100%"
          }
        },
        "3a4822250711479fb2f54a648f795caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88bd0ff9f8784fd1a4ab5995fe915996",
            "max": 2224003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eca2b1d049104f71878a211841f13df7",
            "value": 2224003
          }
        },
        "3add4f4359364a2b846d14e81626f38f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bbdc47ad28341c999676d974b4ca14d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c1aa041a9b64e509fda33da939cfa25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c72786637634cadafc6e7828d408dd1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d3cdaaf155d4e2086a5e1fc9c653226": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3dbb67d76bde46be994d0ab97c0900e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f77fdb9c7d649b5b4e7528ea74fef83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ffbd1d10bba431a85cc30fe34a41641": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40a5d8f8280d4d4a9466091f17a1e9c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4126701d0b9b4ff2babee7cd8dfaa21b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41725e1c7ec24043a10a0d9259e2589d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41a32bcf8000456ab34e5ceb372f1e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41d6b9aa81f347b8b1fee44aee63b8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "420e9e6ae622439ca44c809600fc3970": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4234d7175c264d7eaf4d6c32dc2dc669": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42377cf44f974391a7b90f263879acac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a14c5f0d195548aea3ac62b0340a5e18",
              "IPY_MODEL_c890ef2b22b64f82974480734efbe9d5",
              "IPY_MODEL_e9a4a7dc0b3544f7a300745e46f87525"
            ],
            "layout": "IPY_MODEL_59029ed7eb3a4b78a23a4169727d566c"
          }
        },
        "424ff9f4606a4b379147aa9ae3ae7a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42dc301bb34c48b2895bc59296b270d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42f4e526a57a4051a45023b551025873": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28fcedb3b1fe427a9b0d619c28482de6",
            "placeholder": "​",
            "style": "IPY_MODEL_5a8b3698da1e42fa9e91448ab6d27258",
            "value": " 631/631 [00:00&lt;00:00, 55.6kB/s]"
          }
        },
        "4475f88bc7c5418aa89b32787eccf1fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44b348752a8e49eb944c4758b854267e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45477907cd70476ebc3972945776bcd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c58a6f9e4667468dbc2d4d8a61c5dcee",
              "IPY_MODEL_7548d4e6447e42b5a136ff95dfe642fb",
              "IPY_MODEL_53935857af824144b9cb1cdbc013e5ed"
            ],
            "layout": "IPY_MODEL_be8d39aa24ec49408a8d16e346693e32"
          }
        },
        "455cfdb319134fc6bd915c31615e2ad9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "457e085df8cc4b389577bc860f3e8e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4bcbdd42a214a089aa0704c0603f9b5",
            "placeholder": "​",
            "style": "IPY_MODEL_056de1d8d2094d248796c12d831a7a08",
            "value": "model.safetensors: 100%"
          }
        },
        "45e9999d81fb40359095d28ec6dc0f54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46a8abcfa2084dc9a7f421ed0985dd43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a970e9aa6b4f431197f1c1ea6b5ab764",
            "max": 1059962,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41d6b9aa81f347b8b1fee44aee63b8c3",
            "value": 1059962
          }
        },
        "4756da0158d54d818ee776a92c0d71e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "479e7a96e1cd45189aa4640e1ba8fece": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2b52271b41949d0bd21cbe3035e521d",
            "placeholder": "​",
            "style": "IPY_MODEL_42dc301bb34c48b2895bc59296b270d3",
            "value": " 2.22M/2.22M [00:00&lt;00:00, 3.21MB/s]"
          }
        },
        "47e0b39a9f774990aaf0985f8136dd30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48b2c1f1e7434b92b00b3d23236949cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7b9259bce924c95b977531f6f796f0c",
              "IPY_MODEL_921f89d8a5be4fd3b231d833e0c3534a",
              "IPY_MODEL_0972f5f45b3d4d6d997794adaf42d988"
            ],
            "layout": "IPY_MODEL_b714b3a199744e58adce7508c9f9ca23"
          }
        },
        "490d40c726004b2a8f6d281df4c9ae31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49b97361d95a49b0bd085705e86d2f08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a06e78cd250429bbad59ad68eb2b3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ffbd1d10bba431a85cc30fe34a41641",
            "placeholder": "​",
            "style": "IPY_MODEL_35358f6ccb7042d2b58aac407b6cd440",
            "value": "text_encoder_2/config.json: 100%"
          }
        },
        "4acf5198bb2a4722bb67c16015c210e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11807a9968bc4b7e9d6eeba3e0ee576e",
            "placeholder": "​",
            "style": "IPY_MODEL_0ebfad027fe247f6af0eece055c9f47d",
            "value": " 609/609 [00:00&lt;00:00, 43.7kB/s]"
          }
        },
        "4ad3ddada58c442ca26089723dbede0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4caa3bbcd51e4861ab84ef9e46bd9f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_501968f2e8c3402188552c66db9ebe68",
            "max": 2778702264,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30ef25fb25e84e6a86c3351e02fad380",
            "value": 2778702264
          }
        },
        "4d1f4966b6894e4081330050e8c7b7d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d57aed7f42b4d60b6cdfba08fcfdb8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dd540b7c7a7479f8b688b5d87085a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf188c17ee5142e2b28075a1a0aff304",
            "max": 334643238,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ba17408358a4be393514cc155a71e87",
            "value": 334643238
          }
        },
        "4e6a89e114f749839dd29a6956f45782": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa971b74ac314087bf950965b228cec1",
            "placeholder": "​",
            "style": "IPY_MODEL_84bfdfd0c277406dada5560117ee1243",
            "value": "tokenizer/special_tokens_map.json: 100%"
          }
        },
        "4ef6691309754418ad14b3dd324a75a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7df71b3d187441e8a615c2f74789d491",
              "IPY_MODEL_d494e712bd994fa3a5071adb6fccfc55",
              "IPY_MODEL_107d82afd6664e6b929b63895a0572ce"
            ],
            "layout": "IPY_MODEL_57fd398fbd66433fadc3bffd797f4ff2"
          }
        },
        "4fa08ee7392d4a378fd20a273780de04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f52b05b37b34e23b47462fc18726e9c",
            "placeholder": "​",
            "style": "IPY_MODEL_7bc430ca7a0c44ec922764ed43b82ba1",
            "value": " 0/30 [00:00&lt;?, ?it/s]"
          }
        },
        "4fb53e7c0f40450a86ff3a5bb8b3d0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9291f15e4e0845388abc1d71d5fd7ab4",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90d71ed7cb3442578cd7b096536fccf9",
            "value": 50
          }
        },
        "4fe3689205494c669a9ff315ca26e8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_781a4acc44c4476c9b7ed3b7937b5f4d",
              "IPY_MODEL_6edce9449b0c4ef9a704e609314994d7",
              "IPY_MODEL_b7558040759a40db8e55395f94bbb23b"
            ],
            "layout": "IPY_MODEL_5cc8891593754a75a3b1d81e1458cfdc"
          }
        },
        "5017a2228d8847e98e85e4ac58b80f94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "501968f2e8c3402188552c66db9ebe68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "510449a0ea1c48e7aa4649c4c0364da1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51ccdbe91a0346b9aae36b2b92c51033": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f101f427915497398e25f8c7c921b65",
            "max": 609,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7003c4c2b647416993fd82a41963dda4",
            "value": 609
          }
        },
        "51f71c046fbb47fbba9153153536a289": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "525948aaa8d042768b2c2010d5838cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52a5da1f67db43d5b1ba693f0e7b5266": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "534ae29f3b2740f3ba8d787a468fc905": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "537f759bbcfb4340b46697742b71a61f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53935857af824144b9cb1cdbc013e5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_835ebe7535a24630b43a4dda6164008f",
            "placeholder": "​",
            "style": "IPY_MODEL_fddbc3b3a75e40ecbdfbf387820de538",
            "value": " 460/460 [00:00&lt;00:00, 2.45kB/s]"
          }
        },
        "55026358f3a1440b8b1b2a96b01e27cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5525a020c7154a959964f7b076488357": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55caa26773134bdbbb04d4102156e831": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "562d4bfd65c04c618a1d15d268bed945": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_843565eb179c4d73a83975f723b2371a",
              "IPY_MODEL_5a7e273fb33d4b388a7881280d8a090e",
              "IPY_MODEL_0e9ffd1e62114a1892aada0b072d6c76"
            ],
            "layout": "IPY_MODEL_d4b734b506f3463eae346f01f424ac58"
          }
        },
        "56330b139b124cf0871d3ddbb2dd9b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd2a66677ce54c8f9792b7db4d703a3b",
            "placeholder": "​",
            "style": "IPY_MODEL_1f75efc6175d468481f6c7806b840dd0",
            "value": "diffusion_pytorch_model.safetensors: 100%"
          }
        },
        "56f46d27d04141ab806f46ae1dacfd15": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56fd2848df154b749e0ae3a8b4245933": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5729bd7b54bd45588e24515e13f7e936": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18b0b95cef9c431a8df7c1f47692716c",
              "IPY_MODEL_4fb53e7c0f40450a86ff3a5bb8b3d0f6",
              "IPY_MODEL_e4ace33ba3ee41ae873641644bea0308"
            ],
            "layout": "IPY_MODEL_bc7b3b571d0a4039bb06560632565aa2"
          }
        },
        "57fd398fbd66433fadc3bffd797f4ff2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5817fb2a64e74410b26e8c37e3754726": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cc54df5431145499e2200420e543b81",
              "IPY_MODEL_71a9e9494c4541f5b38d5d090b730490",
              "IPY_MODEL_31e8032dbd5e4a90979957ffa6f6c002"
            ],
            "layout": "IPY_MODEL_0c00ad25b49a4d31b8596b7111ad5af3"
          }
        },
        "58fd0e73b79d4788a70e692a08a338d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59029ed7eb3a4b78a23a4169727d566c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59553f83a97c428d90d870e824a5161d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59d32a27ecaf40ddb53f25525eeef6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2702bf6d999b4d809f2a3a94b4d98c4f",
            "max": 681,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44b348752a8e49eb944c4758b854267e",
            "value": 681
          }
        },
        "59d739c76f9f4511a885cc6cc1a4924e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_044f65dd855c48acb0f87c358455b5d8",
              "IPY_MODEL_59d32a27ecaf40ddb53f25525eeef6dc",
              "IPY_MODEL_f8c0c5bafcb74519877418328024c161"
            ],
            "layout": "IPY_MODEL_0b83863d3e904622a0af54740f7698d4"
          }
        },
        "5a31d62c3d704d0c845e3c48b693cd76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a7e273fb33d4b388a7881280d8a090e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22441075dbd84f6c900c2295d5c71f92",
            "max": 17,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03fe68b9f32445c2b7de6dc316482e49",
            "value": 17
          }
        },
        "5a8b3698da1e42fa9e91448ab6d27258": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5af9a0b8fc05443bafbb9dbf67107d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a7aa53aaf8a48c3ac382f4334983f0d",
              "IPY_MODEL_c64837a14f0e4e43a487bcb1479a1547",
              "IPY_MODEL_7715c1108dd34adab8269b6559e2f9c0"
            ],
            "layout": "IPY_MODEL_8761dee1f9b342d681f09ba5db9b6742"
          }
        },
        "5b727c3656a14c5c8a533d1e8a0d1345": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bf6a4f560dd434284eba5ab65974a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94994cbbce3146b198dcdbcd47b31566",
            "max": 565,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdf62800f78443f78aaabaa56b2c1619",
            "value": 565
          }
        },
        "5c6f705b9c0844148af76adef7ac22bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cc8891593754a75a3b1d81e1458cfdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cdc44913aaa436f9865a044b28d24ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a78ba2ec0b2f4aa4a09b98ad73a288dd",
            "placeholder": "​",
            "style": "IPY_MODEL_20127b92ccc241b7aa5e802b5772ae81",
            "value": "unet/config.json: 100%"
          }
        },
        "5d1e1c469b85487dac79eac01df09fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32154364f98844a1a93574b7debd7083",
            "max": 631,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de812259916545c19d91e41b9323056b",
            "value": 631
          }
        },
        "5d2d6884c99f412fb45bf1bd729b8a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7ed37e4781442ac9b2e1a4a640103c1",
            "placeholder": "​",
            "style": "IPY_MODEL_4ad3ddada58c442ca26089723dbede0c",
            "value": " 7/7 [00:03&lt;00:00,  1.73it/s]"
          }
        },
        "5d4f717ae245446b8294c56c900a6598": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f28259fbc214a98965194a9da82d82f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f523d655bed4508be6de70a907fa9f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f66cbfe44144c2c8db29234b8fd5c84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "609da650367f4eb284dd76246609f387": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6212801c1c0f4365887d686725ded172": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62748d3f85c24ab7b9ce3179a02ca325": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb2bafcbcaf04787b1608c5bac3cac19",
            "placeholder": "​",
            "style": "IPY_MODEL_06bd1486d1b0499dbb7f56d2b06fe30c",
            "value": " 2.50G/2.50G [01:01&lt;00:00, 42.3MB/s]"
          }
        },
        "62b949c25e694a6bba6a118229ea4cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bbe9b1d5b824fe187209211ef682010",
              "IPY_MODEL_46a8abcfa2084dc9a7f421ed0985dd43",
              "IPY_MODEL_c0c18a88439e4d5eb4a9759cd1d5f814"
            ],
            "layout": "IPY_MODEL_0eb92dcbb27a4f23ba9cd0da5fa95b65"
          }
        },
        "63384619ed4b4d9584cbd7006b18eb43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64288953735d47c8a8b219536dc3d23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8432a23539f947bb8e8d2b7732af1bc9",
            "placeholder": "​",
            "style": "IPY_MODEL_6f352b15666a44c0bcd91d99b7851d07",
            "value": "model_index.json: 100%"
          }
        },
        "64855f125ae44fe78ff31fa825ff09b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6498f1599d75411eafba907fbc946ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a338a3c5ca594e8581bd25830a82a4f6",
            "placeholder": "​",
            "style": "IPY_MODEL_74657ba839584071ade50a4025552d56",
            "value": "text_encoder_2/config.json: 100%"
          }
        },
        "651ac9e7c8da4913890851f0d46644ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39ba0971bd864003aaaeef3b76957bcb",
            "placeholder": "​",
            "style": "IPY_MODEL_4756da0158d54d818ee776a92c0d71e9",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "655b1ece6bb24255a6d476f69cf1a3a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "673619c4850c48b199841817183f2c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7a6061f095b497fbad23815e09a2dde",
            "max": 2502139104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bccbb605807d4ee1b41314f632483ba6",
            "value": 2502139104
          }
        },
        "6798e243ef8e42538974f9c87b71063a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67cf61f197e94ac78779e90d638837f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67d303b7feca4aee926acfbdb1981079": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_168115c4992146998042eb2ade6c329a",
            "placeholder": "​",
            "style": "IPY_MODEL_b35ebbea6c4f4919acea89d40f5e3916",
            "value": "model.safetensors: 100%"
          }
        },
        "681b9dd0d3634b3fa52009cb36553369": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45e9999d81fb40359095d28ec6dc0f54",
            "placeholder": "​",
            "style": "IPY_MODEL_d97fe47f723c441ca563e9fdf60390ad",
            "value": " 1.34k/1.34k [00:00&lt;00:00, 55.1kB/s]"
          }
        },
        "69c0f836e83b488faf9d043503449f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5525a020c7154a959964f7b076488357",
            "placeholder": "​",
            "style": "IPY_MODEL_5d4f717ae245446b8294c56c900a6598",
            "value": "model.safetensors: 100%"
          }
        },
        "6c01de2c792747d5a41f3f73daf95ca4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c1157f514814fae9076e9d2942ebf4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9fce0d96a9d4e7e9a440843ce537c5d",
            "placeholder": "​",
            "style": "IPY_MODEL_b031e260204542b6925bf1b3ec6a5769",
            "value": "diffusion_pytorch_model.safetensors: 100%"
          }
        },
        "6c391e2118a44e09a969a7f7d2a7a3fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_455cfdb319134fc6bd915c31615e2ad9",
            "placeholder": "​",
            "style": "IPY_MODEL_01e9755e67fa41be9f13d2d4524c2c4d",
            "value": " 2.78G/2.78G [00:18&lt;00:00, 221MB/s]"
          }
        },
        "6d50236c70a34e7bb309a95647bed7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1af48f50b2d4e4597a0a533b13b43ac",
            "placeholder": "​",
            "style": "IPY_MODEL_a502d18a75ea4d91875ee43e3655d852",
            "value": "merges.txt: 100%"
          }
        },
        "6d676c139d6e4bbfa72eddcb56117f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17d2aaf8f6f746558c5ab84d5df8aec9",
            "placeholder": "​",
            "style": "IPY_MODEL_05fedefbfd86470e9b13cc2857e665a3",
            "value": "config.json: 100%"
          }
        },
        "6e22ef5b91ad408987330c36c62908f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e47838e4a7c4b029aae4e46a3eed770": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_366034a52a4a421e869a942150aae645",
            "placeholder": "​",
            "style": "IPY_MODEL_e6dd15ef979b4c4982176fbf3dae3d3a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "6eab28e3811544d09464bb3db81c973a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ebc0201d1304a95be3740b545ce961c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6edce9449b0c4ef9a704e609314994d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_779ccb06116a4c7ab631d5f8e739f816",
            "max": 2502139136,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_768cf24ae7534ec5ba89f089dca41c41",
            "value": 2502139136
          }
        },
        "6f352b15666a44c0bcd91d99b7851d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f52b05b37b34e23b47462fc18726e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7003c4c2b647416993fd82a41963dda4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7023d3adf6c041829fb2134873554938": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69c0f836e83b488faf9d043503449f01",
              "IPY_MODEL_d8bad9ea6a2342f3b2899f561bd4d290",
              "IPY_MODEL_6c391e2118a44e09a969a7f7d2a7a3fa"
            ],
            "layout": "IPY_MODEL_cac7c642af8a4f539d350451aa233722"
          }
        },
        "7048bcf07fc14c84a7bc549ab1fa12a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70743e7af2fd4215957889434899bde5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70a93aae91b84de0a75175c28afa4679": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70d7bb3d3eda4aa2a9325e3fc7fd2bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67d303b7feca4aee926acfbdb1981079",
              "IPY_MODEL_4caa3bbcd51e4861ab84ef9e46bd9f0c",
              "IPY_MODEL_188a3c5f2d554f38b24e3eac7a2d5653"
            ],
            "layout": "IPY_MODEL_750607a260504a21b1d891a952ee53d6"
          }
        },
        "717fc2f185054b43b7e52e43697e97f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7eba9d12a12b48c29c8861f52ec2de93",
            "placeholder": "​",
            "style": "IPY_MODEL_9b42611af4b74026baaecb969a85dcd1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "71a9e9494c4541f5b38d5d090b730490": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87e5a97d7a884bd7a43a8a5109e827bc",
            "max": 961143,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c78e91927eeb49da910e1c5d38fdeb09",
            "value": 961143
          }
        },
        "71ce1ae673ec4c1c843c2af85cc4e9db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "724529a2a9bc455eb54ba521c2958dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d50236c70a34e7bb309a95647bed7ca",
              "IPY_MODEL_8ffc7c14d3e14a46aa6688041baae8aa",
              "IPY_MODEL_225de4f3a3df49e781d5bda483b8b165"
            ],
            "layout": "IPY_MODEL_b9c9cf39e01d4944b32cbc12704478b9"
          }
        },
        "72b45a7433b34f9c82891d999eeebc31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74657ba839584071ade50a4025552d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7479119f365246149078ba560aa95ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "747b84b1adde4962b8d9d36c1d6d44c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "747be79329d84728a6d3f8af9c393557": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e22ef5b91ad408987330c36c62908f1",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79d596731844453eb5e6ce5355857843",
            "value": 16
          }
        },
        "750607a260504a21b1d891a952ee53d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7548d4e6447e42b5a136ff95dfe642fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9559abe488d4441aa394de5cb003b38",
            "max": 460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7eb5e119c73f4414829f4609cfb6bd0d",
            "value": 460
          }
        },
        "7551ae8dec1f4849a7f3d6254b1818e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_537f759bbcfb4340b46697742b71a61f",
            "max": 524619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_023df8b8c986436182a7fb62fa00dc44",
            "value": 524619
          }
        },
        "7651203542ad4f89a4665aa5373b3d31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "768cf24ae7534ec5ba89f089dca41c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "769b124249a64db483011693172b3728": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76a0764a524f43dfa93819ca9ecff5ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7048bcf07fc14c84a7bc549ab1fa12a8",
            "max": 1059962,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d5b1f21b53f4a1aa077617579523d7b",
            "value": 1059962
          }
        },
        "76c0911cc04a41209864ace7e27b22e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc30203cd8ef48938c8dfe0fed8cb09a",
            "placeholder": "​",
            "style": "IPY_MODEL_cc167425e7694c268dc12bdc9a424db9",
            "value": " 1.68k/1.68k [00:00&lt;00:00, 103kB/s]"
          }
        },
        "76c5ff27de444c50916e8436f86821c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7715c1108dd34adab8269b6559e2f9c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b75a7ec9927b4e66ba93a8df043c5979",
            "placeholder": "​",
            "style": "IPY_MODEL_3c1aa041a9b64e509fda33da939cfa25",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "776725c48b0c491691670ded8de55dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bd9508dcbe349d6ac68129082bf74b6",
            "placeholder": "​",
            "style": "IPY_MODEL_2e81d536c7b24c558564409c2c18eb87",
            "value": "tokenizer/vocab.json: 100%"
          }
        },
        "779ccb06116a4c7ab631d5f8e739f816": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77a10398c1924d8a834ba3f26627616b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77aeb3a4f9894121812d96073f44a141": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77de45f8681a4563a02c376d62288561": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77f37be86c8445c9a3c2f4de58534736": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "781a4acc44c4476c9b7ed3b7937b5f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55026358f3a1440b8b1b2a96b01e27cf",
            "placeholder": "​",
            "style": "IPY_MODEL_2bdc3c82c13146ada1b2a8261245f5c7",
            "value": "diffusion_pytorch_model.safetensors: 100%"
          }
        },
        "789c6b192940440cb4d0de8a0397cb19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e115417e94314f2c881dcf341c1135da",
            "max": 737,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01e97aa7317e4c6cbf2a36d6fe7d6b9f",
            "value": 737
          }
        },
        "79d596731844453eb5e6ce5355857843": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ab72f6aa44f4d1995d87f9b65022415": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ac0a1b9dfd84485a7eaca671c8610cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_109b8475eb9246da82dae34e221946bf",
            "placeholder": "​",
            "style": "IPY_MODEL_28b7ba0103234e11941a5fd4af2afb6f",
            "value": " 725/725 [00:00&lt;00:00, 28.7kB/s]"
          }
        },
        "7bc430ca7a0c44ec922764ed43b82ba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d08fcee21724076b37f432369f2525f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dce93d1135048f8b3bb31d0c90d3791": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd7bd3ae52804a6aaca5db7837c80bd3",
              "IPY_MODEL_a9a6a95546904cdeb97bce62ef9a45eb",
              "IPY_MODEL_0dd5f42206d9428398a6ea9fd86a3374"
            ],
            "layout": "IPY_MODEL_67cf61f197e94ac78779e90d638837f3"
          }
        },
        "7df71b3d187441e8a615c2f74789d491": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85f308672ea34437a617f10bc702ea54",
            "placeholder": "​",
            "style": "IPY_MODEL_5c6f705b9c0844148af76adef7ac22bb",
            "value": "diffusion_pytorch_model.safetensors: 100%"
          }
        },
        "7e85f97d98b64f688818f91658f6fbe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7eb2eeac910840e29c248f43ba6dde3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7eb5e119c73f4414829f4609cfb6bd0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7eba9d12a12b48c29c8861f52ec2de93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ebbdf5a04f84542bfdba07ae251a1aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ed265597290420fa2f768ea7102bc0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ee88877b1354a50aad77c6d5ec03e64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "805d3573401f488fa951d27736d1f5aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80856a2836544aa7933e580a2c7e6871": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80c7d211cb294f43af846241818f8445": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d21d359678ce41caac0be120eb3862e1",
            "placeholder": "​",
            "style": "IPY_MODEL_09db989912774f888c3ebded60872a8e",
            "value": " 389/389 [00:00&lt;00:00, 32.1kB/s]"
          }
        },
        "81347750927d4a68853f150d3315687c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "835ebe7535a24630b43a4dda6164008f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83cd3e5f4a224afd98e08213750d0a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a31d62c3d704d0c845e3c48b693cd76",
            "placeholder": "​",
            "style": "IPY_MODEL_9884bf9762f64e6191422fc2d2d0077e",
            "value": "diffusion_pytorch_model.safetensors: 100%"
          }
        },
        "8432a23539f947bb8e8d2b7732af1bc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "843565eb179c4d73a83975f723b2371a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_969b60f82a354ba28d155baee293c255",
            "placeholder": "​",
            "style": "IPY_MODEL_5f523d655bed4508be6de70a907fa9f8",
            "value": "Fetching 17 files: 100%"
          }
        },
        "84bfdfd0c277406dada5560117ee1243": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "857ae2a7015a4bc2ac4245afcd10a4e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85f308672ea34437a617f10bc702ea54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85fe24efb45843b8b960e9961b5d6c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9cd41740dc24239b99914e36432d729",
            "placeholder": "​",
            "style": "IPY_MODEL_0aed79556aa346d682e09e1653c6a843",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "86d7a7f904724067bb576d6b7583b371": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86d9d138c9a845f5a26a7d5974ed548b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8761dee1f9b342d681f09ba5db9b6742": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87e5a97d7a884bd7a43a8a5109e827bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88bd0ff9f8784fd1a4ab5995fe915996": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8935c1c741024ce98ea4fef2d57cfaae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86d9d138c9a845f5a26a7d5974ed548b",
            "placeholder": "​",
            "style": "IPY_MODEL_27bf4fec18cd42b88cae6570b5993859",
            "value": " 565/565 [00:00&lt;00:00, 37.4kB/s]"
          }
        },
        "8a8c5d9e487b446ba727726beb92b699": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8af392ed2c0648349e03660f8b57a07f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f560d4d5f6ed4245ad98d1c30cdc9f69",
            "max": 905,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d80471fb38a42b38d1c26b3eaed1bdd",
            "value": 905
          }
        },
        "8b404badcde74f9eb40227311a07ccbb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b4caf99947e44159169bdecfb50edea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bbe9b1d5b824fe187209211ef682010": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d64f403a62a4b959bba730cdc6f0351",
            "placeholder": "​",
            "style": "IPY_MODEL_e351ca432f4841a9b8ab3d4ad7ba1b41",
            "value": "tokenizer/vocab.json: 100%"
          }
        },
        "8cc54df5431145499e2200420e543b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14881852ea964905932858987e401e62",
            "placeholder": "​",
            "style": "IPY_MODEL_424ff9f4606a4b379147aa9ae3ae7a37",
            "value": "vocab.json: 100%"
          }
        },
        "8d32100bc2564dee8b7cc2b043e73db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_011d2ccd58c6484e92ccdf11461abd2b",
            "placeholder": "​",
            "style": "IPY_MODEL_4d57aed7f42b4d60b6cdfba08fcfdb8e",
            "value": " 1.06M/1.06M [00:00&lt;00:00, 4.18MB/s]"
          }
        },
        "8d50572dc23549f99de9bb87b95e530a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d5b1f21b53f4a1aa077617579523d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d8267f6a8994dac870c094ec7ee882b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e02e5909cd8480e963f1a4d1f0a33a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e6dfcb9c8c642d4b3cc17f5a86bf2b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dccfc313a0794460800e0e3be3f7c96d",
            "placeholder": "​",
            "style": "IPY_MODEL_51f71c046fbb47fbba9153153536a289",
            "value": "tokenizer.json: 100%"
          }
        },
        "8f101f427915497398e25f8c7c921b65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f205555d1ca4ac8bdafeba061d55e42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ffc7c14d3e14a46aa6688041baae8aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf53c4823f784f3197492808f7d255d6",
            "max": 524619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ab72f6aa44f4d1995d87f9b65022415",
            "value": 524619
          }
        },
        "90577bbaf40445eeb0906a964314005c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a24c088602c6424fa38012d33e868b00",
              "IPY_MODEL_dd459f7dc892497ab76d3cf96f4a28aa",
              "IPY_MODEL_5d2d6884c99f412fb45bf1bd729b8a39"
            ],
            "layout": "IPY_MODEL_26bc8802722544d69efb0840a44595fb"
          }
        },
        "90d71ed7cb3442578cd7b096536fccf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91dc9b5c2d9d4f1c91f18e0e4757a89c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "921f89d8a5be4fd3b231d833e0c3534a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93d2fcd8a2ce4c73890e99df0fe00b5e",
            "max": 565,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4ba3dd178d44d62b8b0fa6bcf67118f",
            "value": 565
          }
        },
        "9291f15e4e0845388abc1d71d5fd7ab4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92cf0f6e4b1142ada3c20e303b57cdf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93d2fcd8a2ce4c73890e99df0fe00b5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93ddb363b21242c5b9091e6a6084a69e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "945386f05cee4fa3b938a9b599f7561a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e6a89e114f749839dd29a6956f45782",
              "IPY_MODEL_fc9ee6559e8042a4b00c3b3aacd71891",
              "IPY_MODEL_abdb36aed6e34c38acbb1d3065735576"
            ],
            "layout": "IPY_MODEL_049f09d6eec640728d87b0e560ca7781"
          }
        },
        "94994cbbce3146b198dcdbcd47b31566": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "952eef74193b450bba4ce4139df2245e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1086f2a7d8d646ffa27d63c56ad9413a",
              "IPY_MODEL_d8a58d67f42c4d0685b10dae8bd7f359",
              "IPY_MODEL_681b9dd0d3634b3fa52009cb36553369"
            ],
            "layout": "IPY_MODEL_06f0c83e9608449a9846d362f5c69bcd"
          }
        },
        "9532e5c867ef46d3a9fd2a26608014eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "969b60f82a354ba28d155baee293c255": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9797182166d3400bbe33092695ebb9a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9884bf9762f64e6191422fc2d2d0077e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99420ca8ae1a40668d4d92c24c28e872": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9b09e057a6894d98812d5941c75d7b32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b42611af4b74026baaecb969a85dcd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ba17408358a4be393514cc155a71e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bd9508dcbe349d6ac68129082bf74b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d24c846f7f54219b935c8fae320e236": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_076269715a2140eaa549ddb8863ed854",
            "max": 631,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f223769289a5462e851c4e72958b3099",
            "value": 631
          }
        },
        "9e46975ddeb24c2bab80d628f7563627": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a07c3dec63bf4d7caf7664d1e6bd58c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a14c5f0d195548aea3ac62b0340a5e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bec11f4e707c42ea8e20186143fe2aeb",
            "placeholder": "​",
            "style": "IPY_MODEL_8e02e5909cd8480e963f1a4d1f0a33a2",
            "value": "scheduler/scheduler_config.json: 100%"
          }
        },
        "a1682fb6d1b641a7ba716483ccb4ffda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_857ae2a7015a4bc2ac4245afcd10a4e5",
            "placeholder": "​",
            "style": "IPY_MODEL_77de45f8681a4563a02c376d62288561",
            "value": " 492M/492M [00:02&lt;00:00, 153MB/s]"
          }
        },
        "a1ce251bdb20408c935622e7132060ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a209a454daf54dfdb819439b7b871758": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a45f88abf4fe4a5794875106f2cab296",
            "placeholder": "​",
            "style": "IPY_MODEL_10d9e2a49a8e4215882b576343feba50",
            "value": " 16/16 [01:25&lt;00:00,  5.62s/it]"
          }
        },
        "a24c088602c6424fa38012d33e868b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7651203542ad4f89a4665aa5373b3d31",
            "placeholder": "​",
            "style": "IPY_MODEL_70a93aae91b84de0a75175c28afa4679",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "a2707688a4ea40fca46db2a9d1a5dea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d9076ea15c346f59da4867bbb8b6035",
              "IPY_MODEL_5bf6a4f560dd434284eba5ab65974a41",
              "IPY_MODEL_8935c1c741024ce98ea4fef2d57cfaae"
            ],
            "layout": "IPY_MODEL_d1537c303797496fbad19202c78acaf6"
          }
        },
        "a2869e04e2fc44348a8767a2b0eba392": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a338a3c5ca594e8581bd25830a82a4f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a361bc28776444a1a124e5c60ea4d84c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a45f88abf4fe4a5794875106f2cab296": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a47890191b9146e3a1f41a5ad7dcc749": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a361bc28776444a1a124e5c60ea4d84c",
            "placeholder": "​",
            "style": "IPY_MODEL_91dc9b5c2d9d4f1c91f18e0e4757a89c",
            "value": "tokenizer_2/special_tokens_map.json: 100%"
          }
        },
        "a4bcbdd42a214a089aa0704c0603f9b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a502d18a75ea4d91875ee43e3655d852": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a52d8d49fc864dc9ba8449a1308e964c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a55dd58544c3410782491fbb9fa36463": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23f6e9e148d34eab8c95a2a8d61d67fa",
            "max": 725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ca892d51a55401dbdeb328adbd42155",
            "value": 725
          }
        },
        "a61bbb7a18504b9c8fbf10603fc57028": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a635f43a1d674bc698e4ccbf1a6bd8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ed265597290420fa2f768ea7102bc0b",
            "max": 524619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_129f124d7e704403ae4638d57ba1f175",
            "value": 524619
          }
        },
        "a6c77bb9fe9d4bb6bbb0860782da86ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a71f6326ad5f441fa21a00e7e6b92dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80856a2836544aa7933e580a2c7e6871",
            "placeholder": "​",
            "style": "IPY_MODEL_aeeaa36ba00e47e8a142de1650e007d9",
            "value": " 525k/525k [00:00&lt;00:00, 1.67MB/s]"
          }
        },
        "a78ba2ec0b2f4aa4a09b98ad73a288dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a88f88408e5a4f048425d404ff020b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a968aa266de244d68cc45338b1aa62f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2ee1825d92146fcbb3e69390b3db222",
              "IPY_MODEL_0dbf6f16b384469283b40d5be01706c7",
              "IPY_MODEL_0d4e4e52a589466ab1487289c847201b"
            ],
            "layout": "IPY_MODEL_127c80d36bc24d45aa9132a7fb173a8f"
          }
        },
        "a970e9aa6b4f431197f1c1ea6b5ab764": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9a6a95546904cdeb97bce62ef9a45eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9705a6f9bd54243829d4a681272af55",
            "max": 334643268,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae64ef0fe22e4497ad6a69dc93edd004",
            "value": 334643268
          }
        },
        "aa60afb16aca4732b27a89eb7ed551dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cdc44913aaa436f9865a044b28d24ab",
              "IPY_MODEL_1c8056de84d346ed8629448eac453ce5",
              "IPY_MODEL_76c0911cc04a41209864ace7e27b22e0"
            ],
            "layout": "IPY_MODEL_2f0c402d4bcb4c50a4d8c942de27e8b7"
          }
        },
        "aa98614ec7b44763bb602692343d0737": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e6dfcb9c8c642d4b3cc17f5a86bf2b2",
              "IPY_MODEL_3a4822250711479fb2f54a648f795caf",
              "IPY_MODEL_479e7a96e1cd45189aa4640e1ba8fece"
            ],
            "layout": "IPY_MODEL_534ae29f3b2740f3ba8d787a468fc905"
          }
        },
        "abb18b968dc64ae5a189b23a3e77cdab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abbd17d9f5794093b18ed245b6d67768": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abdb36aed6e34c38acbb1d3065735576": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e85eaf55d5fb4d6780235d25dd2cb09b",
            "placeholder": "​",
            "style": "IPY_MODEL_2183a1dac672420cbc6956f9688c8abb",
            "value": " 472/472 [00:00&lt;00:00, 11.9kB/s]"
          }
        },
        "ac11cd34bd2f4a9685dcb421f13a0c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41725e1c7ec24043a10a0d9259e2589d",
            "max": 334643238,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0113d7bfcf734340b2d58f046fd1a3a2",
            "value": 334643238
          }
        },
        "ad2b6e48025140b59be0e13524eb6034": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad9aaa478bd544a7b42df5ddb128e9a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae64ef0fe22e4497ad6a69dc93edd004": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aeeaa36ba00e47e8a142de1650e007d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af0d765dcf394d04bf19e8b8dc5b46d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af420b380d1c4671a8b895d415a09e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af4e380a8a3b4761af7922be2e1e1c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b031e260204542b6925bf1b3ec6a5769": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b036f81726244db2b749f9c23c9cfd2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ee88877b1354a50aad77c6d5ec03e64",
            "placeholder": "​",
            "style": "IPY_MODEL_655b1ece6bb24255a6d476f69cf1a3a7",
            "value": " 7/7 [01:19&lt;00:00,  8.89s/it]"
          }
        },
        "b2beed56912c4c1cb15a02b6705ead75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e47838e4a7c4b029aae4e46a3eed770",
              "IPY_MODEL_cb20c491d6d44cd1872a762fbc26b0ed",
              "IPY_MODEL_80c7d211cb294f43af846241818f8445"
            ],
            "layout": "IPY_MODEL_5017a2228d8847e98e85e4ac58b80f94"
          }
        },
        "b2ee1825d92146fcbb3e69390b3db222": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad2b6e48025140b59be0e13524eb6034",
            "placeholder": "​",
            "style": "IPY_MODEL_f9a03a59f3144a6e8e7b497b42c576c4",
            "value": "diffusion_pytorch_model.safetensors: 100%"
          }
        },
        "b31d8fae3f08472e842cb8775c3236b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92cf0f6e4b1142ada3c20e303b57cdf9",
            "placeholder": "​",
            "style": "IPY_MODEL_faf9ef052bec4e8490b0bbfb6a7acf1c",
            "value": " 525k/525k [00:00&lt;00:00, 2.30MB/s]"
          }
        },
        "b35ebbea6c4f4919acea89d40f5e3916": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3d2392382c94dfab46dbbf1e70dc11f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3ef42edf4634da9936fcd5b5509b514": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3f2bf8ab34947d28a18259bf8300a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b51f68ac4d994356bcabf124bc9971b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5caf5f283084b0bbcc30b7ae139c7a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5fa8184224641139ee7021a507c0ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b66ec366fd754fbe912750eb3187ee9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6cbd60a005a47579fc3dfe61524e980": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_717fc2f185054b43b7e52e43697e97f5",
              "IPY_MODEL_8af392ed2c0648349e03660f8b57a07f",
              "IPY_MODEL_0d010e343c844257aa2e30b01bf9d0a7"
            ],
            "layout": "IPY_MODEL_f78d8386b81a487b81cabc1b204369b3"
          }
        },
        "b714b3a199744e58adce7508c9f9ca23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7558040759a40db8e55395f94bbb23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3371dadb6f84d69a7145642052e5621",
            "placeholder": "​",
            "style": "IPY_MODEL_2751d0bdbbeb48418f9fe9fb0d415bc4",
            "value": " 2.50G/2.50G [00:59&lt;00:00, 42.5MB/s]"
          }
        },
        "b75a7ec9927b4e66ba93a8df043c5979": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b863d51c1d1e4123be7839905346da64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86d7a7f904724067bb576d6b7583b371",
            "placeholder": "​",
            "style": "IPY_MODEL_39d5f4be9b41435eabb7786257f3a7c8",
            "value": " 1.68k/1.68k [00:00&lt;00:00, 11.0kB/s]"
          }
        },
        "b8c2a8fa74654e4da153f64b2518e13e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b96f876d38c3485b928c546c7f4de239": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9705a6f9bd54243829d4a681272af55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9c9cf39e01d4944b32cbc12704478b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc30203cd8ef48938c8dfe0fed8cb09a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc3bcaa6bbb6410f8687c39c4aa3ce0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc7b3b571d0a4039bb06560632565aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bccbb605807d4ee1b41314f632483ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcffd6ad9f7b4694aa8343f76449b406": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ede2ac99c29946518c9441f75438b221",
              "IPY_MODEL_ac11cd34bd2f4a9685dcb421f13a0c66",
              "IPY_MODEL_e2173be2c6d6418f90683b2f3750bcf1"
            ],
            "layout": "IPY_MODEL_00711f6476c0452e8c53e038e8cc1b6f"
          }
        },
        "be8d39aa24ec49408a8d16e346693e32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bea00dae05484f938d993a78ab9e50f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bec11f4e707c42ea8e20186143fe2aeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beded9de684b4821b3818a4b4a12dd43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ef949bb877a409dadf9720c9057cf07",
              "IPY_MODEL_c0846654957143ae8c1cf7f7f0a9a3bb",
              "IPY_MODEL_4fa08ee7392d4a378fd20a273780de04"
            ],
            "layout": "IPY_MODEL_fd5ad7745d8241e98da69a479332b36b"
          }
        },
        "bf4edd1beda747b39ce268c7a0954675": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c01da5c6733e4b519756c41bf2a6538a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e46975ddeb24c2bab80d628f7563627",
            "placeholder": "​",
            "style": "IPY_MODEL_08521b337d754fc88cbab3546096259e",
            "value": "tokenizer/special_tokens_map.json: 100%"
          }
        },
        "c0846654957143ae8c1cf7f7f0a9a3bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbba41afe0e04b39ae3da6029955645b",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca1bed64d245432a9e25be3afc017583",
            "value": 0
          }
        },
        "c0c18a88439e4d5eb4a9759cd1d5f814": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93ddb363b21242c5b9091e6a6084a69e",
            "placeholder": "​",
            "style": "IPY_MODEL_e79411fb102c4ff18d2c88eefe2601d8",
            "value": " 1.06M/1.06M [00:00&lt;00:00, 1.55MB/s]"
          }
        },
        "c17c57de7e334cdeb5301895a50ade72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c58a6f9e4667468dbc2d4d8a61c5dcee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30dff80ba7cf4563a09bd42f0b35167d",
            "placeholder": "​",
            "style": "IPY_MODEL_bf4edd1beda747b39ce268c7a0954675",
            "value": "tokenizer_2/special_tokens_map.json: 100%"
          }
        },
        "c5a293cc3ccd4ece949ddb6b16a19df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c64837a14f0e4e43a487bcb1479a1547": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99420ca8ae1a40668d4d92c24c28e872",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d3cdaaf155d4e2086a5e1fc9c653226",
            "value": 0
          }
        },
        "c67b7ee1a09f4bb1b0a386de7b380153": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c72dfbf67e5c4190b34413ef1e12f036": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a47890191b9146e3a1f41a5ad7dcc749",
              "IPY_MODEL_2833c32fe6264928b7a9c9ff04e43b33",
              "IPY_MODEL_05d8815c6a48408b8edf6237a4ba918e"
            ],
            "layout": "IPY_MODEL_ad9aaa478bd544a7b42df5ddb128e9a2"
          }
        },
        "c78e91927eeb49da910e1c5d38fdeb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c890ef2b22b64f82974480734efbe9d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ef8ff2b5574cd5ada2cec5942f76fc",
            "max": 479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e50ae298d29043219fe8c7761d904863",
            "value": 479
          }
        },
        "c98d688caac44e129c8920dc6fc06388": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca1bed64d245432a9e25be3afc017583": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca1dadcb959b4f65bc8b34db9c6fc114": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e26b8b28f40948c7add10d9658e30bda",
            "placeholder": "​",
            "style": "IPY_MODEL_420e9e6ae622439ca44c809600fc3970",
            "value": "tokenizer_2/tokenizer_config.json: 100%"
          }
        },
        "ca2a8ec229234e6fa161652a638e0523": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eed61e27f6ff4d9d81f0b04733978816",
              "IPY_MODEL_789c6b192940440cb4d0de8a0397cb19",
              "IPY_MODEL_275241564f4248a0a2dc36b4f5d79916"
            ],
            "layout": "IPY_MODEL_59553f83a97c428d90d870e824a5161d"
          }
        },
        "cac7c642af8a4f539d350451aa233722": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb01922c589843348b8891a2559fc020": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb20c491d6d44cd1872a762fbc26b0ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b09e057a6894d98812d5941c75d7b32",
            "max": 389,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23bf412165384b8eba635cf75697cab0",
            "value": 389
          }
        },
        "cb3768ff817041418edbee5ff21a0888": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c01da5c6733e4b519756c41bf2a6538a",
              "IPY_MODEL_cc2636365f1d4b79995def48a3f7d9d2",
              "IPY_MODEL_174c36947efb414f9c9007b09a1a03d4"
            ],
            "layout": "IPY_MODEL_b96f876d38c3485b928c546c7f4de239"
          }
        },
        "cbba41afe0e04b39ae3da6029955645b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc167425e7694c268dc12bdc9a424db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc2636365f1d4b79995def48a3f7d9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaa2b30fda18435393630336641f4221",
            "max": 472,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72b45a7433b34f9c82891d999eeebc31",
            "value": 472
          }
        },
        "cdc144e8192c4138bef01a1e223d0274": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceef3ff67eb84efba8470c157b18d0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c67b7ee1a09f4bb1b0a386de7b380153",
            "placeholder": "​",
            "style": "IPY_MODEL_19ea31f2360f4fc3852725ec09190db1",
            "value": " 725/725 [00:00&lt;00:00, 3.26kB/s]"
          }
        },
        "cf188c17ee5142e2b28075a1a0aff304": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf53c4823f784f3197492808f7d255d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf8b994c556a4fb4a51f2ef29e2a2fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d04dfa55b0cd423491dc2f9a0140066e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d676c139d6e4bbfa72eddcb56117f9a",
              "IPY_MODEL_5d1e1c469b85487dac79eac01df09fde",
              "IPY_MODEL_42f4e526a57a4051a45023b551025873"
            ],
            "layout": "IPY_MODEL_bc3bcaa6bbb6410f8687c39c4aa3ce0e"
          }
        },
        "d0c094a5a5174a35b33d9e1bb052a71e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0f1df4a66334726a30db120f31f9ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3f2bf8ab34947d28a18259bf8300a7a",
            "max": 737,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b4dc249702c46cf8667c2dbf851a4ba",
            "value": 737
          }
        },
        "d1537c303797496fbad19202c78acaf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1af48f50b2d4e4597a0a533b13b43ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d21d359678ce41caac0be120eb3862e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2692cc333fc4b81b5efa86d782df898": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d352f6d57b39431f8e612a9cfb26f3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffab9401c2b041a0a6d1864de946e7b5",
            "max": 575,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58fd0e73b79d4788a70e692a08a338d7",
            "value": 575
          }
        },
        "d3c69b48c0de4b90b6d063d1828ea87b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eed149a5d2cb44faaf19063c537225c4",
              "IPY_MODEL_d0f1df4a66334726a30db120f31f9ace",
              "IPY_MODEL_32c8c134d2c849ff84edb613b68c1d44"
            ],
            "layout": "IPY_MODEL_49b97361d95a49b0bd085705e86d2f08"
          }
        },
        "d494e712bd994fa3a5071adb6fccfc55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2970c4f298248ed923804c0dff3e0cf",
            "max": 10270077736,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_525948aaa8d042768b2c2010d5838cdd",
            "value": 10270077736
          }
        },
        "d4b734b506f3463eae346f01f424ac58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4fac2a0bcdc41a8b9026c650ab454bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85fe24efb45843b8b960e9961b5d6c70",
              "IPY_MODEL_eb74834bf3d94106b91726d290000635",
              "IPY_MODEL_b036f81726244db2b749f9c23c9cfd2e"
            ],
            "layout": "IPY_MODEL_09e3149c33b7427fb5d6bd3d2667e246"
          }
        },
        "d5e0146742494b25be31f0272addfbc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56fd2848df154b749e0ae3a8b4245933",
            "placeholder": "​",
            "style": "IPY_MODEL_7479119f365246149078ba560aa95ac7",
            "value": " 8/8 [00:01&lt;00:00,  5.73it/s]"
          }
        },
        "d6ef8ff2b5574cd5ada2cec5942f76fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7b9259bce924c95b977531f6f796f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a88f88408e5a4f048425d404ff020b9f",
            "placeholder": "​",
            "style": "IPY_MODEL_f0d382cbab6247f5abc187f90dae17e3",
            "value": "text_encoder/config.json: 100%"
          }
        },
        "d7ed37e4781442ac9b2e1a4a640103c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8a58d67f42c4d0685b10dae8bd7f359": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db87273869e9478bbc848186727eb70c",
            "max": 1340,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecd71d48780846aa83f6e740aab08c38",
            "value": 1340
          }
        },
        "d8bad9ea6a2342f3b2899f561bd4d290": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eea05ac0d4a74cfebce3ff925120e283",
            "max": 2778702264,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bbce83811b94e3aa88ada564c20d73d",
            "value": 2778702264
          }
        },
        "d97fe47f723c441ca563e9fdf60390ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9fce0d96a9d4e7e9a440843ce537c5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da05c48746e14d1e9cf528f5cd9bb930": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eab28e3811544d09464bb3db81c973a",
            "placeholder": "​",
            "style": "IPY_MODEL_de73542b288b4db08e852a5fe8208bf1",
            "value": "tokenizer_2/tokenizer_config.json: 100%"
          }
        },
        "da6c64a9affd4997935ff98a26cdc4a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b4caf99947e44159169bdecfb50edea",
            "placeholder": "​",
            "style": "IPY_MODEL_c5a293cc3ccd4ece949ddb6b16a19df9",
            "value": "model_index.json: 100%"
          }
        },
        "daaa93b80b5e4c169e1a6aa71d25cda3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db87273869e9478bbc848186727eb70c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dccfc313a0794460800e0e3be3f7c96d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd459f7dc892497ab76d3cf96f4a28aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1ce251bdb20408c935622e7132060ac",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5caf5f283084b0bbcc30b7ae139c7a1",
            "value": 7
          }
        },
        "dd7bd3ae52804a6aaca5db7837c80bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f28259fbc214a98965194a9da82d82f",
            "placeholder": "​",
            "style": "IPY_MODEL_747b84b1adde4962b8d9d36c1d6d44c0",
            "value": "diffusion_pytorch_model.safetensors: 100%"
          }
        },
        "de58984a44c64634a2558af489d7aa70": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de73542b288b4db08e852a5fe8208bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de812259916545c19d91e41b9323056b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dec52e2dfb334ae0abc2738d56f4a04e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f53e9fc6c5d640c0807b6d8819b5db9d",
              "IPY_MODEL_21e65a844f754ce2ab2336e8b2ff75ca",
              "IPY_MODEL_b863d51c1d1e4123be7839905346da64"
            ],
            "layout": "IPY_MODEL_8a8c5d9e487b446ba727726beb92b699"
          }
        },
        "dee0b73f44764d89b1b8cfaeac56e3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfd561faafac42698f9b61064042e896": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3d2392382c94dfab46dbbf1e70dc11f",
            "max": 492265168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41a32bcf8000456ab34e5ceb372f1e26",
            "value": 492265168
          }
        },
        "dfea8e343e4b473b8657c9b51909ee10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff2c9ccafee04cfeab5db052b7c97ab3",
              "IPY_MODEL_a635f43a1d674bc698e4ccbf1a6bd8d9",
              "IPY_MODEL_a71f6326ad5f441fa21a00e7e6b92dfb"
            ],
            "layout": "IPY_MODEL_76c5ff27de444c50916e8436f86821c8"
          }
        },
        "dffd445613e14dbfad06ba358130c614": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e09ffc6c839e456685cf890c2261d1e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e115417e94314f2c881dcf341c1135da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2173be2c6d6418f90683b2f3750bcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6c77bb9fe9d4bb6bbb0860782da86ef",
            "placeholder": "​",
            "style": "IPY_MODEL_7e85f97d98b64f688818f91658f6fbe2",
            "value": " 335M/335M [00:02&lt;00:00, 209MB/s]"
          }
        },
        "e26b8b28f40948c7add10d9658e30bda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e28a840d071e447c9232a95e99a634ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_776725c48b0c491691670ded8de55dee",
              "IPY_MODEL_76a0764a524f43dfa93819ca9ecff5ba",
              "IPY_MODEL_8d32100bc2564dee8b7cc2b043e73db8"
            ],
            "layout": "IPY_MODEL_77f37be86c8445c9a3c2f4de58534736"
          }
        },
        "e2970c4f298248ed923804c0dff3e0cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2b52271b41949d0bd21cbe3035e521d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e32445e2d2454a34bb072855d6857a84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e351ca432f4841a9b8ab3d4ad7ba1b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3bb675ccd8944888e7af081f3bfaec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e48fcd0886244127bb0c14ad4bb626e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a06e78cd250429bbad59ad68eb2b3ac",
              "IPY_MODEL_0c0817ade2b7457cbe418b2bb6114c09",
              "IPY_MODEL_eb06f1b021e94c5da5f3fb48f280f681"
            ],
            "layout": "IPY_MODEL_e32445e2d2454a34bb072855d6857a84"
          }
        },
        "e496314fe0bb4cd7a27c7a56426b8dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f9fb2231cfd409ea3a3b90c624bb397",
            "placeholder": "​",
            "style": "IPY_MODEL_3dbb67d76bde46be994d0ab97c0900e4",
            "value": " 1.24k/1.24k [00:00&lt;00:00, 109kB/s]"
          }
        },
        "e4ace33ba3ee41ae873641644bea0308": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c7100d5a4a14f0e802cc12cd444cab3",
            "placeholder": "​",
            "style": "IPY_MODEL_e617b650e35a49aeac2ff5ba669e379e",
            "value": " 50/50 [00:16&lt;00:00,  3.28it/s]"
          }
        },
        "e4ba3dd178d44d62b8b0fa6bcf67118f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e50ae298d29043219fe8c7761d904863": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5c949feefd141c1ba987eea153fb6fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc144e8192c4138bef01a1e223d0274",
            "max": 1235,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7eb2eeac910840e29c248f43ba6dde3b",
            "value": 1235
          }
        },
        "e617b650e35a49aeac2ff5ba669e379e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e697e70e4c5f45aba7038f2df017f98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6dd15ef979b4c4982176fbf3dae3d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e79411fb102c4ff18d2c88eefe2601d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7a6061f095b497fbad23815e09a2dde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e85eaf55d5fb4d6780235d25dd2cb09b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e883f8f23f8747d690cabb0da75b0736": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a53a5eb2c1410898ef886454c0d8df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8cf0232c6854ce3a6adab4dcb350446": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_510449a0ea1c48e7aa4649c4c0364da1",
            "placeholder": "​",
            "style": "IPY_MODEL_77aeb3a4f9894121812d96073f44a141",
            "value": " 335M/335M [00:01&lt;00:00, 220MB/s]"
          }
        },
        "e9a4a7dc0b3544f7a300745e46f87525": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0c094a5a5174a35b33d9e1bb052a71e",
            "placeholder": "​",
            "style": "IPY_MODEL_af4e380a8a3b4761af7922be2e1e1c3a",
            "value": " 479/479 [00:00&lt;00:00, 18.0kB/s]"
          }
        },
        "e9cd41740dc24239b99914e36432d729": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaa2b30fda18435393630336641f4221": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb06f1b021e94c5da5f3fb48f280f681": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6a9ab0c9c541319d12239c95e72704",
            "placeholder": "​",
            "style": "IPY_MODEL_fc3fa5de9f384220bce886f42716e777",
            "value": " 575/575 [00:00&lt;00:00, 15.7kB/s]"
          }
        },
        "eb2bafcbcaf04787b1608c5bac3cac19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb74834bf3d94106b91726d290000635": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b51f68ac4d994356bcabf124bc9971b1",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bbdc47ad28341c999676d974b4ca14d",
            "value": 7
          }
        },
        "ec0bc06282b6467e84d9d078f3311aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f5e0d4fcb864777ba1e26183bf95ec2",
            "placeholder": "​",
            "style": "IPY_MODEL_30e0493ca3064d658957fd02b749fb3a",
            "value": " 492M/492M [00:10&lt;00:00, 64.6MB/s]"
          }
        },
        "eca2b1d049104f71878a211841f13df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecd71d48780846aa83f6e740aab08c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ede2ac99c29946518c9441f75438b221": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af420b380d1c4671a8b895d415a09e1c",
            "placeholder": "​",
            "style": "IPY_MODEL_cb01922c589843348b8891a2559fc020",
            "value": "diffusion_pytorch_model.safetensors: 100%"
          }
        },
        "ee43e34fa59c43c8a6a08f5bbd605509": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c98d688caac44e129c8920dc6fc06388",
            "placeholder": "​",
            "style": "IPY_MODEL_fc608c71d5a7488689ebdb07bef6aaa5",
            "value": " 575/575 [00:00&lt;00:00, 5.27kB/s]"
          }
        },
        "eea05ac0d4a74cfebce3ff925120e283": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eed149a5d2cb44faaf19063c537225c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29a54fda5730418bb83df4884697f9a1",
            "placeholder": "​",
            "style": "IPY_MODEL_55caa26773134bdbbb04d4102156e831",
            "value": "tokenizer/tokenizer_config.json: 100%"
          }
        },
        "eed61e27f6ff4d9d81f0b04733978816": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b66ec366fd754fbe912750eb3187ee9f",
            "placeholder": "​",
            "style": "IPY_MODEL_b5fa8184224641139ee7021a507c0ed7",
            "value": "tokenizer/tokenizer_config.json: 100%"
          }
        },
        "ef06048f2b534ddc8d75927a42325c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11af2a41f18f4387976ce896eb90766e",
            "max": 725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9532e5c867ef46d3a9fd2a26608014eb",
            "value": 725
          }
        },
        "ef27ffeb5f3d429485d376658a4032ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e94d2d583a94cb783e86ffc923be868",
              "IPY_MODEL_e5c949feefd141c1ba987eea153fb6fd",
              "IPY_MODEL_e496314fe0bb4cd7a27c7a56426b8dcf"
            ],
            "layout": "IPY_MODEL_b8c2a8fa74654e4da153f64b2518e13e"
          }
        },
        "f0d382cbab6247f5abc187f90dae17e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f223769289a5462e851c4e72958b3099": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2f7281055fb453488f1c155f7bb3432": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e2f34dc713240c28dd69b26d592c43c",
              "IPY_MODEL_7551ae8dec1f4849a7f3d6254b1818e7",
              "IPY_MODEL_b31d8fae3f08472e842cb8775c3236b6"
            ],
            "layout": "IPY_MODEL_251de098ac5744ab9360dc5690e8a03f"
          }
        },
        "f3371dadb6f84d69a7145642052e5621": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f53e9fc6c5d640c0807b6d8819b5db9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0459b3f8e0a6421584573955f38b6ef6",
            "placeholder": "​",
            "style": "IPY_MODEL_64855f125ae44fe78ff31fa825ff09b1",
            "value": "unet/config.json: 100%"
          }
        },
        "f560d4d5f6ed4245ad98d1c30cdc9f69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6acc6f583814459b92c6732eb4a6489": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7402fe98378473bbe4fdc0d0340230d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f78d8386b81a487b81cabc1b204369b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8501cd6f1a14b7da61018ffa37bbd07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6498f1599d75411eafba907fbc946ad8",
              "IPY_MODEL_d352f6d57b39431f8e612a9cfb26f3ff",
              "IPY_MODEL_ee43e34fa59c43c8a6a08f5bbd605509"
            ],
            "layout": "IPY_MODEL_3f77fdb9c7d649b5b4e7528ea74fef83"
          }
        },
        "f85fe08ec3474bbaa2dd00aeec83cff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8c0c5bafcb74519877418328024c161": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_769b124249a64db483011693172b3728",
            "placeholder": "​",
            "style": "IPY_MODEL_f6acc6f583814459b92c6732eb4a6489",
            "value": " 681/681 [00:00&lt;00:00, 33.6kB/s]"
          }
        },
        "f9559abe488d4441aa394de5cb003b38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a03a59f3144a6e8e7b497b42c576c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9a95f0bcbbe463d891c72db242ddcdf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9cb1e8477c54863bc2061d2844d55dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa971b74ac314087bf950965b228cec1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf9ef052bec4e8490b0bbfb6a7acf1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc3fa5de9f384220bce886f42716e777": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc608c71d5a7488689ebdb07bef6aaa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc9ee6559e8042a4b00c3b3aacd71891": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d50572dc23549f99de9bb87b95e530a",
            "max": 472,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_209c8165ea7e4e8ea861e556d3f28516",
            "value": 472
          }
        },
        "fcd1c7c99d9143a581de4012a424e32b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15d85fb5b0174b938ab8fca8357ff1db",
              "IPY_MODEL_9d24c846f7f54219b935c8fae320e236",
              "IPY_MODEL_27dbbb8acc50431d9f61fee633383e4c"
            ],
            "layout": "IPY_MODEL_391266aa5965470caadf361de11c92c4"
          }
        },
        "fd2a66677ce54c8f9792b7db4d703a3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd5ad7745d8241e98da69a479332b36b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fddbc3b3a75e40ecbdfbf387820de538": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdf62800f78443f78aaabaa56b2c1619": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe76ce76d6ee4e1885389ff6a5fdf26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daaa93b80b5e4c169e1a6aa71d25cda3",
            "max": 10270077736,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_097f9e49117e4ee98990a0c21985363e",
            "value": 10270077736
          }
        },
        "fef115a939cc433a81d51f5951186197": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff2c9ccafee04cfeab5db052b7c97ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2869e04e2fc44348a8767a2b0eba392",
            "placeholder": "​",
            "style": "IPY_MODEL_5b727c3656a14c5c8a533d1e8a0d1345",
            "value": "tokenizer/merges.txt: 100%"
          }
        },
        "ffab9401c2b041a0a6d1864de946e7b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}